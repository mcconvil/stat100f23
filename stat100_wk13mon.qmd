---
pagetitle: "More Theory-Based Inference"
format: 
  revealjs:
    html-math-method: mathjax
    chalkboard: true
    incremental: true
    theme: [default, custom.scss]
    multiplex: true
    height: 900
    width: 1600
    slide-number: c
    auto-stretch: false
    callout-appearance: simple
    pdf-max-pages-per-slide: 1
    menu: 
      side: right
      numbers: true
    code-overflow: wrap
#    fontsize: 20
execute:
  echo: true
  warning: false
  message: false
  fig-asp: 0.75
  fig-width: 8
#  fig-align: center
  fig-dpi: 500
---

```{r}
#| include: false
#| warning: false
#| message: false
# Some global options still not available in quarto
 knitr::opts_chunk$set(fig.align = 'center')
library(knitr)
library(tidyverse)
theme_update(text = element_text(size = 13))
```

------------------------------------------------------------------------

::: columns
::: {.column .center width="45%"}
![](img/DAW.png){width="90%"}
:::

::: {.column .center width="55%"}
[More Theory-Based Inference]{.custom-title}

<br> <br> <br>

[Kelly McConville]{.custom-subtitle}

[Stat 100 <br> Week 13 \| Fall 2023]{.custom-subtitle}
:::
:::

------------------------------------------------------------------------

## Announcements

-   Regular OH schedule ends on Tues, Dec 5th (last day of classes).
-   Will have lots of office hours during Reading Period but not at the standard times.
    -   Will update the OH spreadsheet once finalized.

### Goals for Today

::: columns
::: column
-   Discuss more theory-based inference.
:::

::: column
-   Sample size calculations.
:::
:::

------------------------------------------------------------------------

## `r emo::ji("tada")` You are all invited to the Stat 100 `ggparty`! `r emo::ji("tada")`

::: fragment
**Question**: What is a `ggparty`?
:::

::: fragment
> "`ggparty`": An end-of-semester party filled with Stat 100-themed games, prizes, and food!
:::

------------------------------------------------------------------------

![](img/ggpartyf23.jpeg){width="45%" fig-align="center"}

[If you are able to attend, please RSVP: [bit.ly/ggpartyf23](https://bit.ly/ggpartyf23)]{.custom-subtitle}

------------------------------------------------------------------------

![](img/prizes.jpeg){width="80%" fig-align="center"}

[If you are able to attend, please RSVP: [bit.ly/ggpartyf23](https://bit.ly/ggpartyf23)]{.custom-subtitle}

------------------------------------------------------------------------

### Statistical Inference Zoom Out -- Estimation

![](img/ci_diagram.png){width="60%" fig-align="center"}

------------------------------------------------------------------------

### Statistical Inference Zoom Out -- Testing

![](img/hyp_testing_diagram.png){width="70%" fig-align="center"}

------------------------------------------------------------------------

### Recap:

**Central Limit Theorem (CLT):** For random samples and a large sample size $(n)$, the sampling distribution of many sample statistics is approximately normal.

::: columns
::: column
**Sample Proportion Version:**

When $n$ is large (at least 10 successes and 10 failures):

$$
\hat{p} \sim N \left(p, \sqrt{\frac{p(1-p)}{n}} \right)
$$
:::

::: column
**Sample Mean Version:**

When $n$ is large (at least 30):

$$
\bar{x} \sim N \left(\mu, \frac{\sigma}{\sqrt{n}} \right)
$$
:::
:::

------------------------------------------------------------------------

### There Are [Several Versions](https://mcconvil.github.io/stat100f23/inference_summary.html) of the CLT!

```{r, echo = FALSE}
symbols <- data.frame(Response = c("quantitative", "categorical",
                                   "quantitative", "categorical",
                                   "quantitative"),
                         Explanatory = c("-", "-",
                                         "categorical",
                                         "categorical",
                                         "quantitative"),
                         Numerical_Quantity = c("mean", 
                                                "proportion",
                                                "difference in means",
                                                "difference in proportions",
                                                "correlation"),
                         Parameter = c("$\\mu$", "$p$", 
                                       "$\\mu_1 - \\mu_2$",
                                       "$p_1 - p_2$",
                                       "$\\rho$"),
                                       Statistic = c("$\\bar{x}$",
                                                     "$\\hat{p}$",
                                                     "$\\bar{x}_1 - \\bar{x}_2$",
                                                     "$\\hat{p}_1 - \\hat{p}_2$",
                                                     "$r$"))

symbols %>% 
  kableExtra::kbl(format="markdown")
```

-   Refer to [these tables](https://mcconvil.github.io/stat100f23/inference_summary.html) for:
    -   CLT's "large sample" assumption
    -   Equation for the test statistic
    -   Equation for the confidence interval

------------------------------------------------------------------------

### Recap:

**Z-score test statistics**:

$$
\mbox{Z-score} = \frac{\mbox{statistic} - \mu}{\sigma}
$$

-   Usually follows a **standard normal** or a **t** distribution.

-   Use the approximate distribution to find the p-value.

------------------------------------------------------------------------

### Recap:

**Formula-Based** P\*100% Confidence Intervals

$$
\mbox{statistic} \pm z^* SE
$$

where $P(-z^* \leq Z \leq z^*) = P$

Or we will see that sometimes we use a **t** critical value:

$$
\mbox{statistic} \pm t^* SE
$$

where $P(-t^* \leq t \leq t^*) = P$

# How do we perform probability model calculations in `R`?

------------------------------------------------------------------------

### Probability Calculations in R

**Question**: How do I compute **probabilities** in R?

::: columns
::: column
```{r, echo = FALSE}
library(tidyverse)
dat <- data.frame(x = seq(-3, 3, length.out = 1000)) %>%
  mutate(y = dnorm(x, mean = 0, sd = 1),
         z = if_else(x > 1, TRUE, FALSE))
dat2 <- dat %>%
  filter(z)
ggplot(data = dat, mapping = aes(x, y)) +
  geom_ribbon(mapping = aes(ymin = 0, ymax = y, fill = z),
              data = dat2) +
  guides(fill = FALSE) +
  geom_line(size = 2) +
  scale_fill_manual(values = "deeppink")
```
:::

::: column
```{r}
pnorm(q = 1, mean = 0, sd = 1)
pt(q = 1, df = 52)
```
:::
:::

**Doesn't seem quite right**...

------------------------------------------------------------------------

### Probability Calculations in R

**Question**: How do I compute **probabilities** in R?

::: columns
::: column
```{r, echo = FALSE}
library(tidyverse)
dat <- data.frame(x = seq(-3, 3, length.out = 1000)) %>%
  mutate(y = dnorm(x, mean = 0, sd = 1),
         z = if_else(x > 1, TRUE, FALSE))
dat2 <- dat %>%
  filter(z)
ggplot(data = dat, mapping = aes(x, y)) +
  geom_ribbon(mapping = aes(ymin = 0, ymax = y, fill = z),
              data = dat2) +
  guides(fill = FALSE) +
  geom_line(size = 2) +
  scale_fill_manual(values = "deeppink")
```
:::

::: column
```{r}
pnorm(q = 1, mean = 0, sd = 1,
      lower.tail = FALSE)
pt(q = 1, df = 52, lower.tail = FALSE)
```
:::
:::

------------------------------------------------------------------------

### P\*100% CI for parameter:

$$
\mbox{statistic} \pm z^* SE
$$

::: columns
::: column
**Question**: How do I find the correct critical values $(z^* \mbox{ or } t^*)$ for the confidence interval?

```{r, echo = FALSE}
library(tidyverse)
dat <- data.frame(x = seq(-3, 3, length.out = 1000)) %>%
  mutate(y = dnorm(x, mean = 0, sd = 1))
ggplot(data = dat, mapping = aes(x, y)) +
  geom_line(size = 2) +
  geom_vline(xintercept = -1.96, color = "deeppink", size = 2) +
  geom_vline(xintercept = 1.96, color = "deeppink", size = 2)
```
:::

::: column
```{r}
qnorm(p = 0.975, mean = 0, sd = 1)
qt(p = 0.975, df = 52)
```
:::
:::

------------------------------------------------------------------------

### P\*100% CI for parameter:

$$
\mbox{statistic} \pm z^* SE
$$

::: columns
::: column
**Question**: What percentile/quantile do I need for a 90% CI?

```{r, echo = FALSE}
library(tidyverse)
dat <- data.frame(x = seq(-3, 3, length.out = 1000)) %>%
  mutate(y = dnorm(x, mean = 0, sd = 1))
ggplot(data = dat, mapping = aes(x, y)) +
  geom_line(size = 2) +
  geom_vline(xintercept = -1.645, color = "deeppink", size = 2) +
  geom_vline(xintercept = 1.645, color = "deeppink", size = 2)
```
:::

::: column
```{r}
qnorm(p = 0.95, mean = 0, sd = 1)
qt(p = 0.95, df = 52)
```
:::
:::

------------------------------------------------------------------------

### Probability Calculations in R

**To help you remember**:

::: fragment
Want a **P**robability?

→ use `pnorm()`, `pt()`, ...
:::

::: fragment
Want a **Q**uantile (i.e. percentile)?

→ use `qnorm()`, `qt()`, ...
:::

------------------------------------------------------------------------

### Probability Calculations in R

**Question**: When might I want to do probability calculations in R?

-   Computed a test statistic that is approximated by a named random variable. Want to compute the p-value with `p---()`

-   Compute a confidence interval. Want to find the critical value with `q---()`.

-   To do a **Sample Size Calculation**.

------------------------------------------------------------------------

### Sample Size Calculations

-   Very important part of the data analysis process!

-   Happens BEFORE you collect data.

-   You determine how large your sample size needs for a desired precision in your CI.

    -   The power calculations from hypothesis testing relate to this idea.

------------------------------------------------------------------------

### Sample Size Calculations

**Question**: Why do we need sample size calculations?

**Example**: Let's return to the dolphins for treating depression example.

-   With a sample size of 30 and 95% confidence, we estimate that the improvement rate for depression is between 14.5 percentage points and 75 percentage points higher if you swim with a dolphin instead of swimming without a dolphin.

-   With a width of 60.5 percentage points, this 95% CI is a **wide**/very imprecise interval.

::: fragment
**Question**: How could we make it narrower? How could we decrease the Margin of Error (ME)?
:::

------------------------------------------------------------------------

### Sample Size Calculations -- Single Proportion

Let's focus on estimating a single proportion. Suppose we want to estimate the current proportion of Harvard undergraduates with COVID with 95% confidence and we want the margin of error on our interval to be less than or equal to 0.02. **How large does our sample size need to be?**

Want

$$ 
z^* \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}} \leq B
$$

::: fragment
Need to derive a formula that looks like

$$ 
n \geq \quad ...
$$

**Question**: How can we isolate $n$ to be on a side by itself?
:::

------------------------------------------------------------------------

### Sample Size Calculations -- Single Proportion

Let's focus on estimating a single proportion. Suppose we want to estimate the current proportion of Harvard undergraduates with COVID with 95% confidence and we want the margin of error on our interval to be less than or equal to 0.02. **How large does our sample size need to be?**

**Sample size calculation:**

$$
n \geq \frac{\hat{p}(1 - \hat{p})z^{*2}}{B^2}
$$

-   What do we plug in for, $\hat{p}$, $z^{*}$, $B$?

-   Consider sample size calculations when estimating a **mean** on this week's p-set!

# Let's cover examples of theory-based inference for two variables.

------------------------------------------------------------------------

## Data Example

We have data on a random sub-sample of the 2010 American Community Survey. The American Community Survey is given every year to a random sample of US residents.

```{r}
# Libraries
library(tidyverse)
library(Lock5Data)

# Data
data(ACS)
# Focus on adults
ACS_adults <- filter(ACS, Age >= 18)

glimpse(ACS_adults)
```

------------------------------------------------------------------------

### Difference in Proportions

Let's try to determine if there's a relationship between US citizenship and marriage.

**Response variable:**

**Explanatory variable:**

**Parameter of interest:**

**Sample size requirement for theory-based inference**:

------------------------------------------------------------------------

### Difference in Proportions

Let's try to determine if there's a relationship between US citizenship and marriage.

```{r}
#| output-location: column

# Exploratory data analysis
ggplot(data = ACS_adults, 
       mapping = aes(x = factor(USCitizen),
                     fill  = factor(Married))) +
  geom_bar(position = "fill")
```

```{r}
#| output-location: column
# Sample size
ACS_adults %>%
  count(Married, USCitizen)
```

------------------------------------------------------------------------

### Difference in Proportions

Let's try to determine if there's a relationship between US citizenship and marriage.

Why is`prop_test()` failing?

```{r}
#| error: true

library(infer)
ACS_adults %>%
prop_test(Married ~ USCitizen, 
          order = c("1", "0"), z = TRUE,
          success = "1")
```

------------------------------------------------------------------------

### Difference in Proportions

Let's try to determine if there's a relationship between US citizenship and marriage.

```{r}
ACS_adults %>%
  mutate(MarriedCat = case_when(Married == 0 ~ "No",
                                Married == 1 ~ "Yes"),
         USCitizenCat = case_when(USCitizen == 0 ~ "Not citizen",
                                  USCitizen == 1 ~ "Citizen")) %>%
prop_test(MarriedCat ~ USCitizenCat, 
          order = c("Citizen", "Not citizen"), z = TRUE,
          success = "Yes")
```

------------------------------------------------------------------------

### Difference in Means

Let's estimate the average hours worked per week between married and unmarried US residents.

**Response variable:**

**Explanatory variable:**

**Parameter of interest:**

**Sample size requirement for theory-based inference**:

------------------------------------------------------------------------

### Difference in Means

Let's estimate the average hours worked per week between married and unmarried US residents.

```{r}
#| output-location: column

# Exploratory data analysis
ggplot(data = ACS_adults, mapping = aes(x = HoursWk)) +
  geom_histogram() +
  facet_wrap(~Married, ncol = 1)
```

```{r}
#| output-location: column
# Sample size
ACS_adults %>%
  drop_na(HoursWk) %>%
  count(Married)
```

------------------------------------------------------------------------

### Difference in Means

Let's estimate the average hours worked per week between married and unmarried US residents.

Which arguments for `t_test()` reflect my research question?

::: columns
::: column
```{r}
library(infer)
ACS_adults %>%
t_test(HoursWk ~ Married, order = c("1", "0"))
```
:::

::: column
```{r}
library(infer)
ACS_adults %>%
t_test(HoursWk ~ Married, order = c("1", "0"),
       alternative = "greater")
```
:::
:::

------------------------------------------------------------------------

### Correlation

We want to determine if age and hours worked per week have a positive linear relationship.

**Response variable:**

**Explanatory variable:**

**Parameter of interest:**

**Sample size requirement for theory-based inference**:

------------------------------------------------------------------------

### Correlation

We want to determine if age and hours worked per week have a positive linear relationship.

```{r}
#| output-location: column

# Exploratory data analysis
ggplot(data = ACS_adults, 
       mapping = aes(x = Age,
                     y  = HoursWk)) +
  geom_jitter(alpha = 0.5) +
  geom_smooth()
```

------------------------------------------------------------------------

### Correlation

We want to determine if age and hours worked per week have a positive linear relationship.

```{r}
cor.test(~ HoursWk + Age, data = ACS_adults, alternative = "greater")
```

------------------------------------------------------------------------

### Correlation

We want to determine if age and hours worked per week have a positive linear relationship.

```{r}
#| output-location: column

# Exploratory data analysis
ggplot(data = ACS_adults, 
       mapping = aes(x = Age,
                     y  = HoursWk)) +
  geom_jitter(alpha = 0.5) +
  geom_smooth()
```

# Have Learned Two Routes to Statistical Inference

[Which is **better**?]{.custom-subtitle .fragment}

------------------------------------------------------------------------

#### Is Simulation-Based Inference or Theory-Based Inference better?

Depends on how you define **better**.

::: columns
::: column
-   If **better** = Leads to better understanding:
:::

::: column
::: fragment
→ Research tends to show students have a better understanding of **p-values** and **confidence** from learning simulation-based methods.
:::
:::
:::

::: columns
::: column
-   If **better** = More flexible/robust to assumptions:
:::

::: column
::: fragment
→ The simulation-based methods tend to be more flexible but that generally requires learning extensions beyond what we've seen in Stat 100.
:::
:::
:::

::: columns
::: column
-   If **better** = More commonly used:
:::

::: column
::: fragment
→ Definitely the theory-based methods but the simulation-based methods are becoming more **common**.
:::
:::
:::

-   Good to be comfortable with both as you will find both approaches used in journal and news articles!

# What does statistical inference (estimation and hypothesis testing) look like when I have more than 0 or 1 explanatory variables?

------------------------------------------------------------------------

## Reminders:

::: nonincremental
-   If you are able to attend the `ggparty`, RSVP: [bit.ly/ggpartyf23](https://bit.ly/ggpartyf23)
-   Regular OH schedule ends on Tues, Dec 5th (last day of classes).
-   Will have lots of office hours during Reading Period but not at the standard times.
    -   Will update the OH spreadsheet once finalized.
:::
