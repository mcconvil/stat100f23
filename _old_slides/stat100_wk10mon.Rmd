---
title: P-Value Pitfalls
output:
  xaringan::moon_reader:
    css: ["more.css", "xaringan-themer.css", "hygge"]
    lib_dir: libsSlides
    self_contained: false
    nature:
      highlightStyle: github
      ratio: '16:9'      
      highlightLines: true
      countIncrementalSlides: false
      navigation:
        scroll: false
    seal: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE,
                      message = FALSE, 
                      fig.retina = 3, fig.align = 'center',
                      fig.asp = 0.75, fig.width = 8)
library(knitr)
library(tidyverse)
theme_update(text = element_text(size = 20))
```

```{r xaringan-scribble, echo=FALSE}
xaringanExtra::use_scribble()
```



background-image: url("img/DAW.png")
background-position: left
background-size: 50%
class: middle, center, 


.pull-right[



## .base-blue[P-Value Pitfalls]

<br>

<br>

### .purple[Kelly McConville]

#### .purple[ Stat 100 | Week 10 | Spring 2023] 

]



---

### Announcements

* `r emo::ji("tada")` We are now accepting Course Assistant/Teaching Fellow applications for Stat 100 for next semester. To apply, fill out [this application](https://docs.google.com/forms/d/e/1FAIpQLScwKJaRfppRqXAzyxMMCeBUdwrzBudNONt0S9dc8lE2ZUlQwQ/viewform) by **April 7th**.
    + About 9-12 hours of work per week.  
    + Primary responsibilities: Lead a discussion section, hold office hours, grade assessments.




****************************

--

### Goals for Today

.pull-left[


* Finish discussion power

* Statistical inference zoom out




] 



.pull-right[

* A hearty p-values discussion

* Key probability concepts

]

---

### Power Example

Suppose we have a baseball player who has been a 0.250 career hitter who suddenly improves to be a 0.333 hitter.  He wants a raise but needs to convince his manager that he has genuinely improved.  The manager offers to examine his performance in 20 at-bats.

.pull-left[

#### Ho:

]

.pull-right[

#### Ha: 

]


--

.pull-left[
```{r, echo = FALSE, fig.asp = 0.65}
dat <- data.frame(at_bats = c(rep("hit", 8), 
                              rep("miss", 12)))



library(infer)
library(tidyverse)
null <- dat %>%
  specify(response = at_bats, success = "hit") %>%
  hypothesize(null = "point", p = 0.25) %>%
  generate(reps = 1000, type = "draw") %>%
  calculate(stat = "prop") %>%
  mutate(dist = "Null")

alt <- dat %>%
  specify(response = at_bats, success = "hit") %>%
  hypothesize(null = "point", p = 0.333) %>%
  generate(reps = 1000, type = "draw") %>%
  calculate(stat = "prop") %>%
  mutate(dist = "Alternative")

both <- bind_rows(null, alt) %>%
  mutate(dist = fct_relevel(dist, "Null"))

both %>%
  ggplot(mapping = aes(x = stat)) +
  geom_histogram(bins = 40, color = "white") +
  facet_wrap(~dist, ncol = 1) +
  geom_vline(xintercept = 0.45, size = 2,
             color = "turquoise4")


# mean(null$stat >= 0.45)  

power <- round(mean(alt$stat >= 0.45), digits = 2)
```

]

--

.pull-right[

* When $\alpha$ is set to $0.05$, he needs to hit 9 or more (showcase a hitting average of at least 0.45) to get a small enough p-value to reject $H_o$.

* When $\alpha$ is set to $0.05$, the power of this test is `r power`.

* Why is the power **so low**?  

* What aspects of the test could the baseball player change to **increase the power** of the test?


]


---

### Power Example

Suppose we have a baseball player who has been a 0.250 career hitter who suddenly improves to be a 0.333 hitter.  He wants a raise but needs to convince his manager that he has genuinely improved.  The manager offers to examine his performance in ~~20~~ 100 at-bats.

**What will happen to the power of the test if we increase the sample size?**


--

.pull-left[

```{r, echo = FALSE, fig.asp = 0.65}
dat <- data.frame(at_bats = c(rep("hit", 40), 
                              rep("miss", 60)))



library(infer)
library(tidyverse)
null <- dat %>%
  specify(response = at_bats, success = "hit") %>%
  hypothesize(null = "point", p = 0.25) %>%
  generate(reps = 1000, type = "draw") %>%
  calculate(stat = "prop") %>%
  mutate(dist = "Null")

alt <- dat %>%
  specify(response = at_bats, success = "hit") %>%
  hypothesize(null = "point", p = 0.333) %>%
  generate(reps = 1000, type = "draw") %>%
  calculate(stat = "prop") %>%
  mutate(dist = "Alternative")

both <- bind_rows(null, alt) %>%
  mutate(dist = fct_relevel(dist, "Null"))

#quantile(null$stat, 0.95)
# mean(null$stat >= 0.33)

both %>%
  ggplot(mapping = aes(x = stat)) +
  geom_histogram(bins = 40, color = "white") +
  facet_wrap(~dist, ncol = 1) +
  geom_vline(xintercept = quantile(null$stat, 0.95) + .01, size = 2,
             color = "turquoise4")


  

power <- round(mean(alt$stat >= quantile(null$stat, 0.95) + .01), digits = 2)
```

]

--

.pull-right[

* Increasing the sample size increases the power.

* When $\alpha$ is set to $0.05$ and the sample size is now 100, the power of this test is `r power`.


]


---

### Power Example

Suppose we have a baseball player who has been a 0.250 career hitter who suddenly improves to be a 0.333 hitter.  He wants a raise but needs to convince his manager that he has genuinely improved.  The manager offers to examine his performance in ~~20~~ 100 at-bats.

**What will happen to the power of the test if we increase $\alpha$ to 0.1?**


--

.pull-left[

```{r, echo = FALSE, fig.asp = 0.65}
dat <- data.frame(at_bats = c(rep("hit", 40), 
                              rep("miss", 60)))



library(infer)
library(tidyverse)
null <- dat %>%
  specify(response = at_bats, success = "hit") %>%
  hypothesize(null = "point", p = 0.25) %>%
  generate(reps = 1000, type = "draw") %>%
  calculate(stat = "prop") %>%
  mutate(dist = "Null")

alt <- dat %>%
  specify(response = at_bats, success = "hit") %>%
  hypothesize(null = "point", p = 0.333) %>%
  generate(reps = 1000, type = "draw") %>%
  calculate(stat = "prop") %>%
  mutate(dist = "Alternative")

both <- bind_rows(null, alt) %>%
  mutate(dist = fct_relevel(dist, "Null"))

#quantile(null$stat, 0.9)
# mean(null$stat >= 0.31)

both %>%
  ggplot(mapping = aes(x = stat)) +
  geom_histogram(bins = 40, color = "white") +
  facet_wrap(~dist, ncol = 1) +
  geom_vline(xintercept = quantile(null$stat, 0.9) + .01, size = 2,
             color = "turquoise4")


  

power <- round(mean(alt$stat >= quantile(null$stat, 0.9) + .01), digits = 2)
```

]

--

.pull-right[

* Increasing $\alpha$ increases the power.
    + Decreases $\beta$.

* When $\alpha$ is set to $0.1$ and the sample size is  100, the power of this test is `r power`.


]

---

### Power Example

Suppose we have a baseball player who has been a 0.250 career hitter who suddenly improves to be a ~~0.333~~ 0.400 hitter.  He wants a raise but needs to convince his manager that he has genuinely improved.  The manager offers to examine his performance in ~~20~~ 100 at-bats.

**What will happen to the power of the test if he is an even better player?**


--

.pull-left[

```{r, echo = FALSE, fig.asp = 0.65}
dat <- data.frame(at_bats = c(rep("hit", 40), 
                              rep("miss", 60)))



library(infer)
library(tidyverse)
null <- dat %>%
  specify(response = at_bats, success = "hit") %>%
  hypothesize(null = "point", p = 0.25) %>%
  generate(reps = 1000, type = "draw") %>%
  calculate(stat = "prop") %>%
  mutate(dist = "Null")

alt <- dat %>%
  specify(response = at_bats, success = "hit") %>%
  hypothesize(null = "point", p = 0.4) %>%
  generate(reps = 1000, type = "draw") %>%
  calculate(stat = "prop") %>%
  mutate(dist = "Alternative")

both <- bind_rows(null, alt) %>%
  mutate(dist = fct_relevel(dist, "Null"))

#quantile(null$stat, 0.9)
# mean(null$stat >= 0.31)

both %>%
  ggplot(mapping = aes(x = stat)) +
  geom_histogram(bins = 40, color = "white") +
  facet_wrap(~dist, ncol = 1) +
  geom_vline(xintercept = quantile(null$stat, 0.9) + .01, size = 2,
             color = "turquoise4")


  

power <- round(mean(alt$stat >= quantile(null$stat, 0.9) + .01), digits = 2)
```

]

--

.pull-right[

* **Effect size**: Difference between true value of the parameter and null value.
    + Often standardized.

* Increasing the effect size increases the power.

* When $\alpha$ is set to $0.1$, the sample size is 100, and the true probability of hitting the ball is 0.4, the power of this test is `r power`.


]

---

## Thoughts on Power

* What aspects of the test did the player actually have control over?

--

* Why is it easier to set $\alpha$ than to set $\beta$ or power?

--

* Considering power before collecting data is very important!




---

### Let's Talk About P-values

--

* The original intention of the p-value was as an **informal** measure to judge whether or not a researcher should take a second look.

--

* But to create simple statistical manuals for practitioners, this informal measure quickly became a rule: **"p-value < 0.05" = "statistically significant"**.

--

**What were/are the consequences of the "p-value < 0.05" = "statistically significant" rule?**


--

* **A consequence**: The p-value is often misinterpreted to be the probability the null hypothesis is true.  
    + A p-value of 0.003 does not mean there's a 0.3% chance that ESP doesn't exist!
    + People forgot or were never taught what it actually measures.
    
---

### Let's Talk About P-values


.pull-left[

* **A consequence**: Researchers often put too much weight on the p-value and not enough weight on their domain knowledge/the plausibility of their conjecture.
    + Sometimes we give more weight to things we don't understand.

* [xkcd comic](https://xkcd.com/1132/)



]

.pull-right[


```{r  out.width = "65%", echo=FALSE, fig.align='center'}
include_graphics("img/frequentists_vs_bayesians_2x.png") 
```

]



---



.pull-left[

### Let's Talk About P-values


* **A consequence**: [P-hacking](https://projects.fivethirtyeight.com/p-hacking/): Cherry-picking promising findings that are beyond this arbitrary threshold.


* [xkcd comic](https://www.explainxkcd.com/wiki/index.php/882:_Significant)


]

.pull-right[


```{r  out.width = "45%", echo=FALSE, fig.align='center'}
include_graphics("img/significant.png") 
```

]




---

### Let's Talk About P-values


* **A consequence**: People conflate *statistical significance* with *practical significance*.

--

**Example**: A recent *Nature* study of 19,000+ people found that those who meet their spouses online...

--

&rarr; Are less likely to divorce (p-value < 0.002)

--

&rarr; Are more likely to have high marital satisfaction (p-value < 0.001)

--

BUT the estimated **effect sizes** were tiny:

(Recall: The effect size is the difference between true value of the parameter and null value.)

--

* Divorce rate of 5.96% for those who met online versus 7.67% for those who met in-person.

--

* On a 7 point scale, happiness value of 5.64 for those who met online versus 5.48 for those who met in-person.

--

**Question**: Do these results provide compelling evidence that one should change their behavior?

---

### Let's Talk About P-values

The American Statistical Association created a set of principles to address misconceptions and misuse of p-values:

--


1. P-values can indicate how incompatible the data are with a specified statistical model.



2. P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.



3. Scientific conclusions and business or policy decisions should not be based only on whether or not a p-value passes a specific threshold (i.e. 0.05).



4. Proper inference requires full reporting and transparency.



5. A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.



6. By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.





---

### Let's Talk About P-values

* Despite its issues, p-values are still quite popular and can still be a useful tool **when used properly**.

--


* In 2014, George Cobb a professor from Mount Holyoke College poised the following questions (and answers):

```{r  out.width = "55%", echo=FALSE, fig.align='center'}
include_graphics("img/Cobb.png") 
```

--

* Understanding p-values and being able to **interpret a p-value in context** is a learning objective of Stat 100.
    + Ex: If ESP doesn't exist, the probability of guessing correctly on at least 106 out of 329 trials is 0.003.

--

* Understanding that a small p-value means evidence for $H_a$ is important.
    + Ex: Because the p-value is small, we have evidence for ESP.  

--


* Understanding that what you mean by **small** should depend on your field and whether a Type I Error or Type II Error is worse for **your particular research question**.

--
    
* Your ability to tell if a # is less than 0.05 is not a learning objective for Stat 100.  

---

### Reporting Results in Journal Articles

```{r, echo = FALSE, out.width= "60%"}
knitr::include_graphics("img/bem_honorton_1994_results.png")
```



---

background-image: url("img/ci_diagram_sim.png")
background-position: contain
background-size: 70%

### Statistical Inference Zoom Out -- Estimation



--

**Question**: How did folks do inference before computers?


---

background-image: url("img/hyp_testing_diagram_sim.png")
background-position: contain
background-size: 80%

### Statistical Inference Zoom Out -- Testing



--

**Question**: How did folks do inference before computers?


---

background-image: url("img/ci_diagram_sim.png")
background-position: contain
background-size: 70%

### Statistical Inference Zoom Out -- Estimation


**Question**: How did folks do inference before computers?


---

background-image: url("img/ci_diagram.png")
background-position: contain
background-size: 70%

### Statistical Inference Zoom Out -- Estimation


**Question**: How did folks do inference before computers?



---

background-image: url("img/hyp_testing_diagram_sim.png")
background-position: contain
background-size: 80%

### Statistical Inference Zoom Out -- Testing



**Question**: How did folks do inference before computers?


---

background-image: url("img/hyp_testing_diagram.png")
background-position: contain
background-size: 80%

### Statistical Inference Zoom Out -- Testing



**Question**: How did folks do inference before computers?



---

class: middle, center


## This means we need to learn about probability models!



---

### Probability Models

--

*"All models are wrong but some are useful."*  -- George Box

--

.pull-left[

**Question**: How can we use theoretical models to approximate our distributions?

```{r, echo=FALSE, fig.width = 6}
library(tidyverse)
library(palmerpenguins)
library(infer)
penguins %>%
  drop_na(sex) %>%
  specify(flipper_length_mm ~ sex) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat ="diff in means", order = c("female", "male")) %>%
  visualize()
```

]

--

.pull-right[

Before we can answer that question, we need to learn some probability concepts that will help us understand these models.

]

---

### Probability Concepts

**Random process**: outcomes is uncertain.

--

* EX: Roll 6 sided die.

--

The **probability** of an outcome is the "long-run proportion" of times the outcome occurs.

--

* EX: Want probability of rolling the #5
    + Let $p_n$ = proportion of rolls that are 5 in n rolls
    + Let $p$ = probability of rolling 5 = $P$(roll 5)

--

**Law of Large Numbers** (LLN) says that as $n$ increases, $p_n$ converges to $p$.

---

### Probability Concepts

.pull-left[

**Question**: Why is the LLN important to us?

]


--


.pull-left[

**Question**: How have we been computing p-values?

]

--


.pull-left[


$$
\mbox{p-value} = \frac{\mbox{# of extreme test stats}}{\mbox{# of replications}}
$$

LLN tells us the proportion of extreme test stats is roughly equal to the true probability of observing the test statistic or more extreme under $H_o$.

]

.pull-right[


```{r, echo = FALSE}
# Construct data frame of sample results
esp <- data.frame(guess = c(rep("correct", 106),
                            rep("incorrect", 329 - 106)))

# Compute observed test statistic
test_stat <- esp %>%
  specify(response = guess, success = "correct") %>%
  calculate(stat ="prop")


# Generate null distribution 
set.seed(411)
null_dist <- esp %>%
  specify(response = guess, success = "correct") %>%
  hypothesize(null = "point", p = 0.25) %>%
  generate(reps = 200, type = "draw") %>%
  calculate(stat ="prop")

# Graph null distribution with test statistic
ggplot(null_dist, aes(x = stat)) +
  geom_dotplot() +
  geom_vline(xintercept = test_stat$stat, color = "deeppink", size = 2)
```

]





---

### Probabilities: $P(\mbox{event})$

* Probability of event = long-run proportion of event


#### Useful properties of probabilities:

(1)  $0 \leq P(\mbox{event}) \leq 1$

--

.pull-left[

(2) If two events are disjoints (have no outcomes in common), then 

$$
P(\mbox{event 1 or event 2}) = P(\mbox{event 1}) + P(\mbox{event 1}).
$$

]





.pull-right[

```{r, echo = FALSE}
ggplot(null_dist, aes(x = stat)) +
  geom_histogram() +
  geom_vline(xintercept = .3, color = "deeppink", size = 2) +
  geom_vline(xintercept = .2, color = "deeppink", size = 2)
```
We use this fact when we find a two-sided p-value.

]

---

### Probabilities: $P(\mbox{event})$

#### Useful properties of probabilities:

.pull-left[

(3) Complement Rule

$$
P(\mbox{event}) = 1 - P(\mbox{not that event}) = 1 - P(\mbox{event}^c)
$$

Sometimes it is "easier" to find the complement event's probability.

]

.pull-right[

```{r, echo = FALSE}
ggplot(null_dist, aes(x = stat)) +
  geom_histogram() +
  geom_vline(xintercept = .3, color = "deeppink", size = 2)
```



]


---

### Random Variables

**Random variable** (RV) is a random process that **takes on numerical values**.

--

* Discrete RV: Takes on discrete values (countable number of possible values)
    + EX: 0, 1, 2, 3, ...

* Continuous RV: Can take on any value in a interval

--

* Random variables have **probability functions** that tell us the likelihood of specific values.

* For discrete RV, probability function is:

$$
p(x) = P(X = x)
$$
where $\sum p(x) = 1$.

--

* Example: X = # when you roll die

---

### Random Variables

For a random variable, care about its:

--

* Probability function: $p(x) = P(X = x)$

--


* Center: Mean of a RV:

$$
\mu = \sum x p(x)
$$

--

* Spread: Variance of a RV:

$$
\sigma^2 = \sum (x - \mu)^2 p(x)
$$
* And, standard deviation of a RV: 

$$
\sigma = \sqrt{ \sum (x - \mu)^2 p(x)}
$$

--

**Example**: What is the mean and variance for $X$ = # when you roll die?

**Question**: How do these measures relate to $\bar{x}$ and $s^2$?


---

### Another Example:

Suppose 4 students have still not received their graded Stat 100 Midterm (yes, let's pretend we actually have hand-written work) and that I hand back the exams randomly to each student.  Let X = the number of students who get their correct exam.

--

**Questions:**

* Let's say the student's names are A(licia), B(ob), C(olin), and D(onna) and they are sitting in a row ABCD.  One possible outcome is ABDC (1st exam goes to A, 2nd to B, 3rd to D, 4th to C).  In that case, what does X equal?

* List out all possible outcomes.  And for each outcome, determine what X equals.  

* Why is P(X = 3) = 0?

* Write out the probability distribution for X.

* Determine the mean value of X. 

* Determine the standard deviation of X.

* What is the probability that at least one student gets their correct exam?



