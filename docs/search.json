[
  {
    "objectID": "stat100_wk05mon.html#announcements",
    "href": "stat100_wk05mon.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nDiscuss exams:\n\nRegistrar’s Office posted our Final Exam time:\n\nIn-class: Fri, Dec 15th 9am - noon\nOral: Wed, Dec 13th & Thurs, Dec 14th\n\nMidterm next week\n\nIn-class: Wed, Oct 11th 10:30 - 11:15 11:45am\nOral: Wed afternoon - Fri, Oct 13th\nNo sections during midterm exam week!\n\n\n\nGoals for Today\n\nDiscus data ethics: responsibilities to research subjects\nFinish up data collection"
  },
  {
    "objectID": "stat100_wk05mon.html#responsibilities-to-research-subjects",
    "href": "stat100_wk05mon.html#responsibilities-to-research-subjects",
    "title": "Stat 100",
    "section": "Responsibilities to Research Subjects",
    "text": "Responsibilities to Research Subjects\n\n“The ethical statistician protects and respects the rights and interests of human and animal subjects at all stages of their involvement in a project. This includes respondents to the census or to surveys, those whose data are contained in administrative records, and subjects of physically or psychologically invasive research.”"
  },
  {
    "objectID": "stat100_wk05mon.html#detour-from-our-detour",
    "href": "stat100_wk05mon.html#detour-from-our-detour",
    "title": "Stat 100",
    "section": "Detour from Our Detour",
    "text": "Detour from Our Detour\n\n\nlibrary(tidyverse)\nlibrary(NHANES)\n\nggplot(data = NHANES, \n       mapping = aes(x = Age,\n                     y = Height)) +\n  geom_point(alpha = 0.1) +\n  geom_smooth(color = \"skyblue\")"
  },
  {
    "objectID": "stat100_wk05mon.html#detour-from-our-detour-1",
    "href": "stat100_wk05mon.html#detour-from-our-detour-1",
    "title": "Stat 100",
    "section": "Detour from Our Detour",
    "text": "Detour from Our Detour\n\n\nlibrary(tidyverse)\nlibrary(NHANES)\nlibrary(emojifont)\n\nNHANES &lt;- mutate(NHANES, \n          heart = fontawesome(\"fa-pumpkin\"))\n\nggplot(data = NHANES, \n       mapping = aes(x = Age,\n                     y = Height,\n                     label = heart)) +\n  geom_text(alpha = 0.1, color = \"red\",\n            family='fontawesome-webfont',\n            size = 16) +\n  stat_smooth(color = \"deeppink\")"
  },
  {
    "objectID": "stat100_wk05mon.html#who-are-the-data-supposed-to-represent",
    "href": "stat100_wk05mon.html#who-are-the-data-supposed-to-represent",
    "title": "Stat 100",
    "section": "Who are the data supposed to represent?",
    "text": "Who are the data supposed to represent?"
  },
  {
    "objectID": "stat100_wk05mon.html#who-are-the-data-supposed-to-represent-1",
    "href": "stat100_wk05mon.html#who-are-the-data-supposed-to-represent-1",
    "title": "Stat 100",
    "section": "Who are the data supposed to represent?",
    "text": "Who are the data supposed to represent?\n\n\n\n\n\nKey questions:\n\nWhat evidence is there that the respondents are representative of the population?\nWho is present? Who is absent?\nWho is overrepresented? Who is underrepresented?"
  },
  {
    "objectID": "stat100_wk05mon.html#nonresponse-bias",
    "href": "stat100_wk05mon.html#nonresponse-bias",
    "title": "Stat 100",
    "section": "Nonresponse bias",
    "text": "Nonresponse bias\n\n\n\n\n\nNonresponse bias: The respondents are systematically different from the non-respondents for the variables of interest."
  },
  {
    "objectID": "stat100_wk05mon.html#tackling-nonresponse-bias",
    "href": "stat100_wk05mon.html#tackling-nonresponse-bias",
    "title": "Stat 100",
    "section": "Tackling Nonresponse bias",
    "text": "Tackling Nonresponse bias\n\n\n\n\n\n\nUse multiple modes (mail, phone, in-person) and multiple attempts for reaching sampled cases.\nExplore key demographic variables to see how respondents and non-respondents vary.\nTake a survey stats course to learn how to create survey weights to adjust for potential nonresponse bias."
  },
  {
    "objectID": "stat100_wk05mon.html#is-bigger-always-better",
    "href": "stat100_wk05mon.html#is-bigger-always-better",
    "title": "Stat 100",
    "section": "Is Bigger Always Better?",
    "text": "Is Bigger Always Better?\n\n\n\n\n\nFor our Literary Digest Example, Gallup predicted Roosevelt would win based on a survey of 50,000 people (instead of 2.4 million)."
  },
  {
    "objectID": "stat100_wk05mon.html#thoughts-on-sampling",
    "href": "stat100_wk05mon.html#thoughts-on-sampling",
    "title": "Stat 100",
    "section": "Thoughts on Sampling",
    "text": "Thoughts on Sampling\n\nRandom sampling is important to ensure the sample is representative of the population.\n\nWord we will use: generalizability\n\nRepresentativeness isn’t about size.\n\nSmall random samples will tend to be more representative than large non-random samples.\n\nHowever, I bet most samples you will encounter won’t have arisen from a random mechanism.\nHow do we draw conclusions about the population from non-random samples?\n\nDeterminee if your sampled cases (and respondents) are systematically different from the non-sampled cases (and non-respondents) for the variables you care about.\nAdjust your population of interest.\nTake a survey stats course to learn how to adjust the sample to make it more representative."
  },
  {
    "objectID": "stat100_wk05mon.html#careful-with-non-random-assignment-data",
    "href": "stat100_wk05mon.html#careful-with-non-random-assignment-data",
    "title": "Stat 100",
    "section": "Careful with Non-Random Assignment Data",
    "text": "Careful with Non-Random Assignment Data\n\n\nWe have data on the number of Methodist ministers in New England and the number of barrels of rum imported into Boston each year. The data range from 1860 to 1940.\n\nShould we conclude that ministers drink a lot of rum? Or maybe that rum drinking encourages church attendance?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfounding variable: A third variable that is associated with both the explanatory variable and the response variable.\nUnclear if the explanatory variable or the confounder (or some other variable) is causing changes in the response."
  },
  {
    "objectID": "stat100_wk05mon.html#causal-inference",
    "href": "stat100_wk05mon.html#causal-inference",
    "title": "Stat 100",
    "section": "Causal Inference",
    "text": "Causal Inference\n\nSpurious relationship: Two variables are associated but not causally related\n\nIn the age of big data, lots of good examples out there.\n\n\n\n→ “Correlation does not imply causation.”\n\n\n→ “Correlation does not imply not causation.”\n\n\nCausal inference: Methods for finding causal relationships even when the data were collected without random assignment."
  },
  {
    "objectID": "stat100_wk05mon.html#observational-studies",
    "href": "stat100_wk05mon.html#observational-studies",
    "title": "Stat 100",
    "section": "Observational Studies",
    "text": "Observational Studies\n\nA study in which the researchers don’t actively control the value of any variable, but simply observe the values as they naturally exist.\nExample: Hand washing study\n\nTo estimate what percent of people in the US wash their hands after using a public restroom, researchers pretended to comb their hair while observing 6000 people in public restrooms throughout the United States. They found that 85% of the people who were observed washed their hands after going to the bathroom."
  },
  {
    "objectID": "stat100_wk05mon.html#randomized-experiment",
    "href": "stat100_wk05mon.html#randomized-experiment",
    "title": "Stat 100",
    "section": "(Randomized) Experiment",
    "text": "(Randomized) Experiment\n\nA study in which the researcher actively controls one or more of the explanatory variables through random assignment.\nExample: COVID Trial\nCommon features:\n\nControl group that gets no treatment or a standard treatment\nPlacebo: A fake treatment to control for the placebo effect where if people believe they are receiving a treatment, they may experience the desired effect regardless of whether the treatment is any good.\nBlinding: When the subjects and/or researchers don’t know the explanatory group assignments."
  },
  {
    "objectID": "stat100_wk05mon.html#thoughts-on-data-collection-goals",
    "href": "stat100_wk05mon.html#thoughts-on-data-collection-goals",
    "title": "Stat 100",
    "section": "Thoughts on Data Collection Goals",
    "text": "Thoughts on Data Collection Goals\n\nRandom assignment allows you to explore causal relationships between your explanatory variables and the predictor variables because the randomization makes the explanatory groups roughly similar.\nHow do we draw causal conclusions from studies without random assignment?\n\nWith extreme care! Try to control for all possible confounding variables.\nDiscuss the associations/correlations you found. Use domain knowledge to address potentially causal links.\nTake more stats to learn more about causal inference.\n\nBut also consider the goals of your analysis. Often the research question isn’t causal.\n\nBottom Line: We often have to use imperfect data to make decisions."
  },
  {
    "objectID": "stat100_wk05mon.html#reminders",
    "href": "stat100_wk05mon.html#reminders",
    "title": "Stat 100",
    "section": "Reminders",
    "text": "Reminders\n\nDiscuss exams:\n\nRegistrar’s Office posted our Final Exam time:\n\nIn-class: Fri, Dec 15th 9am - noon\nOral: Wed, Dec 13th & Thurs, Dec 14th\n\nMidterm next week\n\nIn-class: Wed, Oct 11th 10:30 - 11:15 11:45am\nOral: Wed afternoon - Fri, Oct 13th\nNo sections during midterm exam week!"
  },
  {
    "objectID": "stat100_wk03mon.html#announcements",
    "href": "stat100_wk03mon.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nWith COVID working its way through campus right now, make sure to check the Sections spreadsheet and the Office hours spreadsheet for updates!\nGrab a postcard and/or a stamp from SC 316 if you lost yours.\n\nWe also have markers, colored pencils, and crayons!\n\nDon’t forget that P-Set 1 due on Tuesday by 5pm in Gradescope.\nCome by office hours with any questions."
  },
  {
    "objectID": "stat100_wk03mon.html#goals-for-today",
    "href": "stat100_wk03mon.html#goals-for-today",
    "title": "Stat 100",
    "section": "Goals for Today",
    "text": "Goals for Today\n\n\n\nCome back to the general structure of ggplot2.\nLearn a few standard graphs for numerical/quantitative data:\n\nHistogram: one numerical variable\nSide-by-side boxplot: one numerical variable and one categorical variable\nSide-by-side violin plot: one numerical variable and one categorical variable\nScatterplot: two numerical variables\nLinegraph: two numerical variables\n\n\n\n\nAnd, learn the standard graphic for categorical data:\n\nBarplot: one categorical variable\nSegmented barplot: two categorical variables\n\nAlso cover some common extensions and customizations."
  },
  {
    "objectID": "stat100_wk03mon.html#load-necessary-packages",
    "href": "stat100_wk03mon.html#load-necessary-packages",
    "title": "Stat 100",
    "section": "Load Necessary Packages",
    "text": "Load Necessary Packages\n\n\n\n\n\nggplot2 is part of this collection of data science packages.\n\n# Load necessary packages\nlibrary(tidyverse)"
  },
  {
    "objectID": "stat100_wk03mon.html#data-setting-eco-totem-broadway-bicycle-count",
    "href": "stat100_wk03mon.html#data-setting-eco-totem-broadway-bicycle-count",
    "title": "Stat 100",
    "section": "Data Setting: Eco-Totem Broadway Bicycle Count",
    "text": "Data Setting: Eco-Totem Broadway Bicycle Count"
  },
  {
    "objectID": "stat100_wk03mon.html#import-the-data",
    "href": "stat100_wk03mon.html#import-the-data",
    "title": "Stat 100",
    "section": "Import the Data",
    "text": "Import the Data\n\njuly_2019 &lt;- read_csv(\"data/july_2019.csv\")\n\n# Inspect the data\nglimpse(july_2019)\n\nRows: 192\nColumns: 8\n$ DateTime  &lt;chr&gt; \"07/04/2019 12:00:00 AM\", \"07/04/2019 12:15:00 AM\", \"07/04/2…\n$ Day       &lt;chr&gt; \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\", …\n$ Date      &lt;date&gt; 2019-07-04, 2019-07-04, 2019-07-04, 2019-07-04, 2019-07-04,…\n$ Time      &lt;time&gt; 00:00:00, 00:15:00, 00:30:00, 00:45:00, 01:00:00, 01:15:00,…\n$ Total     &lt;dbl&gt; 2, 3, 2, 0, 3, 2, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, …\n$ Westbound &lt;dbl&gt; 2, 3, 1, 0, 2, 2, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, …\n$ Eastbound &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ Occasion  &lt;chr&gt; \"Fourth of July\", \"Fourth of July\", \"Fourth of July\", \"Fourt…"
  },
  {
    "objectID": "stat100_wk03mon.html#ggplot2-example-code",
    "href": "stat100_wk03mon.html#ggplot2-example-code",
    "title": "Stat 100",
    "section": "ggplot2 example code",
    "text": "ggplot2 example code\nGuiding Principle: We will map variables from the data to the aesthetic attributes (e.g. location, size, shape, color) of geometric objects (e.g. points, lines, bars).\n\n\nggplot(data = ---, mapping = aes(---)) +\n  geom_---(---) \n\n\nThere are other layers, such as scales_---_---() and labs(), but we will wait on those."
  },
  {
    "objectID": "stat100_wk03mon.html#histograms",
    "href": "stat100_wk03mon.html#histograms",
    "title": "Stat 100",
    "section": "Histograms",
    "text": "Histograms\n\n\n# Create histogram\nggplot(data = july_2019, \n       mapping = aes(x = Total)) +\n  geom_histogram()"
  },
  {
    "objectID": "stat100_wk03mon.html#histograms-1",
    "href": "stat100_wk03mon.html#histograms-1",
    "title": "Stat 100",
    "section": "Histograms",
    "text": "Histograms\n\n\n# Create histogram\nggplot(data = july_2019, \n       mapping = aes(x = Total)) +\n  geom_histogram(color = \"white\",\n                 fill = \"violetred1\",\n                 bins = 50)\n\n\n\n\n\n\n\n\n\n\n\nmapping to a variable goes in aes()\nsetting to a specific value goes in the geom_---()"
  },
  {
    "objectID": "stat100_wk03mon.html#boxplots",
    "href": "stat100_wk03mon.html#boxplots",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\n\nFive number summary:\n\nMinimum\nFirst quartile (Q1)\nMedian\nThird quartile (Q3)\nMaximum\n\nInterquartile range (IQR) \\(=\\) Q3 \\(-\\) Q1\nOutliers: unusual points\n\nBoxplot defines unusual as being beyond \\(1.5*IQR\\) from \\(Q1\\) or \\(Q3\\).\n\nWhiskers: reach out to the furthest point that is NOT an outlier"
  },
  {
    "objectID": "stat100_wk03mon.html#boxplots-1",
    "href": "stat100_wk03mon.html#boxplots-1",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\n# Create boxplot\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total)) +\n  geom_boxplot()"
  },
  {
    "objectID": "stat100_wk03mon.html#boxplots-2",
    "href": "stat100_wk03mon.html#boxplots-2",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total)) +\n  geom_boxplot(fill = \"springgreen3\")"
  },
  {
    "objectID": "stat100_wk03mon.html#boxplots-3",
    "href": "stat100_wk03mon.html#boxplots-3",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total,\n                     fill = Total)) +\n  geom_boxplot()"
  },
  {
    "objectID": "stat100_wk03mon.html#boxplots-4",
    "href": "stat100_wk03mon.html#boxplots-4",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total,\n                     fill = Occasion)) +\n  geom_boxplot() +\n  guides(fill = \"none\")"
  },
  {
    "objectID": "stat100_wk03mon.html#violin-plots",
    "href": "stat100_wk03mon.html#violin-plots",
    "title": "Stat 100",
    "section": "Violin Plots",
    "text": "Violin Plots\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total,\n                     fill = Occasion)) +\n  geom_violin() +\n  guides(fill = \"none\")"
  },
  {
    "objectID": "stat100_wk03mon.html#boxplot-versus-violin-plots",
    "href": "stat100_wk03mon.html#boxplot-versus-violin-plots",
    "title": "Stat 100",
    "section": "Boxplot Versus Violin Plots",
    "text": "Boxplot Versus Violin Plots"
  },
  {
    "objectID": "stat100_wk03mon.html#scatterplots",
    "href": "stat100_wk03mon.html#scatterplots",
    "title": "Stat 100",
    "section": "Scatterplots",
    "text": "Scatterplots\n\nExplore relationships between numerical variables.\n\nWe will be especially interested in linear relationships.\n\n\n\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total)) +\n  geom_point(size = 2)"
  },
  {
    "objectID": "stat100_wk03mon.html#scatterplots-1",
    "href": "stat100_wk03mon.html#scatterplots-1",
    "title": "Stat 100",
    "section": "Scatterplots",
    "text": "Scatterplots\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total)) +\n  geom_point(size = 2, alpha = 0.6)\n\n\n\n\n\n\n\n\n\n\n\nFix over-plotting\nWhy the weird pattern??"
  },
  {
    "objectID": "stat100_wk03mon.html#scatterplots-2",
    "href": "stat100_wk03mon.html#scatterplots-2",
    "title": "Stat 100",
    "section": "Scatterplots",
    "text": "Scatterplots\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total,\n                     color = Occasion)) +\n  geom_point(size = 2, alpha = 0.6)"
  },
  {
    "objectID": "stat100_wk03mon.html#linegraphs",
    "href": "stat100_wk03mon.html#linegraphs",
    "title": "Stat 100",
    "section": "Linegraphs",
    "text": "Linegraphs\nAlso called time series plot when time is represented on the x axis.\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total,\n                     color = Occasion)) +\n  geom_line(alpha = 0.6)"
  },
  {
    "objectID": "stat100_wk03mon.html#linegraphs-1",
    "href": "stat100_wk03mon.html#linegraphs-1",
    "title": "Stat 100",
    "section": "Linegraphs",
    "text": "Linegraphs\nAlso called time series plot when time is represented on the x axis.\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total,\n                     color = Occasion)) +\n  geom_line(alpha = 0.6) +\n  theme(legend.pos = \"bottom\")"
  },
  {
    "objectID": "stat100_wk03mon.html#new-data-setting-dog-names-in-cambridge-ma",
    "href": "stat100_wk03mon.html#new-data-setting-dog-names-in-cambridge-ma",
    "title": "Stat 100",
    "section": "New Data Setting: Dog Names in Cambridge, MA",
    "text": "New Data Setting: Dog Names in Cambridge, MA\nBased on dog license data collected by Cambridge’s Animal Commission\n\n# Import and inspect data\ndogs &lt;- read_csv(\"https://data.cambridgema.gov/api/views/sckh-3xyx/rows.csv\")\nglimpse(dogs)\n\nRows: 3,942\nColumns: 6\n$ Dog_Name         &lt;chr&gt; \"Butch\", \"Baxter\", \"Bodhi\", \"Ocean\", \"Coco\", \"Brio\", …\n$ Dog_Breed        &lt;chr&gt; \"Mixed Breed\", \"Mixed Breed\", \"Golden Retriever\", \"Pu…\n$ Location_masked  &lt;chr&gt; \"POINT (-71.1328 42.3989)\", \"POINT (-71.1186 42.3814)…\n$ Latitude_masked  &lt;dbl&gt; 42.3989, 42.3814, 42.3998, 42.3726, 42.3610, 42.3892,…\n$ Longitude_masked &lt;dbl&gt; -71.1328, -71.1186, -71.1308, -71.1087, -71.1022, -71…\n$ Neighborhood     &lt;chr&gt; \"North Cambridge\", \"Neighborhood Nine\", \"North Cambri…"
  },
  {
    "objectID": "stat100_wk03mon.html#data-wrangling",
    "href": "stat100_wk03mon.html#data-wrangling",
    "title": "Stat 100",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nWe haven’t learned this topic yet.\nI only included this code for completeness/transparency.\n\n# Create a column for Breed\ndogs &lt;- mutate(dogs, Breed = if_else(\n                       Dog_Breed == \"Mixed Breed\",\n                       \"Mixed\", \"Single\"))\n\n\n# Find the 5 top most common names\ntop5names &lt;- count(dogs, Dog_Name) %&gt;%\n  slice_max(n = 5, order_by = n) %&gt;%\n  select(Dog_Name) %&gt;%\n  pull()\n  \n# Filter dataset to only the 5 top most common names\ndogs_top5 &lt;- filter(dogs,\n                     Dog_Name %in% top5names)"
  },
  {
    "objectID": "stat100_wk03mon.html#barplots",
    "href": "stat100_wk03mon.html#barplots",
    "title": "Stat 100",
    "section": "Barplots",
    "text": "Barplots\n\n\nDisplays the frequency for each category."
  },
  {
    "objectID": "stat100_wk03mon.html#barplots-1",
    "href": "stat100_wk03mon.html#barplots-1",
    "title": "Stat 100",
    "section": "Barplots",
    "text": "Barplots\n\n\n# Create barplot\nggplot(data = dogs_top5, \n    mapping = aes(x = Dog_Name)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nHow could we make this graph better?"
  },
  {
    "objectID": "stat100_wk03mon.html#barplots-2",
    "href": "stat100_wk03mon.html#barplots-2",
    "title": "Stat 100",
    "section": "Barplots",
    "text": "Barplots\n\n\n# Create barplot\nggplot(data = dogs_top5, \n  mapping = aes(x = fct_infreq(Dog_Name))) +\n  geom_bar()"
  },
  {
    "objectID": "stat100_wk03mon.html#segmented-barplots",
    "href": "stat100_wk03mon.html#segmented-barplots",
    "title": "Stat 100",
    "section": "Segmented Barplots",
    "text": "Segmented Barplots\n\n\n# Create segmented barplot\nggplot(data = dogs_top5, \n       mapping = aes(x = fct_infreq(Dog_Name),\n                     fill = Breed)) +\n  geom_bar() +\n  theme(legend.pos = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nEach bar is divided into the frequencies of the fill variable.\nHard to make comparisons across categories."
  },
  {
    "objectID": "stat100_wk03mon.html#segmented-barplots-1",
    "href": "stat100_wk03mon.html#segmented-barplots-1",
    "title": "Stat 100",
    "section": "Segmented Barplots",
    "text": "Segmented Barplots\n\n\n# Create segmented barplot\nggplot(data = dogs_top5, \n       mapping = aes(x = fct_infreq(Dog_Name),\n                     fill = Breed)) +\n  geom_bar(position = \"dodge\") +\n  theme(legend.pos = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nCan add the position argument into the geom_bar()."
  },
  {
    "objectID": "stat100_wk03mon.html#segmented-barplots-2",
    "href": "stat100_wk03mon.html#segmented-barplots-2",
    "title": "Stat 100",
    "section": "Segmented Barplots",
    "text": "Segmented Barplots\n\n\n# Create segmented barplot\nggplot(data = dogs_top5, \n       mapping = aes(x = fct_infreq(Dog_Name),\n                     fill = Breed)) +\n  geom_bar(position = \"fill\") +\n  theme(legend.pos = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nNow each bar is divided into proportions based on the fill variable."
  },
  {
    "objectID": "stat100_wk03mon.html#adding-more-variables",
    "href": "stat100_wk03mon.html#adding-more-variables",
    "title": "Stat 100",
    "section": "Adding More Variables",
    "text": "Adding More Variables\n\nTwo main approaches:\n\nUtilize other aesthetics of the geom\nFacet: Create multiple plots across the categories of a categorical variable."
  },
  {
    "objectID": "stat100_wk03mon.html#utilize-other-aesthetics",
    "href": "stat100_wk03mon.html#utilize-other-aesthetics",
    "title": "Stat 100",
    "section": "Utilize other aesthetics",
    "text": "Utilize other aesthetics\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total,\n                     color = Occasion)) +\n  geom_line(size = 2) +\n  theme(legend.pos = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nAlready saw how to add a third variable to a line graph (and a scatterplot) via color.\n\nCan also change size or type."
  },
  {
    "objectID": "stat100_wk03mon.html#facet",
    "href": "stat100_wk03mon.html#facet",
    "title": "Stat 100",
    "section": "Facet",
    "text": "Facet\n\n\nggplot(data = dogs_top5,\n       mapping = aes(x = Longitude_masked,\n                     y = Latitude_masked)) +\n  geom_point(size = 2) +\n  facet_wrap(~Dog_Name, ncol = 2)"
  },
  {
    "objectID": "stat100_wk03mon.html#facet-1",
    "href": "stat100_wk03mon.html#facet-1",
    "title": "Stat 100",
    "section": "Facet",
    "text": "Facet\n\n\nggplot(data = dogs_top5,\n       mapping = aes(x = Longitude_masked,\n                     y = Latitude_masked)) +\n  geom_point(size = 2)  +\n  facet_grid(Breed~Dog_Name)"
  },
  {
    "objectID": "stat100_wk03mon.html#consider-doing-both",
    "href": "stat100_wk03mon.html#consider-doing-both",
    "title": "Stat 100",
    "section": "Consider Doing Both!",
    "text": "Consider Doing Both!\n\n\nggplot(data = dogs_top5,\n       mapping = aes(x = Longitude_masked,\n                     y = Latitude_masked,\n                     color = Breed)) +\n  geom_point(size = 2) +\n  facet_wrap(~Dog_Name, ncol = 2)"
  },
  {
    "objectID": "stat100_wk03mon.html#adding-some-context",
    "href": "stat100_wk03mon.html#adding-some-context",
    "title": "Stat 100",
    "section": "Adding Some Context",
    "text": "Adding Some Context\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total,\n                     color = Occasion)) +\n  geom_line(size = 2) +\n  theme(legend.pos = \"bottom\") +\n  labs(x = \"Time of Day\",\n       y = \"Number of Passes\",\n       color = \"What Type of Day?\",\n       caption = \"Data Collected by Eco-Totem\",\n       title = \"Cycling Patterns at Broadway Bike Counter\")"
  },
  {
    "objectID": "stat100_wk03mon.html#customizing-your-ggplot2-plots",
    "href": "stat100_wk03mon.html#customizing-your-ggplot2-plots",
    "title": "Stat 100",
    "section": "Customizing your ggplot2 Plots",
    "text": "Customizing your ggplot2 Plots\n\nThere are so many ways you can customize the look of your ggplot2 plots.\nLet’s look at some common changes:\n\nFussing with labels\nZooming in\nUsing multiple geoms\nColor!\nThemes"
  },
  {
    "objectID": "stat100_wk03mon.html#fussing-with-labels-rotate",
    "href": "stat100_wk03mon.html#fussing-with-labels-rotate",
    "title": "Stat 100",
    "section": "Fussing with Labels: Rotate",
    "text": "Fussing with Labels: Rotate\n\n\nggplot(data = dogs_top5,\n       mapping = aes(x = Longitude_masked,\n                     y = Latitude_masked)) +\n  geom_point(size = 2)  +\n  facet_grid(Breed~Dog_Name) + \n  theme(axis.text.x =\n          element_text(angle = 45,\n                       vjust = 1,\n                       hjust = 1))"
  },
  {
    "objectID": "stat100_wk03mon.html#zooming-in",
    "href": "stat100_wk03mon.html#zooming-in",
    "title": "Stat 100",
    "section": "Zooming In",
    "text": "Zooming In\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total,\n                     fill = Occasion)) +\n  geom_boxplot() +\n  guides(fill = \"none\")"
  },
  {
    "objectID": "stat100_wk03mon.html#zooming-in-1",
    "href": "stat100_wk03mon.html#zooming-in-1",
    "title": "Stat 100",
    "section": "Zooming In",
    "text": "Zooming In\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total)) +\n  geom_boxplot(fill = \"springgreen2\") +\n  guides(fill = \"none\") +\n  coord_cartesian(ylim = c(0, 40))  +\n  scale_fill_manual()"
  },
  {
    "objectID": "stat100_wk03mon.html#multiple-geoms",
    "href": "stat100_wk03mon.html#multiple-geoms",
    "title": "Stat 100",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total,\n                     fill = Occasion)) +\n  geom_boxplot() +\n  guides(fill = \"none\") +\n  coord_cartesian(ylim = c(0, 40)) +\n  geom_jitter(width = 0.1,\n              height = 0, \n              alpha = 0.6)"
  },
  {
    "objectID": "stat100_wk03mon.html#multiple-geoms-1",
    "href": "stat100_wk03mon.html#multiple-geoms-1",
    "title": "Stat 100",
    "section": "Multiple geoms",
    "text": "Multiple geoms\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total,\n                     color = Occasion)) +\n  geom_line(size = 2) +\n  theme(legend.pos = \"bottom\") +\n  geom_point(size = 3)"
  },
  {
    "objectID": "stat100_wk03mon.html#change-the-color",
    "href": "stat100_wk03mon.html#change-the-color",
    "title": "Stat 100",
    "section": "Change the Color",
    "text": "Change the Color\n\ncolors()\n\n  [1] \"white\"                \"aliceblue\"            \"antiquewhite\"        \n  [4] \"antiquewhite1\"        \"antiquewhite2\"        \"antiquewhite3\"       \n  [7] \"antiquewhite4\"        \"aquamarine\"           \"aquamarine1\"         \n [10] \"aquamarine2\"          \"aquamarine3\"          \"aquamarine4\"         \n [13] \"azure\"                \"azure1\"               \"azure2\"              \n [16] \"azure3\"               \"azure4\"               \"beige\"               \n [19] \"bisque\"               \"bisque1\"              \"bisque2\"             \n [22] \"bisque3\"              \"bisque4\"              \"black\"               \n [25] \"blanchedalmond\"       \"blue\"                 \"blue1\"               \n [28] \"blue2\"                \"blue3\"                \"blue4\"               \n [31] \"blueviolet\"           \"brown\"                \"brown1\"              \n [34] \"brown2\"               \"brown3\"               \"brown4\"              \n [37] \"burlywood\"            \"burlywood1\"           \"burlywood2\"          \n [40] \"burlywood3\"           \"burlywood4\"           \"cadetblue\"           \n [43] \"cadetblue1\"           \"cadetblue2\"           \"cadetblue3\"          \n [46] \"cadetblue4\"           \"chartreuse\"           \"chartreuse1\"         \n [49] \"chartreuse2\"          \"chartreuse3\"          \"chartreuse4\"         \n [52] \"chocolate\"            \"chocolate1\"           \"chocolate2\"          \n [55] \"chocolate3\"           \"chocolate4\"           \"coral\"               \n [58] \"coral1\"               \"coral2\"               \"coral3\"              \n [61] \"coral4\"               \"cornflowerblue\"       \"cornsilk\"            \n [64] \"cornsilk1\"            \"cornsilk2\"            \"cornsilk3\"           \n [67] \"cornsilk4\"            \"cyan\"                 \"cyan1\"               \n [70] \"cyan2\"                \"cyan3\"                \"cyan4\"               \n [73] \"darkblue\"             \"darkcyan\"             \"darkgoldenrod\"       \n [76] \"darkgoldenrod1\"       \"darkgoldenrod2\"       \"darkgoldenrod3\"      \n [79] \"darkgoldenrod4\"       \"darkgray\"             \"darkgreen\"           \n [82] \"darkgrey\"             \"darkkhaki\"            \"darkmagenta\"         \n [85] \"darkolivegreen\"       \"darkolivegreen1\"      \"darkolivegreen2\"     \n [88] \"darkolivegreen3\"      \"darkolivegreen4\"      \"darkorange\"          \n [91] \"darkorange1\"          \"darkorange2\"          \"darkorange3\"         \n [94] \"darkorange4\"          \"darkorchid\"           \"darkorchid1\"         \n [97] \"darkorchid2\"          \"darkorchid3\"          \"darkorchid4\"         \n[100] \"darkred\"              \"darksalmon\"           \"darkseagreen\"        \n[103] \"darkseagreen1\"        \"darkseagreen2\"        \"darkseagreen3\"       \n[106] \"darkseagreen4\"        \"darkslateblue\"        \"darkslategray\"       \n[109] \"darkslategray1\"       \"darkslategray2\"       \"darkslategray3\"      \n[112] \"darkslategray4\"       \"darkslategrey\"        \"darkturquoise\"       \n[115] \"darkviolet\"           \"deeppink\"             \"deeppink1\"           \n[118] \"deeppink2\"            \"deeppink3\"            \"deeppink4\"           \n[121] \"deepskyblue\"          \"deepskyblue1\"         \"deepskyblue2\"        \n[124] \"deepskyblue3\"         \"deepskyblue4\"         \"dimgray\"             \n[127] \"dimgrey\"              \"dodgerblue\"           \"dodgerblue1\"         \n[130] \"dodgerblue2\"          \"dodgerblue3\"          \"dodgerblue4\"         \n[133] \"firebrick\"            \"firebrick1\"           \"firebrick2\"          \n[136] \"firebrick3\"           \"firebrick4\"           \"floralwhite\"         \n[139] \"forestgreen\"          \"gainsboro\"            \"ghostwhite\"          \n[142] \"gold\"                 \"gold1\"                \"gold2\"               \n[145] \"gold3\"                \"gold4\"                \"goldenrod\"           \n[148] \"goldenrod1\"           \"goldenrod2\"           \"goldenrod3\"          \n[151] \"goldenrod4\"           \"gray\"                 \"gray0\"               \n[154] \"gray1\"                \"gray2\"                \"gray3\"               \n[157] \"gray4\"                \"gray5\"                \"gray6\"               \n[160] \"gray7\"                \"gray8\"                \"gray9\"               \n[163] \"gray10\"               \"gray11\"               \"gray12\"              \n[166] \"gray13\"               \"gray14\"               \"gray15\"              \n[169] \"gray16\"               \"gray17\"               \"gray18\"              \n[172] \"gray19\"               \"gray20\"               \"gray21\"              \n[175] \"gray22\"               \"gray23\"               \"gray24\"              \n[178] \"gray25\"               \"gray26\"               \"gray27\"              \n[181] \"gray28\"               \"gray29\"               \"gray30\"              \n[184] \"gray31\"               \"gray32\"               \"gray33\"              \n[187] \"gray34\"               \"gray35\"               \"gray36\"              \n[190] \"gray37\"               \"gray38\"               \"gray39\"              \n[193] \"gray40\"               \"gray41\"               \"gray42\"              \n[196] \"gray43\"               \"gray44\"               \"gray45\"              \n[199] \"gray46\"               \"gray47\"               \"gray48\"              \n[202] \"gray49\"               \"gray50\"               \"gray51\"              \n[205] \"gray52\"               \"gray53\"               \"gray54\"              \n[208] \"gray55\"               \"gray56\"               \"gray57\"              \n[211] \"gray58\"               \"gray59\"               \"gray60\"              \n[214] \"gray61\"               \"gray62\"               \"gray63\"              \n[217] \"gray64\"               \"gray65\"               \"gray66\"              \n[220] \"gray67\"               \"gray68\"               \"gray69\"              \n[223] \"gray70\"               \"gray71\"               \"gray72\"              \n[226] \"gray73\"               \"gray74\"               \"gray75\"              \n[229] \"gray76\"               \"gray77\"               \"gray78\"              \n[232] \"gray79\"               \"gray80\"               \"gray81\"              \n[235] \"gray82\"               \"gray83\"               \"gray84\"              \n[238] \"gray85\"               \"gray86\"               \"gray87\"              \n[241] \"gray88\"               \"gray89\"               \"gray90\"              \n[244] \"gray91\"               \"gray92\"               \"gray93\"              \n[247] \"gray94\"               \"gray95\"               \"gray96\"              \n[250] \"gray97\"               \"gray98\"               \"gray99\"              \n[253] \"gray100\"              \"green\"                \"green1\"              \n[256] \"green2\"               \"green3\"               \"green4\"              \n[259] \"greenyellow\"          \"grey\"                 \"grey0\"               \n[262] \"grey1\"                \"grey2\"                \"grey3\"               \n[265] \"grey4\"                \"grey5\"                \"grey6\"               \n[268] \"grey7\"                \"grey8\"                \"grey9\"               \n[271] \"grey10\"               \"grey11\"               \"grey12\"              \n[274] \"grey13\"               \"grey14\"               \"grey15\"              \n[277] \"grey16\"               \"grey17\"               \"grey18\"              \n[280] \"grey19\"               \"grey20\"               \"grey21\"              \n[283] \"grey22\"               \"grey23\"               \"grey24\"              \n[286] \"grey25\"               \"grey26\"               \"grey27\"              \n[289] \"grey28\"               \"grey29\"               \"grey30\"              \n[292] \"grey31\"               \"grey32\"               \"grey33\"              \n[295] \"grey34\"               \"grey35\"               \"grey36\"              \n[298] \"grey37\"               \"grey38\"               \"grey39\"              \n[301] \"grey40\"               \"grey41\"               \"grey42\"              \n[304] \"grey43\"               \"grey44\"               \"grey45\"              \n[307] \"grey46\"               \"grey47\"               \"grey48\"              \n[310] \"grey49\"               \"grey50\"               \"grey51\"              \n[313] \"grey52\"               \"grey53\"               \"grey54\"              \n[316] \"grey55\"               \"grey56\"               \"grey57\"              \n[319] \"grey58\"               \"grey59\"               \"grey60\"              \n[322] \"grey61\"               \"grey62\"               \"grey63\"              \n[325] \"grey64\"               \"grey65\"               \"grey66\"              \n[328] \"grey67\"               \"grey68\"               \"grey69\"              \n[331] \"grey70\"               \"grey71\"               \"grey72\"              \n[334] \"grey73\"               \"grey74\"               \"grey75\"              \n[337] \"grey76\"               \"grey77\"               \"grey78\"              \n[340] \"grey79\"               \"grey80\"               \"grey81\"              \n[343] \"grey82\"               \"grey83\"               \"grey84\"              \n[346] \"grey85\"               \"grey86\"               \"grey87\"              \n[349] \"grey88\"               \"grey89\"               \"grey90\"              \n[352] \"grey91\"               \"grey92\"               \"grey93\"              \n[355] \"grey94\"               \"grey95\"               \"grey96\"              \n[358] \"grey97\"               \"grey98\"               \"grey99\"              \n[361] \"grey100\"              \"honeydew\"             \"honeydew1\"           \n[364] \"honeydew2\"            \"honeydew3\"            \"honeydew4\"           \n[367] \"hotpink\"              \"hotpink1\"             \"hotpink2\"            \n[370] \"hotpink3\"             \"hotpink4\"             \"indianred\"           \n[373] \"indianred1\"           \"indianred2\"           \"indianred3\"          \n[376] \"indianred4\"           \"ivory\"                \"ivory1\"              \n[379] \"ivory2\"               \"ivory3\"               \"ivory4\"              \n[382] \"khaki\"                \"khaki1\"               \"khaki2\"              \n[385] \"khaki3\"               \"khaki4\"               \"lavender\"            \n[388] \"lavenderblush\"        \"lavenderblush1\"       \"lavenderblush2\"      \n[391] \"lavenderblush3\"       \"lavenderblush4\"       \"lawngreen\"           \n[394] \"lemonchiffon\"         \"lemonchiffon1\"        \"lemonchiffon2\"       \n[397] \"lemonchiffon3\"        \"lemonchiffon4\"        \"lightblue\"           \n[400] \"lightblue1\"           \"lightblue2\"           \"lightblue3\"          \n[403] \"lightblue4\"           \"lightcoral\"           \"lightcyan\"           \n[406] \"lightcyan1\"           \"lightcyan2\"           \"lightcyan3\"          \n[409] \"lightcyan4\"           \"lightgoldenrod\"       \"lightgoldenrod1\"     \n[412] \"lightgoldenrod2\"      \"lightgoldenrod3\"      \"lightgoldenrod4\"     \n[415] \"lightgoldenrodyellow\" \"lightgray\"            \"lightgreen\"          \n[418] \"lightgrey\"            \"lightpink\"            \"lightpink1\"          \n[421] \"lightpink2\"           \"lightpink3\"           \"lightpink4\"          \n[424] \"lightsalmon\"          \"lightsalmon1\"         \"lightsalmon2\"        \n[427] \"lightsalmon3\"         \"lightsalmon4\"         \"lightseagreen\"       \n[430] \"lightskyblue\"         \"lightskyblue1\"        \"lightskyblue2\"       \n[433] \"lightskyblue3\"        \"lightskyblue4\"        \"lightslateblue\"      \n[436] \"lightslategray\"       \"lightslategrey\"       \"lightsteelblue\"      \n[439] \"lightsteelblue1\"      \"lightsteelblue2\"      \"lightsteelblue3\"     \n[442] \"lightsteelblue4\"      \"lightyellow\"          \"lightyellow1\"        \n[445] \"lightyellow2\"         \"lightyellow3\"         \"lightyellow4\"        \n[448] \"limegreen\"            \"linen\"                \"magenta\"             \n[451] \"magenta1\"             \"magenta2\"             \"magenta3\"            \n[454] \"magenta4\"             \"maroon\"               \"maroon1\"             \n[457] \"maroon2\"              \"maroon3\"              \"maroon4\"             \n[460] \"mediumaquamarine\"     \"mediumblue\"           \"mediumorchid\"        \n[463] \"mediumorchid1\"        \"mediumorchid2\"        \"mediumorchid3\"       \n[466] \"mediumorchid4\"        \"mediumpurple\"         \"mediumpurple1\"       \n[469] \"mediumpurple2\"        \"mediumpurple3\"        \"mediumpurple4\"       \n[472] \"mediumseagreen\"       \"mediumslateblue\"      \"mediumspringgreen\"   \n[475] \"mediumturquoise\"      \"mediumvioletred\"      \"midnightblue\"        \n[478] \"mintcream\"            \"mistyrose\"            \"mistyrose1\"          \n[481] \"mistyrose2\"           \"mistyrose3\"           \"mistyrose4\"          \n[484] \"moccasin\"             \"navajowhite\"          \"navajowhite1\"        \n[487] \"navajowhite2\"         \"navajowhite3\"         \"navajowhite4\"        \n[490] \"navy\"                 \"navyblue\"             \"oldlace\"             \n[493] \"olivedrab\"            \"olivedrab1\"           \"olivedrab2\"          \n[496] \"olivedrab3\"           \"olivedrab4\"           \"orange\"              \n[499] \"orange1\"              \"orange2\"              \"orange3\"             \n[502] \"orange4\"              \"orangered\"            \"orangered1\"          \n[505] \"orangered2\"           \"orangered3\"           \"orangered4\"          \n[508] \"orchid\"               \"orchid1\"              \"orchid2\"             \n[511] \"orchid3\"              \"orchid4\"              \"palegoldenrod\"       \n[514] \"palegreen\"            \"palegreen1\"           \"palegreen2\"          \n[517] \"palegreen3\"           \"palegreen4\"           \"paleturquoise\"       \n[520] \"paleturquoise1\"       \"paleturquoise2\"       \"paleturquoise3\"      \n[523] \"paleturquoise4\"       \"palevioletred\"        \"palevioletred1\"      \n[526] \"palevioletred2\"       \"palevioletred3\"       \"palevioletred4\"      \n[529] \"papayawhip\"           \"peachpuff\"            \"peachpuff1\"          \n[532] \"peachpuff2\"           \"peachpuff3\"           \"peachpuff4\"          \n[535] \"peru\"                 \"pink\"                 \"pink1\"               \n[538] \"pink2\"                \"pink3\"                \"pink4\"               \n[541] \"plum\"                 \"plum1\"                \"plum2\"               \n[544] \"plum3\"                \"plum4\"                \"powderblue\"          \n[547] \"purple\"               \"purple1\"              \"purple2\"             \n[550] \"purple3\"              \"purple4\"              \"red\"                 \n[553] \"red1\"                 \"red2\"                 \"red3\"                \n[556] \"red4\"                 \"rosybrown\"            \"rosybrown1\"          \n[559] \"rosybrown2\"           \"rosybrown3\"           \"rosybrown4\"          \n[562] \"royalblue\"            \"royalblue1\"           \"royalblue2\"          \n[565] \"royalblue3\"           \"royalblue4\"           \"saddlebrown\"         \n[568] \"salmon\"               \"salmon1\"              \"salmon2\"             \n[571] \"salmon3\"              \"salmon4\"              \"sandybrown\"          \n[574] \"seagreen\"             \"seagreen1\"            \"seagreen2\"           \n[577] \"seagreen3\"            \"seagreen4\"            \"seashell\"            \n[580] \"seashell1\"            \"seashell2\"            \"seashell3\"           \n[583] \"seashell4\"            \"sienna\"               \"sienna1\"             \n[586] \"sienna2\"              \"sienna3\"              \"sienna4\"             \n[589] \"skyblue\"              \"skyblue1\"             \"skyblue2\"            \n[592] \"skyblue3\"             \"skyblue4\"             \"slateblue\"           \n[595] \"slateblue1\"           \"slateblue2\"           \"slateblue3\"          \n[598] \"slateblue4\"           \"slategray\"            \"slategray1\"          \n[601] \"slategray2\"           \"slategray3\"           \"slategray4\"          \n[604] \"slategrey\"            \"snow\"                 \"snow1\"               \n[607] \"snow2\"                \"snow3\"                \"snow4\"               \n[610] \"springgreen\"          \"springgreen1\"         \"springgreen2\"        \n[613] \"springgreen3\"         \"springgreen4\"         \"steelblue\"           \n[616] \"steelblue1\"           \"steelblue2\"           \"steelblue3\"          \n[619] \"steelblue4\"           \"tan\"                  \"tan1\"                \n[622] \"tan2\"                 \"tan3\"                 \"tan4\"                \n[625] \"thistle\"              \"thistle1\"             \"thistle2\"            \n[628] \"thistle3\"             \"thistle4\"             \"tomato\"              \n[631] \"tomato1\"              \"tomato2\"              \"tomato3\"             \n[634] \"tomato4\"              \"turquoise\"            \"turquoise1\"          \n[637] \"turquoise2\"           \"turquoise3\"           \"turquoise4\"          \n[640] \"violet\"               \"violetred\"            \"violetred1\"          \n[643] \"violetred2\"           \"violetred3\"           \"violetred4\"          \n[646] \"wheat\"                \"wheat1\"               \"wheat2\"              \n[649] \"wheat3\"               \"wheat4\"               \"whitesmoke\"          \n[652] \"yellow\"               \"yellow1\"              \"yellow2\"             \n[655] \"yellow3\"              \"yellow4\"              \"yellowgreen\""
  },
  {
    "objectID": "stat100_wk03mon.html#change-the-color-1",
    "href": "stat100_wk03mon.html#change-the-color-1",
    "title": "Stat 100",
    "section": "Change the Color",
    "text": "Change the Color\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total,\n                     color = Occasion)) +\n  geom_line(size = 2) +\n  theme(legend.pos = \"bottom\") +\n  scale_color_manual(values = c(\"violetred2\",\n                                \"steelblue4\"))"
  },
  {
    "objectID": "stat100_wk03mon.html#change-the-color-2",
    "href": "stat100_wk03mon.html#change-the-color-2",
    "title": "Stat 100",
    "section": "Change the Color",
    "text": "Change the Color\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total,\n                     color = Occasion)) +\n  geom_line(size = 2) +\n  theme(legend.pos = \"bottom\") +\n  scale_color_manual(values = c(\"#0D6759\",\n                                \"#E4844A\"))"
  },
  {
    "objectID": "stat100_wk03mon.html#use-a-different-theme",
    "href": "stat100_wk03mon.html#use-a-different-theme",
    "title": "Stat 100",
    "section": "Use a Different Theme",
    "text": "Use a Different Theme\n\n\nggplot(data = july_2019,\n       mapping = aes(x = Time,\n                     y = Total,\n                     color = Occasion)) +\n  geom_line(size = 2) +\n  scale_color_manual(values = c(\"#0D6759\",\n                                \"#E4844A\")) +\n  theme_bw() +\n  theme(legend.pos = \"bottom\")"
  },
  {
    "objectID": "stat100_wk03mon.html#reminders",
    "href": "stat100_wk03mon.html#reminders",
    "title": "Stat 100",
    "section": "Reminders",
    "text": "Reminders\n\nWith COVID working its way through campus right now, make sure to check the Sections spreadsheet and the Office hours spreadsheet for updates!\nGrab a postcard and/or a stamp from SC 316 if you lost yours.\n\nWe also have markers, colored pencils, and crayons!\n\nDon’t forget that P-Set 1 due on Tuesday by 5pm in Gradescope.\nCome by office hours with any questions."
  },
  {
    "objectID": "stat100_wk02wed.html#announcements",
    "href": "stat100_wk02wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nClass in full swing:\n\nSections: Can find your assigned section in my.harvard but need to go to the linked spreadsheet to find the room!\nOffice hours\n\nFill out this form after your first visit.\n\nWrap-ups on Th 3-4pm and Fri 10:30 - 11:30am in SC 309\nLecture quiz will be released in Gradescope after class today."
  },
  {
    "objectID": "stat100_wk02wed.html#teachly",
    "href": "stat100_wk02wed.html#teachly",
    "title": "Stat 100",
    "section": "Teachly",
    "text": "Teachly\n\nTeachly is a platform that allows you to fill out a profile so that we can get to know you and your interests in stats/data science better.\nYou should have received two emails:\n\nThe general Teachly profile\nA couple additional Stat 100 related questions\n\nEach question is optional. You will not be assessed on its completion or your answers.\nWays we plan to use Teachly:\n\nTo get to know you better.\nTo find out what data applications you might be interested in seeing.\nTo tailor advice related to future statistical endeavors."
  },
  {
    "objectID": "stat100_wk02wed.html#goals-for-today",
    "href": "stat100_wk02wed.html#goals-for-today",
    "title": "Stat 100",
    "section": "Goals for Today",
    "text": "Goals for Today\n\n\nFirst Segment:\n\nMotivate data visualizations.\nDevelop language to talk about the components of a graphic.\nPractice deconstructing graphics.\nDiscuss good graphical practices.\n\n\nSecond Segment:\n\nLearn the general structure of ggplot2.\nLearn a few standard graphs for numerical/quantitative data:\n\nHistogram: one numerical variable\nSide-by-side boxplot: one numerical variable and one categorical variable\nSide-by-side violin plot: one numerical variable and one categorical variable"
  },
  {
    "objectID": "stat100_wk02wed.html#why-construct-a-graph",
    "href": "stat100_wk02wed.html#why-construct-a-graph",
    "title": "Stat 100",
    "section": "Why construct a graph?",
    "text": "Why construct a graph?\n\n\nTo explore the data.\n\n\nTo summarize the data.\n\n\nTo showcase trends and make comparisons.\n\n\nTo tell a compelling story."
  },
  {
    "objectID": "stat100_wk02wed.html#challenger",
    "href": "stat100_wk02wed.html#challenger",
    "title": "Stat 100",
    "section": "Challenger",
    "text": "Challenger\n\nOn January 27th, 1986, engineers from Morton Thiokol recommended NASA delay launch of space shuttle Challenger due to cold weather.\n\nBelieved cold weather impacted the o-rings that held the rockets together.\nUsed 13 charts in their argument.\n\nAfter a two hour conference call, the engineer’s recommendation was overruled due to lack of persuasive evidence and the launch proceeded.\nThe Challenger exploded 73 seconds into launch."
  },
  {
    "objectID": "stat100_wk02wed.html#challenger-1",
    "href": "stat100_wk02wed.html#challenger-1",
    "title": "Stat 100",
    "section": "Challenger",
    "text": "Challenger\nHere’s one of those charts."
  },
  {
    "objectID": "stat100_wk02wed.html#challenger-2",
    "href": "stat100_wk02wed.html#challenger-2",
    "title": "Stat 100",
    "section": "Challenger",
    "text": "Challenger\nHere’s another one of those charts."
  },
  {
    "objectID": "stat100_wk02wed.html#challenger-3",
    "href": "stat100_wk02wed.html#challenger-3",
    "title": "Stat 100",
    "section": "Challenger",
    "text": "Challenger\nHere’s a graphic I created from Edward Tufte’s data."
  },
  {
    "objectID": "stat100_wk02wed.html#challenger-4",
    "href": "stat100_wk02wed.html#challenger-4",
    "title": "Stat 100",
    "section": "Challenger",
    "text": "Challenger\nThis adaptation is a recreation of Edward Tufte’s graphic.\n\n\n\n\n\n\n\n\n\n\n\nFor more information on this example and other examples, check out Tufte’s book."
  },
  {
    "objectID": "stat100_wk02wed.html#now-lets-learn-the-grammar-of-graphics.",
    "href": "stat100_wk02wed.html#now-lets-learn-the-grammar-of-graphics.",
    "title": "Stat 100",
    "section": "Now let’s learn the Grammar of Graphics.",
    "text": "Now let’s learn the Grammar of Graphics.\n\nWe will use this grammar to:\n\n\nDecompose and understand existing graphs.\n\n\nCreate our own graphs with the R package ggplot2."
  },
  {
    "objectID": "stat100_wk02wed.html#grammar-of-graphics",
    "href": "stat100_wk02wed.html#grammar-of-graphics",
    "title": "Stat 100",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\n\ndata: Data frame that contains the raw data\n\nVariables used in the graph\n\ngeom: Geometric shape that the data are mapped to.\n\nEX: Point, line, bar, text, …\n\naesthetic: Visual properties of the geom\n\nEX: X (horizontal) position, y (vertical) position, color, fill, shape\n\nscale: Controls how data are mapped to the visual values of the aesthetic.\n\nEX: particular colors, log scale\n\nguide: Legend/key to help user convert visual display back to the data\n\n\nFor right now, we won’t focus on the names of particular types of graphs (e.g., scatterplot) but on the elements of graphs."
  },
  {
    "objectID": "stat100_wk02wed.html#many-ways-to-visually-tell-a-story",
    "href": "stat100_wk02wed.html#many-ways-to-visually-tell-a-story",
    "title": "Stat 100",
    "section": "Many Ways To Visually Tell A Story",
    "text": "Many Ways To Visually Tell A Story\nWashington Post’s Approach:\n\n\n\n\n\nPeriscopic’s Approach"
  },
  {
    "objectID": "stat100_wk02wed.html#bad-graphics",
    "href": "stat100_wk02wed.html#bad-graphics",
    "title": "Stat 100",
    "section": "Bad Graphics",
    "text": "Bad Graphics\nBecause of all the design choices, it is much easier to make a bad graph than a good graph."
  },
  {
    "objectID": "stat100_wk02wed.html#misleading-graphics",
    "href": "stat100_wk02wed.html#misleading-graphics",
    "title": "Stat 100",
    "section": "Misleading Graphics",
    "text": "Misleading Graphics\nBe careful that your design choices don’t cause your viewer to draw incorrect conclusions about the data:\n\n\n\n\n\n\nJust letting the software make all the design choices can still lead to misleading graphs (recall the Georgia COVID graph)."
  },
  {
    "objectID": "stat100_wk02wed.html#summary-thoughts-on-graphical-considerations",
    "href": "stat100_wk02wed.html#summary-thoughts-on-graphical-considerations",
    "title": "Stat 100",
    "section": "Summary Thoughts on Graphical Considerations",
    "text": "Summary Thoughts on Graphical Considerations\n\nGood graphics are one’s where the findings and insights are obvious to the viewer.\n\nAdd information and key context.\n\nFacilitate the comparisons that correspond to the research question.\n\nRecall the three Georgia COVID counts graphs from Day 1!\n\nData visualizations are not neutral.\nIt is easier to see the differences and similarities between different types of graphics if we learn the grammar of graphics.\nPracticing decomposing graphics should make it easier for us to compose our own graphics."
  },
  {
    "objectID": "stat100_wk02wed.html#load-necessary-packages",
    "href": "stat100_wk02wed.html#load-necessary-packages",
    "title": "Stat 100",
    "section": "Load Necessary Packages",
    "text": "Load Necessary Packages\n\n\n\n\n\nggplot2 is part of this collection of data science packages.\n\n# Load necessary packages\nlibrary(tidyverse)"
  },
  {
    "objectID": "stat100_wk02wed.html#data-setting-eco-totem-broadway-bicycle-count",
    "href": "stat100_wk02wed.html#data-setting-eco-totem-broadway-bicycle-count",
    "title": "Stat 100",
    "section": "Data Setting: Eco-Totem Broadway Bicycle Count",
    "text": "Data Setting: Eco-Totem Broadway Bicycle Count"
  },
  {
    "objectID": "stat100_wk02wed.html#import-the-data",
    "href": "stat100_wk02wed.html#import-the-data",
    "title": "Stat 100",
    "section": "Import the Data",
    "text": "Import the Data\n\njuly_2019 &lt;- read_csv(\"data/july_2019.csv\")\n\n# Inspect the data\nglimpse(july_2019)\n\nRows: 192\nColumns: 8\n$ DateTime  &lt;chr&gt; \"07/04/2019 12:00:00 AM\", \"07/04/2019 12:15:00 AM\", \"07/04/2…\n$ Day       &lt;chr&gt; \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\", …\n$ Date      &lt;date&gt; 2019-07-04, 2019-07-04, 2019-07-04, 2019-07-04, 2019-07-04,…\n$ Time      &lt;time&gt; 00:00:00, 00:15:00, 00:30:00, 00:45:00, 01:00:00, 01:15:00,…\n$ Total     &lt;dbl&gt; 2, 3, 2, 0, 3, 2, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, …\n$ Westbound &lt;dbl&gt; 2, 3, 1, 0, 2, 2, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, …\n$ Eastbound &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ Occasion  &lt;chr&gt; \"Fourth of July\", \"Fourth of July\", \"Fourth of July\", \"Fourt…"
  },
  {
    "objectID": "stat100_wk02wed.html#inspect-the-data",
    "href": "stat100_wk02wed.html#inspect-the-data",
    "title": "Stat 100",
    "section": "Inspect the Data",
    "text": "Inspect the Data\n\n# Look at first few rows\nhead(july_2019)\n\n# A tibble: 6 × 8\n  DateTime             Day   Date       Time  Total Westbound Eastbound Occasion\n  &lt;chr&gt;                &lt;chr&gt; &lt;date&gt;     &lt;tim&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   \n1 07/04/2019 12:00:00… Thur… 2019-07-04 00:00     2         2         0 Fourth …\n2 07/04/2019 12:15:00… Thur… 2019-07-04 00:15     3         3         0 Fourth …\n3 07/04/2019 12:30:00… Thur… 2019-07-04 00:30     2         1         1 Fourth …\n4 07/04/2019 12:45:00… Thur… 2019-07-04 00:45     0         0         0 Fourth …\n5 07/04/2019 01:00:00… Thur… 2019-07-04 01:00     3         2         1 Fourth …\n6 07/04/2019 01:15:00… Thur… 2019-07-04 01:15     2         2         0 Fourth …\n\n\nWhat does a row represent here?"
  },
  {
    "objectID": "stat100_wk02wed.html#inspect-the-data-1",
    "href": "stat100_wk02wed.html#inspect-the-data-1",
    "title": "Stat 100",
    "section": "Inspect the Data",
    "text": "Inspect the Data\n\n# Determine type\n# To access one variable: dataset$variable\nclass(july_2019$Day)\n\n[1] \"character\"\n\nclass(july_2019$Total)\n\n[1] \"numeric\"\n\nclass(july_2019)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\""
  },
  {
    "objectID": "stat100_wk02wed.html#grammar-of-graphics-1",
    "href": "stat100_wk02wed.html#grammar-of-graphics-1",
    "title": "Stat 100",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\n\ndata: Data frame that contains the raw data\n\nVariables used in the graph\n\ngeom: Geometric shape that the data are mapped to.\n\nEX: Point, line, bar, text, …\n\naesthetic: Visual properties of the geom\n\nEX: X (horizontal) position, y (vertical) position, color, fill, shape\n\nscale: Controls how data are mapped to the visual values of the aesthetic.\n\nEX: particular colors, log scale\n\nguide: Legend/key to help user convert visual display back to the data"
  },
  {
    "objectID": "stat100_wk02wed.html#ggplot2-example-code",
    "href": "stat100_wk02wed.html#ggplot2-example-code",
    "title": "Stat 100",
    "section": "ggplot2 example code",
    "text": "ggplot2 example code\nGuiding Principle: We will map variables from the data to the aesthetic attributes (e.g. location, size, shape, color) of geometric objects (e.g. points, lines, bars).\n\nggplot(data = ---, mapping = aes(---)) +\n  geom_---(---) \n\n\nThere are other layers, such as scales_---_---() and labs(), but we will wait on those."
  },
  {
    "objectID": "stat100_wk02wed.html#histograms",
    "href": "stat100_wk02wed.html#histograms",
    "title": "Stat 100",
    "section": "Histograms",
    "text": "Histograms\n\n\n\nBinned counts of data.\nGreat for assessing shape."
  },
  {
    "objectID": "stat100_wk02wed.html#data-shapes",
    "href": "stat100_wk02wed.html#data-shapes",
    "title": "Stat 100",
    "section": "Data Shapes",
    "text": "Data Shapes"
  },
  {
    "objectID": "stat100_wk02wed.html#histograms-1",
    "href": "stat100_wk02wed.html#histograms-1",
    "title": "Stat 100",
    "section": "Histograms",
    "text": "Histograms\n\n\n# Create histogram\nggplot(data = july_2019, \n       mapping = aes(x = Total)) +\n  geom_histogram()"
  },
  {
    "objectID": "stat100_wk02wed.html#histograms-2",
    "href": "stat100_wk02wed.html#histograms-2",
    "title": "Stat 100",
    "section": "Histograms",
    "text": "Histograms\n\n\n# Create histogram\nggplot(data = july_2019, \n       mapping = aes(x = Total)) +\n  geom_histogram(color = \"white\",\n                 fill = \"violetred1\",\n                 bins = 50)\n\n\n\n\n\n\n\n\n\n\n\nmapping to a variable goes in aes()\nsetting to a specific value goes in the geom_---()"
  },
  {
    "objectID": "stat100_wk02wed.html#boxplots",
    "href": "stat100_wk02wed.html#boxplots",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\n\nFive number summary:\n\nMinimum\nFirst quartile (Q1)\nMedian\nThird quartile (Q3)\nMaximum\n\nInterquartile range (IQR) \\(=\\) Q3 \\(-\\) Q1\nOutliers: unusual points\n\nBoxplot defines unusual as being beyond \\(1.5*IQR\\) from \\(Q1\\) or \\(Q3\\).\n\nWhiskers: reach out to the furthest point that is NOT an outlier"
  },
  {
    "objectID": "stat100_wk02wed.html#boxplots-1",
    "href": "stat100_wk02wed.html#boxplots-1",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\n# Create boxplot\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total)) +\n  geom_boxplot()"
  },
  {
    "objectID": "stat100_wk02wed.html#boxplots-2",
    "href": "stat100_wk02wed.html#boxplots-2",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total)) +\n  geom_boxplot(fill = \"springgreen3\")"
  },
  {
    "objectID": "stat100_wk02wed.html#boxplots-3",
    "href": "stat100_wk02wed.html#boxplots-3",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total,\n                     fill = Occasion)) +\n  geom_boxplot()"
  },
  {
    "objectID": "stat100_wk02wed.html#boxplots-4",
    "href": "stat100_wk02wed.html#boxplots-4",
    "title": "Stat 100",
    "section": "Boxplots",
    "text": "Boxplots\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total,\n                     fill = Occasion)) +\n  geom_boxplot() +\n  guides(fill = \"none\")"
  },
  {
    "objectID": "stat100_wk02wed.html#violin-plots",
    "href": "stat100_wk02wed.html#violin-plots",
    "title": "Stat 100",
    "section": "Violin Plots",
    "text": "Violin Plots\n\n\nggplot(data = july_2019, \n       mapping = aes(x = Occasion, \n                     y = Total,\n                     fill = Occasion)) +\n  geom_violin() +\n  guides(fill = \"none\")"
  },
  {
    "objectID": "stat100_wk02wed.html#boxplot-versus-violin-plots",
    "href": "stat100_wk02wed.html#boxplot-versus-violin-plots",
    "title": "Stat 100",
    "section": "Boxplot Versus Violin Plots",
    "text": "Boxplot Versus Violin Plots"
  },
  {
    "objectID": "stat100_wk02wed.html#recap-ggplot2",
    "href": "stat100_wk02wed.html#recap-ggplot2",
    "title": "Stat 100",
    "section": "Recap: ggplot2",
    "text": "Recap: ggplot2\n\nlibrary(tidyverse)\nggplot(data = ---, mapping = aes(---)) +\n  geom_---(---)"
  },
  {
    "objectID": "stat100_wk02wed.html#reminders",
    "href": "stat100_wk02wed.html#reminders",
    "title": "Stat 100",
    "section": "Reminders",
    "text": "Reminders\n\nClass in full swing:\n\nSections: Can find your assigned section in my.harvard but need to go to the linked spreadsheet to find the room!\nOffice hours\nWrap-ups on Th 3-4pm and Fri 10:30 - 11:30am in SC 309\nLecture quiz will be released in Gradescope after class today."
  },
  {
    "objectID": "stat100_wk07wed.html#announcements",
    "href": "stat100_wk07wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nDon’t forget about this week’s lecture quiz.\n\nGoals for Today\n\n\n\nHandling categorical, explanatory variables with more than 2 categories\n\n\n\nRegression with polynomial explanatory variables"
  },
  {
    "objectID": "stat100_wk07wed.html#adding-a-curve-to-your-scatterplot",
    "href": "stat100_wk07wed.html#adding-a-curve-to-your-scatterplot",
    "title": "Stat 100",
    "section": "Adding a Curve to your Scatterplot",
    "text": "Adding a Curve to your Scatterplot\n\n\nggplot(data = movies2,\n       mapping = aes(x = AudienceScore,\n                     y = RottenTomatoes,\n                     color = Genre)) +\n  geom_point(alpha = 0.5) +\n  stat_smooth(method = lm, se = FALSE, \n        formula = y ~ poly(x, degree = 2))"
  },
  {
    "objectID": "stat100_wk07wed.html#practice",
    "href": "stat100_wk07wed.html#practice",
    "title": "Stat 100",
    "section": "Practice",
    "text": "Practice\nDetermine and interpret the slope for a Chinstrap penguin using Model 1.\n \nDetermine and interpret the slope for a Adelie penguin using Model 1.\n \nIn Model 1, interpret \\(\\hat{\\beta}_2\\).\n \nDetermine and interpret the slope for a Chinstrap penguin using Model 2.\n \nDetermine and interpret the slope for a Adelie penguin using Model 2."
  },
  {
    "objectID": "stat100_wk08mon.html#announcements",
    "href": "stat100_wk08mon.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nOct 30th: Hex or Treat Day in Stat 100\n\nWear a Halloween costume and get either a hex sticker or candy!!\n\n\nGoals for Today\n\n\n\nFinish up: Regression with polynomial explanatory variables\nModeling guidance\n\n\n\nSampling variability\nSampling distributions"
  },
  {
    "objectID": "stat100_wk08mon.html#sampling-distribution-of-a-statistic",
    "href": "stat100_wk08mon.html#sampling-distribution-of-a-statistic",
    "title": "Stat 100",
    "section": "Sampling Distribution of a Statistic",
    "text": "Sampling Distribution of a Statistic\nSteps to Construct an (Approximate) Sampling Distribution:\n\nDecide on a sample size, \\(n\\).\nRandomly select a sample of size \\(n\\) from the population.\nCompute the sample statistic.\nPut the sample back in.\nRepeat Steps 2 - 4 many (1000+) times."
  },
  {
    "objectID": "stat100_wk08mon.html#sampling-distribution-of-a-statistic-1",
    "href": "stat100_wk08mon.html#sampling-distribution-of-a-statistic-1",
    "title": "Stat 100",
    "section": "Sampling Distribution of a Statistic",
    "text": "Sampling Distribution of a Statistic\n\n\n\n\n\n\n\n\n\n\n\n\nCenter? Shape?\nSpread?\n\nStandard error = standard deviation of the statistic\n\n\n\n\nWhat happens to the center/spread/shape as we increase the sample size?\nWhat happens to the center/spread/shape if the true parameter changes?"
  },
  {
    "objectID": "stat100_wk08wed.html#announcements",
    "href": "stat100_wk08wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nOct 30th: Hex or Treat Day in Stat 100\n\nWear a Halloween costume and get either a hex sticker or candy!!\n\n\nGoals for Today\n\n\n\nModeling & Ethics: Algorithmic bias\nSampling Distribution\n\nProperties\nConstruction in R\n\n\n\n\nEstimation"
  },
  {
    "objectID": "stat100_wk08wed.html#integrity-of-data-and-methods",
    "href": "stat100_wk08wed.html#integrity-of-data-and-methods",
    "title": "Stat 100",
    "section": "Integrity of Data and Methods",
    "text": "Integrity of Data and Methods\n\n“The ethical statistical practitioner seeks to understand and mitigate known or suspected limitations, defects, or biases in the data or methods and communicates potential impacts on the interpretation, conclusions, recommendations, decisions, or other results of statistical practices.”\n\n\n“For models and algorithms designed to inform or implement decisions repeatedly, develops and/or implements plans to validate assumptions and assess performance over time, as needed. Considers criteria and mitigation plans for model or algorithm failure and retirement.”"
  },
  {
    "objectID": "stat100_wk08wed.html#sampling-distribution-of-a-statistic",
    "href": "stat100_wk08wed.html#sampling-distribution-of-a-statistic",
    "title": "Stat 100",
    "section": "Sampling Distribution of a Statistic",
    "text": "Sampling Distribution of a Statistic\n\n\nSteps to Construct an (Approximate) Sampling Distribution:\n\nDecide on a sample size, \\(n\\).\nRandomly select a sample of size \\(n\\) from the population.\nCompute the sample statistic.\nPut the sample back in.\nRepeat Steps 2 - 4 many (1000+) times.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat happens to the center/spread/shape as we increase the sample size?\nWhat happens to the center/spread/shape if the true parameter changes?"
  },
  {
    "objectID": "stat100_wk08wed.html#lets-construct-some-sampling-distributions-using-r",
    "href": "stat100_wk08wed.html#lets-construct-some-sampling-distributions-using-r",
    "title": "Stat 100",
    "section": "Let’s Construct Some Sampling Distributions using R!",
    "text": "Let’s Construct Some Sampling Distributions using R!\nImportant Notes\n\nTo construct a sampling distribution for a statistic, we need access to the entire population so that we can take repeated samples from the population.\n\nPopulation = Harvard trees\n\nBut if we have access to the entire population, then we know the value of the population parameter.\n\nCan compute the exact mean diameter of trees in our population.\n\nThe sampling distribution is needed in the exact scenario where we can’t compute it: the scenario where we only have a single sample.\nWe will learn how to estimate the sampling distribution soon.\nToday, we have the entire population and are constructing sampling distributions anyway to study their properties!"
  },
  {
    "objectID": "stat100_wk08wed.html#new-r-package-infer",
    "href": "stat100_wk08wed.html#new-r-package-infer",
    "title": "Stat 100",
    "section": "New R Package: infer",
    "text": "New R Package: infer\n\n\n\n\n\n\n\n\n  \n\nlibrary(infer)\n\n\n\n\nWill use infer to conduct statistical inference."
  },
  {
    "objectID": "stat100_wk08wed.html#our-population-parameter",
    "href": "stat100_wk08wed.html#our-population-parameter",
    "title": "Stat 100",
    "section": "Our Population Parameter",
    "text": "Our Population Parameter\nCreate data frame of Harvard trees:\n\nlibrary(tidyverse)\nlibrary(bosTrees)\nharTrees &lt;- camTrees %&gt;%\n  filter(Ownership == \"Harvard\", SiteType == \"Tree\") %&gt;%\n  drop_na(SpeciesShort)\n\nAdd variable of interest:\n\nharTrees &lt;- harTrees %&gt;%\n  mutate(tree_of_interest = case_when(\n    SpeciesShort == \"Maple\" ~ \"yes\",\n    SpeciesShort != \"Maple\" ~ \"no\"\n  ))\ncount(harTrees, tree_of_interest)\n\n# A tibble: 2 × 2\n  tree_of_interest     n\n  &lt;chr&gt;            &lt;int&gt;\n1 no                2707\n2 yes                434"
  },
  {
    "objectID": "stat100_wk08wed.html#population-parameter",
    "href": "stat100_wk08wed.html#population-parameter",
    "title": "Stat 100",
    "section": "Population Parameter",
    "text": "Population Parameter\n\n\n# Population distribution\nggplot(data = harTrees, \n       mapping = aes(x = tree_of_interest)) +\n  geom_bar(aes(y = ..prop.., group = 1),\n           stat = \"count\") \n\n\n\n\n\n\n\n\n# True population parameter\nsummarize(harTrees, \n          parameter = mean(tree_of_interest == \"yes\"))\n\n# A tibble: 1 × 1\n  parameter\n      &lt;dbl&gt;\n1     0.138"
  },
  {
    "objectID": "stat100_wk08wed.html#key-features-of-a-sampling-distribution",
    "href": "stat100_wk08wed.html#key-features-of-a-sampling-distribution",
    "title": "Stat 100",
    "section": "Key Features of a Sampling Distribution",
    "text": "Key Features of a Sampling Distribution\nWhat did we learn about sampling distributions?\n\nCentered around the true population parameter.\nAs the sample size increases, the standard error (SE) of the statistic decreases.\nAs the sample size increases, the shape of the sampling distribution becomes more bell-shaped and symmetric.\nQuestion: How do sampling distributions help us quantify uncertainty?\nQuestion: If I am estimating a parameter in a real example, why won’t I be able to construct the sampling distribution??"
  },
  {
    "objectID": "stat100_wk08wed.html#estimation",
    "href": "stat100_wk08wed.html#estimation",
    "title": "Stat 100",
    "section": "Estimation",
    "text": "Estimation\nGoal: Estimate the value of a population parameter using data from the sample.\n\nQuestion: How do I know which population parameter I am interesting in estimating?\nAnswer: Likely depends on the research question and structure of your data!\nPoint Estimate: The corresponding statistic\n\nSingle best guess for the parameter\n\n\n\n\nlibrary(tidyverse)\nce &lt;- read_csv(\"data/fmli.csv\")\nsummarize(ce, meanFINCBTAX = mean(FINCBTAX))\n\n# A tibble: 1 × 1\n  meanFINCBTAX\n         &lt;dbl&gt;\n1       62480."
  },
  {
    "objectID": "stat100_wk08wed.html#confidence-intervals",
    "href": "stat100_wk08wed.html#confidence-intervals",
    "title": "Stat 100",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\n\nIt is time to move beyond just point estimates to interval estimates that quantify our uncertainty.\n\n\nsummarize(ce, meanFINCBTAX = mean(FINCBTAX))\n\n# A tibble: 1 × 1\n  meanFINCBTAX\n         &lt;dbl&gt;\n1       62480.\n\n\n\n\n\nConfidence Interval: Interval of plausible values for a parameter\nForm: \\(\\mbox{statistic} \\pm \\mbox{Margin of Error}\\)\nQuestion: How do we find the Margin of Error (ME)?\nAnswer: If the sampling distribution of the statistic is approximately bell-shaped and symmetric, then a statistic will be within 2 SEs of the parameter for 95% of the samples.\nForm: \\(\\mbox{statistic} \\pm 2\\mbox{SE}\\)\nCalled a 95% confidence interval (CI). (Will discuss the meaning of confidence soon)"
  },
  {
    "objectID": "stat100_wk08wed.html#confidence-intervals-1",
    "href": "stat100_wk08wed.html#confidence-intervals-1",
    "title": "Stat 100",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n95% CI Form:\n\\[\n\\mbox{statistic} \\pm 2\\mbox{SE}\n\\]\nLet’s use the ce data to produce a CI for the average household income before taxes.\n\nsummarize(ce, meanFINCBTAX = mean(FINCBTAX))\n\n# A tibble: 1 × 1\n  meanFINCBTAX\n         &lt;dbl&gt;\n1       62480.\n\n\nWhat else do we need to construct the CI?\n\nProblem: To compute the SE, we need many samples from the population. We have 1 sample.\nSolution: Approximate the sampling distribution using ONLY OUR ONE SAMPLE!"
  },
  {
    "objectID": "stat100_wk08wed.html#reminders",
    "href": "stat100_wk08wed.html#reminders",
    "title": "Stat 100",
    "section": "Reminders:",
    "text": "Reminders:\n\nOct 30th: Hex or Treat Day in Stat 100\n\nWear a Halloween costume and get either a hex sticker or candy!!"
  },
  {
    "objectID": "stat100_wk03wed.html#announcements",
    "href": "stat100_wk03wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nWith COVID working its way through campus right now, make sure to check the Sections spreadsheet and the Office hours spreadsheet for updates!\nLet’s go through up to upload the pngs of your postcards to the RStudio Server on Posit Cloud."
  },
  {
    "objectID": "stat100_wk03wed.html#goals-for-today",
    "href": "stat100_wk03wed.html#goals-for-today",
    "title": "Stat 100",
    "section": "Goals for Today",
    "text": "Goals for Today\n\n\n\nConsider measures for summarizing quantitative data\n\nCenter\nSpread/variability\n\nConsider measures for summarizing categorical data\n\n\n\nDefine data wrangling\nLearn to use functions in the dplyr package to summarize and wrangle data"
  },
  {
    "objectID": "stat100_wk03wed.html#load-necessary-packages",
    "href": "stat100_wk03wed.html#load-necessary-packages",
    "title": "Stat 100",
    "section": "Load Necessary Packages",
    "text": "Load Necessary Packages\n\n\n\n\n\ndplyr is part of this collection of data science packages.\n\n# Load necessary packages\nlibrary(tidyverse)"
  },
  {
    "objectID": "stat100_wk03wed.html#import-the-data",
    "href": "stat100_wk03wed.html#import-the-data",
    "title": "Stat 100",
    "section": "Import the Data",
    "text": "Import the Data\n\njuly_2019 &lt;- read_csv(\"data/july_2019.csv\")\n\n# Inspect the data\nglimpse(july_2019)\n\nRows: 192\nColumns: 8\n$ DateTime  &lt;chr&gt; \"07/04/2019 12:00:00 AM\", \"07/04/2019 12:15:00 AM\", \"07/04/2…\n$ Day       &lt;chr&gt; \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\", \"Thursday\", …\n$ Date      &lt;date&gt; 2019-07-04, 2019-07-04, 2019-07-04, 2019-07-04, 2019-07-04,…\n$ Time      &lt;time&gt; 00:00:00, 00:15:00, 00:30:00, 00:45:00, 01:00:00, 01:15:00,…\n$ Total     &lt;dbl&gt; 2, 3, 2, 0, 3, 2, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, …\n$ Westbound &lt;dbl&gt; 2, 3, 1, 0, 2, 2, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, …\n$ Eastbound &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ Occasion  &lt;chr&gt; \"Fourth of July\", \"Fourth of July\", \"Fourth of July\", \"Fourt…"
  },
  {
    "objectID": "stat100_wk03wed.html#summarizing-data",
    "href": "stat100_wk03wed.html#summarizing-data",
    "title": "Stat 100",
    "section": "Summarizing Data",
    "text": "Summarizing Data\n\n\n\n\n\n\nDateTime\nDay\nDate\nTime\nTotal\nWestbound\nEastbound\nOccasion\n\n\n\n\n07/04/2019 06:00:00 AM\nThursday\n2019-07-04\n06:00:00\n1\n1\n0\nFourth of July\n\n\n07/04/2019 06:15:00 AM\nThursday\n2019-07-04\n06:15:00\n4\n0\n4\nFourth of July\n\n\n07/04/2019 06:30:00 AM\nThursday\n2019-07-04\n06:30:00\n9\n1\n8\nFourth of July\n\n\n07/04/2019 06:45:00 AM\nThursday\n2019-07-04\n06:45:00\n5\n0\n5\nFourth of July\n\n\n07/04/2019 07:00:00 AM\nThursday\n2019-07-04\n07:00:00\n3\n3\n0\nFourth of July\n\n\n07/04/2019 07:15:00 AM\nThursday\n2019-07-04\n07:15:00\n2\n0\n2\nFourth of July\n\n\n07/04/2019 07:30:00 AM\nThursday\n2019-07-04\n07:30:00\n5\n2\n3\nFourth of July\n\n\n07/04/2019 07:45:00 AM\nThursday\n2019-07-04\n07:45:00\n2\n0\n2\nFourth of July\n\n\n\n\n\n\n\n\n\nHard to do by eyeballing a spreadsheet with many rows!"
  },
  {
    "objectID": "stat100_wk03wed.html#summarizing-data-visually",
    "href": "stat100_wk03wed.html#summarizing-data-visually",
    "title": "Stat 100",
    "section": "Summarizing Data Visually",
    "text": "Summarizing Data Visually\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor a quantitative variable, want to answer:\n\nWhat is an average value?\nWhat is the trend/shape of the variable?\nHow much variation is there from case to case?\n\n\n\n\nNeed to learn key summary statistics: Numerical values computed based on the observed cases."
  },
  {
    "objectID": "stat100_wk03wed.html#measures-of-center",
    "href": "stat100_wk03wed.html#measures-of-center",
    "title": "Stat 100",
    "section": "Measures of Center",
    "text": "Measures of Center\n\n\nMean: Average of all the observations\n\n\\(n\\) = Number of cases (sample size)\n\\(x_i\\) = value of the i-th observation\nDenote by \\(\\bar{x}\\)\n\n\\[\n\\bar{x}  = \\frac{1}{n} \\sum_{i = 1}^n x_i\n\\]\n\n# Test out on first 6 values\nhead(july_2019$Total)\n\n[1] 2 3 2 0 3 2\n\n\n\nCompute with a dplyr function:\n\nsummarize(july_2019, mean_bikes = mean(Total))\n\n# A tibble: 1 × 1\n  mean_bikes\n       &lt;dbl&gt;\n1       17.1"
  },
  {
    "objectID": "stat100_wk03wed.html#measures-of-center-1",
    "href": "stat100_wk03wed.html#measures-of-center-1",
    "title": "Stat 100",
    "section": "Measures of Center",
    "text": "Measures of Center\n\n\nMedian: Middle value\n\nHalf of the data falls below the median\nDenote by \\(m\\)\nIf \\(n\\) is even, then it is the average of the middle two values\n\n\n# Test out on first 6 values\nhead(july_2019$Total)\n\n[1] 2 3 2 0 3 2\n\n\n\nCompute with a dplyr function:\n\nsummarize(july_2019, median_bikes = median(Total))\n\n# A tibble: 1 × 1\n  median_bikes\n         &lt;dbl&gt;\n1           11"
  },
  {
    "objectID": "stat100_wk03wed.html#measures-of-center-2",
    "href": "stat100_wk03wed.html#measures-of-center-2",
    "title": "Stat 100",
    "section": "Measures of Center",
    "text": "Measures of Center\n\n\nWhy is the mean larger than the median?\n\nsummarize(july_2019, mean_bikes = mean(Total),\n          median_bikes = median(Total))\n\n# A tibble: 1 × 2\n  mean_bikes median_bikes\n       &lt;dbl&gt;        &lt;dbl&gt;\n1       17.1           11"
  },
  {
    "objectID": "stat100_wk03wed.html#computing-measures-of-center-by-groups",
    "href": "stat100_wk03wed.html#computing-measures-of-center-by-groups",
    "title": "Stat 100",
    "section": "Computing Measures of Center by Groups",
    "text": "Computing Measures of Center by Groups\nQuestion: Were there more bikes, on average, for Fourth of July or for the normal Thursday?"
  },
  {
    "objectID": "stat100_wk03wed.html#computing-measures-of-center-by-groups-1",
    "href": "stat100_wk03wed.html#computing-measures-of-center-by-groups-1",
    "title": "Stat 100",
    "section": "Computing Measures of Center by Groups",
    "text": "Computing Measures of Center by Groups\nHandy dplyr function: group_by()\n\njuly_2019_grouped &lt;- group_by(july_2019, Occasion)\njuly_2019_grouped\n\n# A tibble: 192 × 8\n# Groups:   Occasion [2]\n   DateTime            Day   Date       Time  Total Westbound Eastbound Occasion\n   &lt;chr&gt;               &lt;chr&gt; &lt;date&gt;     &lt;tim&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;   \n 1 07/04/2019 12:00:0… Thur… 2019-07-04 00:00     2         2         0 Fourth …\n 2 07/04/2019 12:15:0… Thur… 2019-07-04 00:15     3         3         0 Fourth …\n 3 07/04/2019 12:30:0… Thur… 2019-07-04 00:30     2         1         1 Fourth …\n 4 07/04/2019 12:45:0… Thur… 2019-07-04 00:45     0         0         0 Fourth …\n 5 07/04/2019 01:00:0… Thur… 2019-07-04 01:00     3         2         1 Fourth …\n 6 07/04/2019 01:15:0… Thur… 2019-07-04 01:15     2         2         0 Fourth …\n 7 07/04/2019 01:30:0… Thur… 2019-07-04 01:30     1         1         0 Fourth …\n 8 07/04/2019 01:45:0… Thur… 2019-07-04 01:45     0         0         0 Fourth …\n 9 07/04/2019 02:00:0… Thur… 2019-07-04 02:00     0         0         0 Fourth …\n10 07/04/2019 02:15:0… Thur… 2019-07-04 02:15     0         0         0 Fourth …\n# ℹ 182 more rows"
  },
  {
    "objectID": "stat100_wk03wed.html#computing-measures-of-center-by-groups-2",
    "href": "stat100_wk03wed.html#computing-measures-of-center-by-groups-2",
    "title": "Stat 100",
    "section": "Computing Measures of Center by Groups",
    "text": "Computing Measures of Center by Groups\n\n\nCompute summary statistics on the grouped data frame:\n\njuly_2019_grouped &lt;- group_by(july_2019, Occasion)\nsummarize(july_2019_grouped,\n          mean_bikes = mean(Total),\n          median_bikes = median(Total))\n\n# A tibble: 2 × 3\n  Occasion        mean_bikes median_bikes\n  &lt;chr&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n1 Fourth of July        10.0          9  \n2 Normal Thursday       24.2         14.5"
  },
  {
    "objectID": "stat100_wk03wed.html#chaining-dplyr-operations",
    "href": "stat100_wk03wed.html#chaining-dplyr-operations",
    "title": "Stat 100",
    "section": "Chaining dplyr Operations",
    "text": "Chaining dplyr Operations\n\n\nInstead of:\n\njuly_2019_grouped &lt;- group_by(july_2019, Occasion)\nsummarize(july_2019_grouped,\n          mean_bikes = mean(Total),\n          median_bikes = median(Total))\n\n# A tibble: 2 × 3\n  Occasion        mean_bikes median_bikes\n  &lt;chr&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n1 Fourth of July        10.0          9  \n2 Normal Thursday       24.2         14.5\n\n\n\nUse the pipe:\n\njuly_2019 %&gt;%\n  group_by(Occasion) %&gt;%\n  summarize(mean_bikes = mean(Total),\n          median_bikes = median(Total))\n\n# A tibble: 2 × 3\n  Occasion        mean_bikes median_bikes\n  &lt;chr&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n1 Fourth of July        10.0          9  \n2 Normal Thursday       24.2         14.5\n\n\n\n\n\n\nWhy pipe?\n\n\n\n\nYou can also use |&gt;, which is newer and often referred to as the “base R pipe.”"
  },
  {
    "objectID": "stat100_wk03wed.html#measures-of-variability",
    "href": "stat100_wk03wed.html#measures-of-variability",
    "title": "Stat 100",
    "section": "Measures of Variability",
    "text": "Measures of Variability\n\nWant a statistic that captures how much observations deviate from the mean\n\n\n\n\nFind how much each observation deviates from the mean.\nCompute the average of the deviations.\n\n\\[\n\\frac{1}{n} \\sum_{i = 1}^n (x_i - \\bar{x})\n\\]\n\n\n# Test out on first 6 values\nhead(july_2019$Total)\n\n[1] 2 3 2 0 3 2\n\n\n\n\n\nProblem?"
  },
  {
    "objectID": "stat100_wk03wed.html#measures-of-variability-1",
    "href": "stat100_wk03wed.html#measures-of-variability-1",
    "title": "Stat 100",
    "section": "Measures of Variability",
    "text": "Measures of Variability\n\nWant a statistic that captures how much observations deviate from the mean\n\n\n\nHere is my NEW proposal:\n\nFind how much each observation deviates from the mean.\nCompute the average of the squared deviations.\n\n\n\n# Test out on first 6 values\nhead(july_2019$Total)\n\n[1] 2 3 2 0 3 2"
  },
  {
    "objectID": "stat100_wk03wed.html#measures-of-variability-2",
    "href": "stat100_wk03wed.html#measures-of-variability-2",
    "title": "Stat 100",
    "section": "Measures of Variability",
    "text": "Measures of Variability\n\nWant a statistic that captures how much observations deviate from the mean\n\n\n\nHere is my ACTUAL formula:\n\nFind how much each observation deviates from the mean.\nCompute the (nearly) average of the squared deviations.\nCalled sample variance \\(s^2\\).\n\n\\[\ns^2 = \\frac{1}{n - 1} \\sum_{i = 1}^n (x_i - \\bar{x})^2\n\\]\n\nCompute with a dplyr function:\n\nsummarize(july_2019, var_bikes = var(Total))\n\n# A tibble: 1 × 1\n  var_bikes\n      &lt;dbl&gt;\n1      454."
  },
  {
    "objectID": "stat100_wk03wed.html#measures-of-variability-3",
    "href": "stat100_wk03wed.html#measures-of-variability-3",
    "title": "Stat 100",
    "section": "Measures of Variability",
    "text": "Measures of Variability\n\nWant a statistic that captures how much observations deviate from the mean\n\n\n\n\nFind how much each observation deviates from the mean.\nCompute the (nearly) average of the squared deviations.\nCalled sample variance \\(s^2\\).\nThe square root of the sample variance is called the sample standard deviation \\(s\\).\n\n\\[\ns = \\sqrt{\\frac{1}{n - 1} \\sum_{i = 1}^n (x_i - \\bar{x})^2}\n\\]\n\nCompute with a dplyr function:\n\nsummarize(july_2019, var_bikes = var(Total),\n          sd_bikes = sd(Total))\n\n# A tibble: 1 × 2\n  var_bikes sd_bikes\n      &lt;dbl&gt;    &lt;dbl&gt;\n1      454.     21.3"
  },
  {
    "objectID": "stat100_wk03wed.html#measures-of-variability-4",
    "href": "stat100_wk03wed.html#measures-of-variability-4",
    "title": "Stat 100",
    "section": "Measures of Variability",
    "text": "Measures of Variability\n\n\n\nIn addition to the sample standard deviation and the sample variance, there is the sample interquartile range (IQR):\n\n\\[\n\\mbox{IQR} = \\mbox{Q}_3 - \\mbox{Q}_1\n\\]\n\nCompute with a dplyr function:\n\nsummarize(july_2019, iqr_bikes = IQR(Total))\n\n# A tibble: 1 × 1\n  iqr_bikes\n      &lt;dbl&gt;\n1        16"
  },
  {
    "objectID": "stat100_wk03wed.html#comparing-measures-of-variability",
    "href": "stat100_wk03wed.html#comparing-measures-of-variability",
    "title": "Stat 100",
    "section": "Comparing Measures of Variability",
    "text": "Comparing Measures of Variability\n\nWhich is more robust to outliers, the IQR or \\(s\\)?\nWhich is more commonly used, the IQR or \\(s\\)?\n\n\njuly_2019 %&gt;%\n  group_by(Occasion) %&gt;%\nsummarize(sd_bikes = sd(Total),\n          iqr_bikes = IQR(Total))\n\n# A tibble: 2 × 3\n  Occasion        sd_bikes iqr_bikes\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;\n1 Fourth of July      8.30      14  \n2 Normal Thursday    27.2       27.2"
  },
  {
    "objectID": "stat100_wk03wed.html#return-to-the-cambridge-dogs",
    "href": "stat100_wk03wed.html#return-to-the-cambridge-dogs",
    "title": "Stat 100",
    "section": "Return to the Cambridge Dogs",
    "text": "Return to the Cambridge Dogs\nFocus on the dogs with the 5 most common names\n\ndogs &lt;- read_csv(\"https://data.cambridgema.gov/api/views/sckh-3xyx/rows.csv\")\n\n# Useful wrangling that we will come back to\ndogs_top5 &lt;- dogs %&gt;% \n  mutate(Breed = case_when(\n                       Dog_Breed == \"Mixed Breed\" ~ \"Mixed\",\n                       Dog_Breed != \"Mixed Breed\" ~ \"Single\")) %&gt;%\n  filter(Dog_Name %in% c(\"Luna\", \"Charlie\", \"Lucy\", \"Cooper\", \"Rosie\" ))"
  },
  {
    "objectID": "stat100_wk03wed.html#frequency-table",
    "href": "stat100_wk03wed.html#frequency-table",
    "title": "Stat 100",
    "section": "Frequency Table",
    "text": "Frequency Table\n\n\n\ncount(dogs_top5, Dog_Name)\n\n# A tibble: 5 × 2\n  Dog_Name     n\n  &lt;chr&gt;    &lt;int&gt;\n1 Charlie     35\n2 Cooper      23\n3 Lucy        25\n4 Luna        41\n5 Rosie       22\n\n\n\n\nggplot(data = dogs_top5, \n    mapping = aes(x = Dog_Name)) +\n  geom_bar()"
  },
  {
    "objectID": "stat100_wk03wed.html#frequency-table-1",
    "href": "stat100_wk03wed.html#frequency-table-1",
    "title": "Stat 100",
    "section": "Frequency Table",
    "text": "Frequency Table\n\n\n\ncount(dogs_top5, Dog_Name)\n\n# A tibble: 5 × 2\n  Dog_Name     n\n  &lt;chr&gt;    &lt;int&gt;\n1 Charlie     35\n2 Cooper      23\n3 Lucy        25\n4 Luna        41\n5 Rosie       22\n\n\n\n\ncount(dogs_top5, Dog_Name, sort = TRUE)\n\n# A tibble: 5 × 2\n  Dog_Name     n\n  &lt;chr&gt;    &lt;int&gt;\n1 Luna        41\n2 Charlie     35\n3 Lucy        25\n4 Cooper      23\n5 Rosie       22"
  },
  {
    "objectID": "stat100_wk03wed.html#contingency-table",
    "href": "stat100_wk03wed.html#contingency-table",
    "title": "Stat 100",
    "section": "Contingency Table",
    "text": "Contingency Table\n\n\n\ncount(dogs_top5, Dog_Name, Breed)\n\n# A tibble: 10 × 3\n   Dog_Name Breed      n\n   &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt;\n 1 Charlie  Mixed     12\n 2 Charlie  Single    23\n 3 Cooper   Mixed      9\n 4 Cooper   Single    14\n 5 Lucy     Mixed     10\n 6 Lucy     Single    15\n 7 Luna     Mixed     16\n 8 Luna     Single    25\n 9 Rosie    Mixed      6\n10 Rosie    Single    16\n\n\n\n\nggplot(data = dogs_top5, \n    mapping = aes(x = Dog_Name, fill = Breed)) +\n  geom_bar(position = \"dodge\")"
  },
  {
    "objectID": "stat100_wk03wed.html#conditional-proportions",
    "href": "stat100_wk03wed.html#conditional-proportions",
    "title": "Stat 100",
    "section": "Conditional Proportions",
    "text": "Conditional Proportions\n\n\n\nBeyond raw counts, we often summarize categorical data with conditional proportions.\n\nEspecially when looking for relationships!\n\n\n\n\nggplot(data = dogs_top5, \n    mapping = aes(x = Dog_Name, fill = Breed)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "stat100_wk03wed.html#conditional-proportions-1",
    "href": "stat100_wk03wed.html#conditional-proportions-1",
    "title": "Stat 100",
    "section": "Conditional Proportions",
    "text": "Conditional Proportions\n\n\n\ncount(dogs_top5, Dog_Name, Breed)\n\n# A tibble: 10 × 3\n   Dog_Name Breed      n\n   &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt;\n 1 Charlie  Mixed     12\n 2 Charlie  Single    23\n 3 Cooper   Mixed      9\n 4 Cooper   Single    14\n 5 Lucy     Mixed     10\n 6 Lucy     Single    15\n 7 Luna     Mixed     16\n 8 Luna     Single    25\n 9 Rosie    Mixed      6\n10 Rosie    Single    16\n\n\n\n\ncount(dogs_top5, Dog_Name, Breed) %&gt;%\n  group_by(Dog_Name) %&gt;%\n  mutate(prop = n/sum(n))\n\n# A tibble: 10 × 4\n# Groups:   Dog_Name [5]\n   Dog_Name Breed      n  prop\n   &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;\n 1 Charlie  Mixed     12 0.343\n 2 Charlie  Single    23 0.657\n 3 Cooper   Mixed      9 0.391\n 4 Cooper   Single    14 0.609\n 5 Lucy     Mixed     10 0.4  \n 6 Lucy     Single    15 0.6  \n 7 Luna     Mixed     16 0.390\n 8 Luna     Single    25 0.610\n 9 Rosie    Mixed      6 0.273\n10 Rosie    Single    16 0.727\n\n\n\n\n\nThe dplyr function mutate() adds new column(s) to your data frame."
  },
  {
    "objectID": "stat100_wk03wed.html#conditional-proportions-2",
    "href": "stat100_wk03wed.html#conditional-proportions-2",
    "title": "Stat 100",
    "section": "Conditional Proportions",
    "text": "Conditional Proportions\n\n\n\ncount(dogs_top5, Dog_Name, Breed) %&gt;%\n  group_by(Dog_Name) %&gt;%\n  mutate(prop = n/sum(n))\n\n# A tibble: 10 × 4\n# Groups:   Dog_Name [5]\n   Dog_Name Breed      n  prop\n   &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;\n 1 Charlie  Mixed     12 0.343\n 2 Charlie  Single    23 0.657\n 3 Cooper   Mixed      9 0.391\n 4 Cooper   Single    14 0.609\n 5 Lucy     Mixed     10 0.4  \n 6 Lucy     Single    15 0.6  \n 7 Luna     Mixed     16 0.390\n 8 Luna     Single    25 0.610\n 9 Rosie    Mixed      6 0.273\n10 Rosie    Single    16 0.727\n\n\n\n\ncount(dogs_top5, Dog_Name, Breed) %&gt;%\n  group_by(Breed) %&gt;%\n  mutate(prop = n/sum(n))\n\n# A tibble: 10 × 4\n# Groups:   Breed [2]\n   Dog_Name Breed      n  prop\n   &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;\n 1 Charlie  Mixed     12 0.226\n 2 Charlie  Single    23 0.247\n 3 Cooper   Mixed      9 0.170\n 4 Cooper   Single    14 0.151\n 5 Lucy     Mixed     10 0.189\n 6 Lucy     Single    15 0.161\n 7 Luna     Mixed     16 0.302\n 8 Luna     Single    25 0.269\n 9 Rosie    Mixed      6 0.113\n10 Rosie    Single    16 0.172\n\n\n\n\nHow does the interpretation change based on which variable you condition on?"
  },
  {
    "objectID": "stat100_wk03wed.html#dplyr-for-data-wrangling",
    "href": "stat100_wk03wed.html#dplyr-for-data-wrangling",
    "title": "Stat 100",
    "section": "dplyr for Data Wrangling",
    "text": "dplyr for Data Wrangling\n\nSeven common wrangling verbs:\n\nsummarize()\ncount()\n\nmutate()\n\nselect()\nfilter()\narrange()\n---_join()\n\nOne action:\n\ngroup_by()"
  },
  {
    "objectID": "stat100_wk03wed.html#return-to-mutate",
    "href": "stat100_wk03wed.html#return-to-mutate",
    "title": "Stat 100",
    "section": "Return to mutate()",
    "text": "Return to mutate()\n\n\nAdd new variables\n\ncount(dogs_top5, Dog_Name, Breed) %&gt;%\n  group_by(Dog_Name) %&gt;%\n  mutate(prop = n/sum(n))\n\n# A tibble: 10 × 4\n# Groups:   Dog_Name [5]\n   Dog_Name Breed      n  prop\n   &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt; &lt;dbl&gt;\n 1 Charlie  Mixed     12 0.343\n 2 Charlie  Single    23 0.657\n 3 Cooper   Mixed      9 0.391\n 4 Cooper   Single    14 0.609\n 5 Lucy     Mixed     10 0.4  \n 6 Lucy     Single    15 0.6  \n 7 Luna     Mixed     16 0.390\n 8 Luna     Single    25 0.610\n 9 Rosie    Mixed      6 0.273\n10 Rosie    Single    16 0.727\n\n\n\nModify existing variables\n\nclass(july_2019$DateTime)\n\n[1] \"character\"\n\njuly_2019 &lt;- july_2019 %&gt;%\n  mutate(DateTime = mdy_hms(DateTime))\nclass(july_2019$DateTime)\n\n[1] \"POSIXct\" \"POSIXt\""
  },
  {
    "objectID": "stat100_wk03wed.html#select-extract-variables",
    "href": "stat100_wk03wed.html#select-extract-variables",
    "title": "Stat 100",
    "section": "select(): Extract variables",
    "text": "select(): Extract variables\n\ndogs %&gt;%\n  select(Dog_Name, Dog_Breed)\n\n# A tibble: 3,942 × 2\n   Dog_Name       Dog_Breed                 \n   &lt;chr&gt;          &lt;chr&gt;                     \n 1 Butch          Mixed Breed               \n 2 Baxter         Mixed Breed               \n 3 Bodhi          Golden Retriever          \n 4 Ocean          Pug                       \n 5 Coco           Pug                       \n 6 Brio           LABRADOODLE               \n 7 Jolene Almeida German Shorthaired Pointer\n 8 Ruger          Labrador Retriever        \n 9 FLASH          Border Collie             \n10 Leo            French Bulldog            \n# ℹ 3,932 more rows"
  },
  {
    "objectID": "stat100_wk03wed.html#motivation-for-filter",
    "href": "stat100_wk03wed.html#motivation-for-filter",
    "title": "Stat 100",
    "section": "Motivation for filter()",
    "text": "Motivation for filter()\n\ncount(dogs, Dog_Name, sort = TRUE)\n\n# A tibble: 2,332 × 2\n   Dog_Name     n\n   &lt;chr&gt;    &lt;int&gt;\n 1 Luna        41\n 2 Charlie     35\n 3 Lucy        25\n 4 Cooper      23\n 5 Rosie       22\n 6 Olive       21\n 7 Pepper      20\n 8 Teddy       19\n 9 Coco        18\n10 Lola        17\n# ℹ 2,322 more rows"
  },
  {
    "objectID": "stat100_wk03wed.html#filter-extract-cases",
    "href": "stat100_wk03wed.html#filter-extract-cases",
    "title": "Stat 100",
    "section": "filter(): Extract cases",
    "text": "filter(): Extract cases\n\ndogs_top5 &lt;- dogs %&gt;% \n  filter(Dog_Name %in% c(\"Luna\", \"Charlie\", \"Lucy\", \"Cooper\", \"Rosie\" ))\n\ncount(dogs_top5, Dog_Name, sort = TRUE)\n\n# A tibble: 5 × 2\n  Dog_Name     n\n  &lt;chr&gt;    &lt;int&gt;\n1 Luna        41\n2 Charlie     35\n3 Lucy        25\n4 Cooper      23\n5 Rosie       22"
  },
  {
    "objectID": "stat100_wk03wed.html#arrange-sort-the-cases",
    "href": "stat100_wk03wed.html#arrange-sort-the-cases",
    "title": "Stat 100",
    "section": "arrange(): Sort the cases",
    "text": "arrange(): Sort the cases\n\n\n\ncount(dogs_top5, Dog_Name) %&gt;%\n  arrange(n)\n\n# A tibble: 5 × 2\n  Dog_Name     n\n  &lt;chr&gt;    &lt;int&gt;\n1 Rosie       22\n2 Cooper      23\n3 Lucy        25\n4 Charlie     35\n5 Luna        41\n\ncount(dogs_top5, Dog_Name) %&gt;%\n  arrange(desc(n))\n\n# A tibble: 5 × 2\n  Dog_Name     n\n  &lt;chr&gt;    &lt;int&gt;\n1 Luna        41\n2 Charlie     35\n3 Lucy        25\n4 Cooper      23\n5 Rosie       22\n\n\n\n\ncount(dogs_top5, Dog_Name) %&gt;%\n  arrange(Dog_Name)\n\n# A tibble: 5 × 2\n  Dog_Name     n\n  &lt;chr&gt;    &lt;int&gt;\n1 Charlie     35\n2 Cooper      23\n3 Lucy        25\n4 Luna        41\n5 Rosie       22"
  },
  {
    "objectID": "stat100_wk03wed.html#reminders",
    "href": "stat100_wk03wed.html#reminders",
    "title": "Stat 100",
    "section": "Reminders",
    "text": "Reminders\n\nWith COVID working its way through campus right now, make sure to check the Sections spreadsheet and the Office hours spreadsheet for updates!"
  },
  {
    "objectID": "stat100_wk01wed.html#keyword",
    "href": "stat100_wk01wed.html#keyword",
    "title": "Stat 100",
    "section": "",
    "text": "What words or phrases do you think of when you hear the word “Harvard”?\n\n\nThis being a data class, I’d like to collect some data related to “statistical thinking.”\n\n\nGo to bit.ly/stat-100-think to provide the words or phrases you think of when you hear “statistical thinking.”"
  },
  {
    "objectID": "stat100_wk01wed.html#getting-started-in-stat-100",
    "href": "stat100_wk01wed.html#getting-started-in-stat-100",
    "title": "Stat 100",
    "section": "Getting Started in Stat 100",
    "text": "Getting Started in Stat 100\nStep 1: Getting Started Module in Canvas"
  },
  {
    "objectID": "stat100_wk01wed.html#stat-100-tech-materials",
    "href": "stat100_wk01wed.html#stat-100-tech-materials",
    "title": "Stat 100",
    "section": "Stat 100 Tech & Materials",
    "text": "Stat 100 Tech & Materials"
  },
  {
    "objectID": "stat100_wk01wed.html#announcements",
    "href": "stat100_wk01wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nLecture slide decks will always be posted and linked to a Canvas Module the day before lecture.\n\nWill also bring printed versions for those who prefer paper copies.\n\nNo section and no lecture quiz this week.\n\nBut be on the look-out for section preference form from my.harvard.\n\nOnly I will be running office hours this week at the following time:\n\nToday 1:30 - 3:00 pm in Science Center 316 (This week only)\n\nThe regular office hour schedule will be posted later this week and will start next week.\nIf able, please bring a laptop or tablet to Mondays’s lecture."
  },
  {
    "objectID": "stat100_wk01wed.html#day-1-goals",
    "href": "stat100_wk01wed.html#day-1-goals",
    "title": "Stat 100",
    "section": "Day 1 Goals",
    "text": "Day 1 Goals\n\nStart engaging in statistical thinking\nIntroduce data\nConsider hand-drawn visualizations as a way to tell stories with data\nHop into the RStudio Server using Posit Cloud"
  },
  {
    "objectID": "stat100_wk01wed.html#looking-ahead-to-day-2",
    "href": "stat100_wk01wed.html#looking-ahead-to-day-2",
    "title": "Stat 100",
    "section": "Looking Ahead to Day 2…",
    "text": "Looking Ahead to Day 2…\n\nDiscuss course structure (lecture, section, wrap-ups, office hours, assessments…)\nPresent important course policies (engagement, code of conduct, chatGPT, …)\nGet started in RStudio and with Quarto documents"
  },
  {
    "objectID": "stat100_wk01wed.html#research-interests",
    "href": "stat100_wk01wed.html#research-interests",
    "title": "Stat 100",
    "section": "Research Interests",
    "text": "Research Interests\nSurvey statistics and collaborate with"
  },
  {
    "objectID": "stat100_wk01wed.html#research-interests-1",
    "href": "stat100_wk01wed.html#research-interests-1",
    "title": "Stat 100",
    "section": "Research Interests",
    "text": "Research Interests\nWhere survey statistics meets data science"
  },
  {
    "objectID": "stat100_wk01wed.html#stat-100-is-about-developing-our-statistical-thinking-skills.",
    "href": "stat100_wk01wed.html#stat-100-is-about-developing-our-statistical-thinking-skills.",
    "title": "Stat 100",
    "section": "Stat 100 is about developing our statistical thinking skills.",
    "text": "Stat 100 is about developing our statistical thinking skills.\n\n\nWhat is statistical thinking?\n\n\n\nIt is not the same as mathematical thinking.\n\n\n\nLet’s discover what statistical thinking is through some examples."
  },
  {
    "objectID": "stat100_wk01wed.html#data-in-stat-100",
    "href": "stat100_wk01wed.html#data-in-stat-100",
    "title": "Stat 100",
    "section": "Data in Stat 100",
    "text": "Data in Stat 100\nWill use a wide-range of real and relevant data examples"
  },
  {
    "objectID": "stat100_wk01wed.html#data-in-stat-100-1",
    "href": "stat100_wk01wed.html#data-in-stat-100-1",
    "title": "Stat 100",
    "section": "Data in Stat 100",
    "text": "Data in Stat 100\n\n\n\n\n\n\n\n\nI understand that some of these topics have likely had profound impacts on your lives.\nWe will focus class time on the key course objectives but will use these current topics to empower ourselves and to see how we can productively participate with data."
  },
  {
    "objectID": "stat100_wk01wed.html#statistical-thinking",
    "href": "stat100_wk01wed.html#statistical-thinking",
    "title": "Stat 100",
    "section": "Statistical Thinking",
    "text": "Statistical Thinking\n\n\n\nUnderstanding the importance of context.\n\n\n\n Context explains the Monday jumps in the COVID counts.\n\n\n\n\n\n\nHow we encode information in a graph should be driven by our research question.\n\n\n\n Design choices impact the conclusions the viewer draws.\n\n\n\n\n\n\nHow the data are collected impacts the conclusions we can draw.\n\n\n\n Voluntary COVID test results don’t likely provide good estimates of COVID prevalence.\n\n\n\n\n\n\nOften we are using a sample of data to say something about a larger group. In this case, we should measure how certain our estimates are!\n\n\n\n We will learn to compute and interpret certainty estimates (like those in the wastewater graph) later in the course!"
  },
  {
    "objectID": "stat100_wk01wed.html#statistical-thinking-1",
    "href": "stat100_wk01wed.html#statistical-thinking-1",
    "title": "Stat 100",
    "section": "Statistical Thinking",
    "text": "Statistical Thinking\n\nAbout developing reasoning (not just learning definitions and formulae).\nDeveloping our statistical thinking skills will allow us to soundly extract knowledge from data!\nStatistical thinking requires judgment that takes time to develop.\n\nWill see examples and practice applying statistical thinking throughout the course."
  },
  {
    "objectID": "stat100_wk01wed.html#what-areis-data",
    "href": "stat100_wk01wed.html#what-areis-data",
    "title": "Stat 100",
    "section": "What are/is Data?",
    "text": "What are/is Data?\n\n\n\n“‘Raw data’ is an oxymoron.” – Lisa Gitelman\n\n\n\n“Data … is information made tractable.” – Catherine D’Ignazio and Lauren Klein"
  },
  {
    "objectID": "stat100_wk01wed.html#data-frames",
    "href": "stat100_wk01wed.html#data-frames",
    "title": "Stat 100",
    "section": "Data Frames",
    "text": "Data Frames\nData in spreadsheet-like format where:\n\nRows = Observations/cases\nColumns = Variables\n\n\n\n\n\n\n\nID\nkind\n.pred_AI\n.pred_class\ndetector\nnative\nname\nmodel\n\n\n\n\n1\nHuman\n0.9999942\nAI\nSapling\nNo\nReal TOEFL\nHuman\n\n\n2\nHuman\n0.8281448\nAI\nCrossplag\nNo\nReal TOEFL\nHuman\n\n\n3\nHuman\n0.0002137\nHuman\nCrossplag\nYes\nReal College Essays\nHuman\n\n\n4\nAI\n0.0000000\nHuman\nZeroGPT\nNA\nFake CS224N - GPT3\nGPT3\n\n\n5\nAI\n0.0017841\nHuman\nOriginalityAI\nNA\nFake CS224N - GPT3, PE\nGPT4\n\n\n6\nHuman\n0.0001783\nHuman\nHFOpenAI\nYes\nReal CS224N\nHuman\n\n\n\n\n\n\n\n\n\nData from GPT Detectors Are Biased Against Non-Native English Writers. Weixin Liang, Mert Yuksekgonul, Yining Mao, Eric Wu, James Zou. CellPress Patterns and available in the R package detectors."
  },
  {
    "objectID": "stat100_wk01wed.html#data-frames-1",
    "href": "stat100_wk01wed.html#data-frames-1",
    "title": "Stat 100",
    "section": "Data Frames",
    "text": "Data Frames\n\n\n\n\n\n\nID\nkind\n.pred_AI\n.pred_class\ndetector\nnative\nname\nmodel\n\n\n\n\n1\nHuman\n0.9999942\nAI\nSapling\nNo\nReal TOEFL\nHuman\n\n\n2\nHuman\n0.8281448\nAI\nCrossplag\nNo\nReal TOEFL\nHuman\n\n\n3\nHuman\n0.0002137\nHuman\nCrossplag\nYes\nReal College Essays\nHuman\n\n\n4\nAI\n0.0000000\nHuman\nZeroGPT\nNA\nFake CS224N - GPT3\nGPT3\n\n\n5\nAI\n0.0017841\nHuman\nOriginalityAI\nNA\nFake CS224N - GPT3, PE\nGPT4\n\n\n6\nHuman\n0.0001783\nHuman\nHFOpenAI\nYes\nReal CS224N\nHuman\n\n\n\n\n\n\n\n\nRows = Observations/cases\nWhat are the cases? What does each row represent?"
  },
  {
    "objectID": "stat100_wk01wed.html#data-frames-2",
    "href": "stat100_wk01wed.html#data-frames-2",
    "title": "Stat 100",
    "section": "Data Frames",
    "text": "Data Frames\n\n\n\n\n\n\nID\nkind\n.pred_AI\n.pred_class\ndetector\nnative\nname\nmodel\n\n\n\n\n1\nHuman\n0.9999942\nAI\nSapling\nNo\nReal TOEFL\nHuman\n\n\n2\nHuman\n0.8281448\nAI\nCrossplag\nNo\nReal TOEFL\nHuman\n\n\n3\nHuman\n0.0002137\nHuman\nCrossplag\nYes\nReal College Essays\nHuman\n\n\n4\nAI\n0.0000000\nHuman\nZeroGPT\nNA\nFake CS224N - GPT3\nGPT3\n\n\n5\nAI\n0.0017841\nHuman\nOriginalityAI\nNA\nFake CS224N - GPT3, PE\nGPT4\n\n\n6\nHuman\n0.0001783\nHuman\nHFOpenAI\nYes\nReal CS224N\nHuman\n\n\n\n\n\n\n\n\nColumns = Variables\nVariables: Describe characteristics of the observations\n\nQuantitative: Numerical in nature\nCategorical: Values are categories\nIdentification: Uniquely identify each case"
  },
  {
    "objectID": "stat100_wk01wed.html#hand-drawn-data-viz",
    "href": "stat100_wk01wed.html#hand-drawn-data-viz",
    "title": "Stat 100",
    "section": "Hand-Drawn Data Viz",
    "text": "Hand-Drawn Data Viz\n\nOnce we have collected data, a common next step is to visualize it.\nTwo key aspects of data visualization:\n\nDetermining how you want to display the data.\nFiguring out how to tell the computer to do that mapping.\n\nHand-drawn data visualizations allow us to focus on the first part with full control over the creative process!"
  },
  {
    "objectID": "stat100_wk01wed.html#hand-drawn-data-viz-examples",
    "href": "stat100_wk01wed.html#hand-drawn-data-viz-examples",
    "title": "Stat 100",
    "section": "Hand-Drawn Data Viz Examples",
    "text": "Hand-Drawn Data Viz Examples\nDear Data\n\n“Each week, and for a year, we collected and measured a particular type of data about our lives, used this data to make a drawing on a postcard-sized sheet of paper, and then dropped the postcard in an English”postbox” (Stefanie) or an American “mailbox” (Giorgia)!“"
  },
  {
    "objectID": "stat100_wk01wed.html#goal-by-next-wed-collect-data-from-your-life-so-that-you-can-visualize-it-on-p-set-1.",
    "href": "stat100_wk01wed.html#goal-by-next-wed-collect-data-from-your-life-so-that-you-can-visualize-it-on-p-set-1.",
    "title": "Stat 100",
    "section": "Goal: By next Wed, collect data from your life so that you can visualize it on P-Set 1.",
    "text": "Goal: By next Wed, collect data from your life so that you can visualize it on P-Set 1.\n\n\n\nRecommendations\n\n\nStore the data in your favorite spreadsheet program (Google Sheets, Numbers, Excel).\nDetermine what your cases/observations will be.\nCollect data on more variables than you will likely visualize. It is hard to know beforehand what the interesting relationships will be.\n\n\n\nNext Week\n\nWill get a blank postcard and further guidance on the visualization with P-Set 1."
  },
  {
    "objectID": "stat100_wk01wed.html#section",
    "href": "stat100_wk01wed.html#section",
    "title": "Stat 100",
    "section": "",
    "text": "Demo of accessing the RStudio Server on Posit Cloud\n\n\nTry to access the RStudio Server between now and next lecture.\nCome back to the recording if need help with the steps."
  },
  {
    "objectID": "stat100_wk01wed.html#reminders",
    "href": "stat100_wk01wed.html#reminders",
    "title": "Stat 100",
    "section": "Reminders",
    "text": "Reminders\n\nIf able, please bring a laptop or tablet to Mondays’s lecture.\nNo section, no wrap-ups, and no lecture quiz this week.\nMake sure to go through the syllabus, which can be found on Canvas.\n\nWill discuss assessments and course policies on Monday.\n\nOnly I will be running office hours this week at the following time:\n\nToday 1:30 - 3:00 pm in Science Center 316 (This week only)\n\nThe regular office hour schedule will be posted later this week and will start next week.\nBe on the look-out for the section preference form."
  },
  {
    "objectID": "stat100_wk10mon.html#announcements",
    "href": "stat100_wk10mon.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\n🎉 We are now accepting Course Assistant/Teaching Fellow applications for Stat 100 for next semester. To apply, fill out this application by Nov 15th.\n\nAbout 10-12 hours of work per week.\n\nPrimary responsibilities: Attend weekly team meetings, lead a discussion section, hold office hours, grade assessments.\n\n\nGoals for Today\n\n\n\nLearn the language of hypothesis testing (including p-values)\nPractice framing research questions in terms of hypotheses\n\n\n\nLearn how to generate null distributions\nUse infer to conduct hypothesis tests in R"
  },
  {
    "objectID": "stat100_wk10mon.html#generating-null-distributions",
    "href": "stat100_wk10mon.html#generating-null-distributions",
    "title": "Stat 100",
    "section": "Generating Null Distributions",
    "text": "Generating Null Distributions\nFor the sample proportion in the ESP Example:\n\n\nSteps:\n\nFlip unfair coin (prop heads = 0.25) 329 times.\nCompute proportion of heads.\nRepeat 1 and 2 many times.\n\n\n\nR code using the infer package:\n\nlibrary(infer)\n\n# Construct data frame of sample results\nesp &lt;- data.frame(guess = c(rep(\"correct\", 106),\n                            rep(\"incorrect\",\n                                329 - 106)))\n\n# Generate Null Distribution\nnull_dist &lt;- esp %&gt;%\n  specify(response = guess, success = \"correct\") %&gt;%\n  hypothesize(null = \"point\", p = 0.25) %&gt;%\n  generate(reps = 1000, type = \"draw\") %&gt;%\n  calculate(stat =\"prop\")\n\n\n\n\n\nFor different variable types, we will need to move beyond using a coin to conceptualize the null distribution."
  },
  {
    "objectID": "stat100_wk10mon.html#hypothesis-testing-in-r",
    "href": "stat100_wk10mon.html#hypothesis-testing-in-r",
    "title": "Stat 100",
    "section": "Hypothesis Testing in R",
    "text": "Hypothesis Testing in R\n\n\n# Compute observed test statistic\ntest_stat &lt;- esp %&gt;%\n  specify(response = guess, success = \"correct\") %&gt;%\n  calculate(stat =\"prop\")\ntest_stat\n\n\nResponse: guess (factor)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1 0.322\n\ntest_stat &lt;- 106/329\ntest_stat\n\n[1] 0.3221884"
  },
  {
    "objectID": "stat100_wk10mon.html#hypothesis-testing-in-r-1",
    "href": "stat100_wk10mon.html#hypothesis-testing-in-r-1",
    "title": "Stat 100",
    "section": "Hypothesis Testing in R",
    "text": "Hypothesis Testing in R\n\n\n# Graph null distribution with test statistic\nvisualize(null_dist) +\n  geom_vline(xintercept = test_stat,\n             color = \"deeppink\", size = 2)"
  },
  {
    "objectID": "stat100_wk10mon.html#hypothesis-testing-in-r-2",
    "href": "stat100_wk10mon.html#hypothesis-testing-in-r-2",
    "title": "Stat 100",
    "section": "Hypothesis Testing in R",
    "text": "Hypothesis Testing in R\n\n\n# Compute p-value\np_value &lt;- null_dist %&gt;%\n  get_p_value(obs_stat = test_stat,\n              direction = \"right\")\np_value\n\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1   0.002\n\n\n\n\nInterpretation of \\(p\\)-value: If ESP doesn’t exist, the probability of observing 106 or more correct identifications out of 329 trials equals 0.002.\n\n\nConclusion: Since it is so unlikely (i.e., practically impossible) to have seen such unusual results if ESP doesn’t exist, these data suggest that ESP does exist."
  },
  {
    "objectID": "stat100_wk10mon.html#penguins-example",
    "href": "stat100_wk10mon.html#penguins-example",
    "title": "Stat 100",
    "section": "Penguins Example",
    "text": "Penguins Example\nLet’s return to the penguins data and ask if flipper length varies, on average, by the sex of the penguin.\nResearch Question: Does flipper length differ by sex?\nResponse Variable:\n\nExplanatory Variable:\n\nStatistical Hypotheses:"
  },
  {
    "objectID": "stat100_wk10mon.html#exploratory-data-analysis",
    "href": "stat100_wk10mon.html#exploratory-data-analysis",
    "title": "Stat 100",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\n\nlibrary(palmerpenguins)\n\npenguins %&gt;%\n  drop_na(sex) %&gt;%\nggplot(mapping = aes(x = sex,\n                     y = flipper_length_mm)) +\n  geom_boxplot()"
  },
  {
    "objectID": "stat100_wk10mon.html#two-sided-hypothesis-test",
    "href": "stat100_wk10mon.html#two-sided-hypothesis-test",
    "title": "Stat 100",
    "section": "Two-Sided Hypothesis Test",
    "text": "Two-Sided Hypothesis Test\n\n\n# Compute observed test statistic\ntest_stat &lt;- penguins %&gt;%\n  drop_na(sex) %&gt;%\n  specify(flipper_length_mm ~ sex) %&gt;%\n  calculate(stat =\"diff in means\",\n            order = c(\"female\", \"male\"))\ntest_stat\n\n\nResponse: flipper_length_mm (numeric)\nExplanatory: sex (factor)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1 -7.14\n\n\n\n\n# Generate null distribution \nnull_dist &lt;- penguins %&gt;%\n  drop_na(sex) %&gt;%\n  specify(flipper_length_mm ~ sex) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 1000, type = \"permute\") %&gt;%\n  calculate(stat =\"diff in means\",\n            order = c(\"female\", \"male\"))"
  },
  {
    "objectID": "stat100_wk10mon.html#two-sided-hypothesis-test-1",
    "href": "stat100_wk10mon.html#two-sided-hypothesis-test-1",
    "title": "Stat 100",
    "section": "Two-Sided Hypothesis Test",
    "text": "Two-Sided Hypothesis Test\n\n\n# Graph null distribution with test statistic\nvisualize(null_dist) +\n  geom_vline(xintercept = test_stat$stat,\n             color = \"deeppink\", size = 2) +\n  geom_vline(xintercept = abs(test_stat$stat),\n             color = \"deeppink\", size = 2)"
  },
  {
    "objectID": "stat100_wk10mon.html#two-sided-hypothesis-test-2",
    "href": "stat100_wk10mon.html#two-sided-hypothesis-test-2",
    "title": "Stat 100",
    "section": "Two-Sided Hypothesis Test",
    "text": "Two-Sided Hypothesis Test\n\n\n# Compute p-value\np_value &lt;- null_dist %&gt;%\n  get_p_value(obs_stat = test_stat,\n              direction = \"two_sided\")\np_value\n\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0\n\n\n\nInterpretation of \\(p\\)-value: If the mean flipper length does not differ by sex in the population, the probability of observing a difference in the sample means of at least 7.142316 mm (in magnitude) is equal to 0.\nConclusion: These data represent evidence that flipper length does vary by sex."
  },
  {
    "objectID": "stat100_wk10mon.html#reminders",
    "href": "stat100_wk10mon.html#reminders",
    "title": "Stat 100",
    "section": "Reminders:",
    "text": "Reminders:\n\n\n🎉 We are now accepting Course Assistant/Teaching Fellow applications for Stat 100 for next semester. To apply, fill out this application by Nov 15th.\n\nAbout 10-12 hours of work per week.\n\nPrimary responsibilities: Attend weekly team meetings, lead a discussion section, hold office hours, grade assessments."
  },
  {
    "objectID": "stat100_wk11mon.html#announcements",
    "href": "stat100_wk11mon.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\n🎉 We are now accepting Course Assistant/Teaching Fellow applications for Stat 100 for next semester. To apply, fill out this application by Nov 15th.\nYou are all invited to the Info Session on Data Science Internships today at 4pm in SC 316!\n\nGoals for Today\n\n\n\nFinish discussion power\nStatistical inference zoom out\n\n\n\nA hearty p-values discussion\nKey probability concepts"
  },
  {
    "objectID": "stat100_wk11mon.html#thoughts-on-power",
    "href": "stat100_wk11mon.html#thoughts-on-power",
    "title": "Stat 100",
    "section": "Thoughts on Power",
    "text": "Thoughts on Power\n\n\n\nWhat aspects of the test did the player actually have control over?\nWhy is it easier to set \\(\\alpha\\) than to set \\(\\beta\\) or power?\nConsidering power before conducting a study is very important!\nThe danger of under-powered studies\n\nEX: Turning right at a red light"
  },
  {
    "objectID": "stat100_wk11mon.html#reminders",
    "href": "stat100_wk11mon.html#reminders",
    "title": "Stat 100",
    "section": "Reminders:",
    "text": "Reminders:\n\n\n🎉 We are now accepting Course Assistant/Teaching Fellow applications for Stat 100 for next semester. To apply, fill out this application by Nov 15th.\n\nAbout 10-12 hours of work per week.\n\nPrimary responsibilities: Attend weekly team meetings, lead a discussion section, hold office hours, grade assessments.\n\nYou are all invited to the Info Session on Data Science Internships today at 4pm in SC 316!"
  },
  {
    "objectID": "stat100_wk10wed.html#announcements",
    "href": "stat100_wk10wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\n🎉 We are now accepting Course Assistant/Teaching Fellow applications for Stat 100 for next semester. To apply, fill out this application by Nov 15th.\nNo wrap-up session on Friday due to the university holiday.\n\nYou are all invited to the Info Session on Data Science Internships: Mon at 4pm in SC 316!\n\nGoals for Today\n\n\n\nCoding goals (Stat 100 & beyond)\nAdvice on the next stats/coding class\n\n\n\nDecisions in a hypothesis test\n\nTypes of errors\n\nThe power of a hypothesis test"
  },
  {
    "objectID": "stat100_wk10wed.html#that-next-stats-class",
    "href": "stat100_wk10wed.html#that-next-stats-class",
    "title": "Stat 100",
    "section": "That Next Stats Class",
    "text": "That Next Stats Class\n\nBut first… Common Question: How should I describe my post-Stat 100 coding abilities?\nPotential Answer: You have learned how to write code to analyze data. This includes visualization (ggplot2), data wrangling (dplyr), data importation (readr), modeling, inference (infer) and communication (with Quarto).\nFollow-up Question: So what coding is there left to learn?\nAnswer: Learning how to program. This includes topics such as control flow, iteration, creating functions, and vectorization."
  },
  {
    "objectID": "stat100_wk10wed.html#that-next-coding-class",
    "href": "stat100_wk10wed.html#that-next-coding-class",
    "title": "Stat 100",
    "section": "That Next Coding Class",
    "text": "That Next Coding Class\n\n\nStat 108: Introduction to Statistical Computing with R\nCompSci 32: Computational Thinking and Problem Solving\nCompSci 50: Introduction to Computer Science\nAP 10: Computing with Python for Scientists and Engineers"
  },
  {
    "objectID": "stat100_wk10wed.html#that-next-modeling-course",
    "href": "stat100_wk10wed.html#that-next-modeling-course",
    "title": "Stat 100",
    "section": "That Next Modeling Course",
    "text": "That Next Modeling Course\n\n\nStat 109A: Data Science I & Stat 109B: Data Science II\nStat 139: Linear Models\nMany of the upper-level stats courses are modeling courses (but they do have pre-reqs)."
  },
  {
    "objectID": "stat100_wk10wed.html#that-next-theorymethods-course",
    "href": "stat100_wk10wed.html#that-next-theorymethods-course",
    "title": "Stat 100",
    "section": "That Next Theory/Methods Course",
    "text": "That Next Theory/Methods Course\n\n\nStat 110: Introduction to Probability\nStat 111: Introduction to Statistical Inference"
  },
  {
    "objectID": "stat100_wk10wed.html#that-next-visualization-course",
    "href": "stat100_wk10wed.html#that-next-visualization-course",
    "title": "Stat 100",
    "section": "That Next Visualization Course",
    "text": "That Next Visualization Course\n\n\nStat 108: Introduction to Statistical Computing with R\nCompSci 171: Visualization\nStat 106: Data Science for Sports Analytics\n\nNot on the books yet but should be coming next academic year."
  },
  {
    "objectID": "stat100_wk10wed.html#penguins-example",
    "href": "stat100_wk10wed.html#penguins-example",
    "title": "Stat 100",
    "section": "Penguins Example",
    "text": "Penguins Example\nLet’s return to the penguins data and ask if flipper length varies, on average, by the sex of the penguin.\nResearch Question: Does flipper length differ by sex?\nResponse Variable:\n\nExplanatory Variable:\n\nStatistical Hypotheses:"
  },
  {
    "objectID": "stat100_wk10wed.html#exploratory-data-analysis",
    "href": "stat100_wk10wed.html#exploratory-data-analysis",
    "title": "Stat 100",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\n\nlibrary(infer)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\npenguins %&gt;%\n  drop_na(sex) %&gt;%\nggplot(mapping = aes(x = sex,\n                     y = flipper_length_mm)) +\n  geom_boxplot()"
  },
  {
    "objectID": "stat100_wk10wed.html#two-sided-hypothesis-test",
    "href": "stat100_wk10wed.html#two-sided-hypothesis-test",
    "title": "Stat 100",
    "section": "Two-Sided Hypothesis Test",
    "text": "Two-Sided Hypothesis Test\n\n\n# Compute observed test statistic\ntest_stat &lt;- penguins %&gt;%\n  drop_na(sex) %&gt;%\n  specify(flipper_length_mm ~ sex) %&gt;%\n  calculate(stat =\"diff in means\",\n            order = c(\"female\", \"male\"))\ntest_stat\n\n\nResponse: flipper_length_mm (numeric)\nExplanatory: sex (factor)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1 -7.14\n\n\n\n\n# Generate null distribution \nnull_dist &lt;- penguins %&gt;%\n  drop_na(sex) %&gt;%\n  specify(flipper_length_mm ~ sex) %&gt;%\n  hypothesize(null = \"independence\") %&gt;%\n  generate(reps = 1000, type = \"permute\") %&gt;%\n  calculate(stat =\"diff in means\",\n            order = c(\"female\", \"male\"))"
  },
  {
    "objectID": "stat100_wk10wed.html#two-sided-hypothesis-test-1",
    "href": "stat100_wk10wed.html#two-sided-hypothesis-test-1",
    "title": "Stat 100",
    "section": "Two-Sided Hypothesis Test",
    "text": "Two-Sided Hypothesis Test\n\n\n# Graph null distribution with test statistic\nvisualize(null_dist) +\n  geom_vline(xintercept = test_stat$stat,\n             color = \"deeppink\", size = 2) +\n  geom_vline(xintercept = abs(test_stat$stat),\n             color = \"deeppink\", size = 2)"
  },
  {
    "objectID": "stat100_wk10wed.html#two-sided-hypothesis-test-2",
    "href": "stat100_wk10wed.html#two-sided-hypothesis-test-2",
    "title": "Stat 100",
    "section": "Two-Sided Hypothesis Test",
    "text": "Two-Sided Hypothesis Test\n\n\n# Compute p-value\np_value &lt;- null_dist %&gt;%\n  get_p_value(obs_stat = test_stat,\n              direction = \"two_sided\")\np_value\n\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0\n\n\n\nInterpretation of \\(p\\)-value: If the mean flipper length does not differ by sex in the population, the probability of observing a difference in the sample means of at least 7.142316 mm (in magnitude) is equal to 0.\nConclusion: These data represent evidence that flipper length does vary by sex."
  },
  {
    "objectID": "stat100_wk10wed.html#thoughts-on-power",
    "href": "stat100_wk10wed.html#thoughts-on-power",
    "title": "Stat 100",
    "section": "Thoughts on Power",
    "text": "Thoughts on Power\n\nWhat aspects of the test did the player actually have control over?\nWhy is it easier to set \\(\\alpha\\) than to set \\(\\beta\\) or power?\nConsidering power before collecting data is very important!\nThe danger of under-powered studies\n\nEX: Turning right at a red light"
  },
  {
    "objectID": "stat100_wk10wed.html#reminders",
    "href": "stat100_wk10wed.html#reminders",
    "title": "Stat 100",
    "section": "Reminders:",
    "text": "Reminders:\n\n\n🎉 We are now accepting Course Assistant/Teaching Fellow applications for Stat 100 for next semester. To apply, fill out this application by Nov 15th.\n\nAbout 10-12 hours of work per week.\n\nPrimary responsibilities: Attend weekly team meetings, lead a discussion section, hold office hours, grade assessments."
  },
  {
    "objectID": "stat100_wk05wed.html#announcements",
    "href": "stat100_wk05wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nNo lecture on Monday – University Holiday.\nSome Monday Office Hours will also be cancelled. Make sure to check the office hours schedule.\nDiscuss upcoming exam:\n\nMidterm next week\n\nIn-class: Wed, Oct 11th 10:30 - 11:45am\nOral: Wed afternoon - Fri, Oct 13th\nNo sections during midterm exam week!\n\n\n\nGoals for Today\n\n\n\nIntroduce statistical modeling\nSimple linear regression model\n\n\n\nMeasuring correlation"
  },
  {
    "objectID": "stat100_wk05wed.html#thoughts-on-data-collection-goals",
    "href": "stat100_wk05wed.html#thoughts-on-data-collection-goals",
    "title": "Stat 100",
    "section": "Thoughts on Data Collection Goals",
    "text": "Thoughts on Data Collection Goals\n\nRandom assignment allows you to explore causal relationships between your explanatory variables and the predictor variables because the randomization makes the explanatory groups roughly similar.\nHow do we draw causal conclusions from studies without random assignment?\n\nWith extreme care! Try to control for all possible confounding variables.\nDiscuss the associations/correlations you found. Use domain knowledge to address potentially causal links.\nTake more stats to learn more about causal inference.\n\nBut also consider the goals of your analysis. Often the research question isn’t causal.\n\n\nBottom Line: We often have to use imperfect data to make decisions."
  },
  {
    "objectID": "stat100_wk05wed.html#conclusions-conclusions",
    "href": "stat100_wk05wed.html#conclusions-conclusions",
    "title": "Stat 100",
    "section": "Conclusions, Conclusions",
    "text": "Conclusions, Conclusions"
  },
  {
    "objectID": "stat100_wk05wed.html#recap",
    "href": "stat100_wk05wed.html#recap",
    "title": "Stat 100",
    "section": "Recap",
    "text": "Recap"
  },
  {
    "objectID": "stat100_wk05wed.html#form-of-the-model",
    "href": "stat100_wk05wed.html#form-of-the-model",
    "title": "Stat 100",
    "section": "Form of the Model",
    "text": "Form of the Model\n\n\\[\ny = f(x) + \\epsilon\n\\]\n\nGoal:\n\nDetermine a reasonable form for \\(f()\\). (Ex: Line, curve, …)\nEstimate \\(f()\\) with \\(\\hat{f}()\\) using the data.\nGenerate predicted values: \\(\\hat y = \\hat{f}(x)\\)."
  },
  {
    "objectID": "stat100_wk05wed.html#sample-correlation-coefficient",
    "href": "stat100_wk05wed.html#sample-correlation-coefficient",
    "title": "Stat 100",
    "section": "(Sample) Correlation Coefficient",
    "text": "(Sample) Correlation Coefficient\n\nMeasures the strength and direction of linear relationship between two quantitative variables\nSymbol: \\(r\\)\nAlways between -1 and 1\nSign indicates the direction of the relationship\nMagnitude indicates the strength of the linear relationship\n\n\n\ncandy %&gt;%\n  summarize(cor = cor(pricepercent, winpercent))\n\n# A tibble: 1 × 1\n    cor\n  &lt;dbl&gt;\n1 0.345"
  },
  {
    "objectID": "stat100_wk05wed.html#new-example",
    "href": "stat100_wk05wed.html#new-example",
    "title": "Stat 100",
    "section": "New Example",
    "text": "New Example\n\n\n\n# Correlation coefficients\ndat2 %&gt;%\n  group_by(dataset) %&gt;%\n  summarize(cor = cor(x, y))\n\n# A tibble: 12 × 2\n   dataset        cor\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 away       -0.0641\n 2 bullseye   -0.0686\n 3 circle     -0.0683\n 4 dino       -0.0645\n 5 dots       -0.0603\n 6 h_lines    -0.0617\n 7 high_lines -0.0685\n 8 slant_down -0.0690\n 9 star       -0.0630\n10 v_lines    -0.0694\n11 wide_lines -0.0666\n12 x_shape    -0.0656\n\n\n\n\nConclude that \\(x\\) and \\(y\\) have the same relationship across these different datasets because the correlation is the same?"
  },
  {
    "objectID": "stat100_wk05wed.html#reminders",
    "href": "stat100_wk05wed.html#reminders",
    "title": "Stat 100",
    "section": "Reminders",
    "text": "Reminders\n\nNo lecture on Monday – University Holiday.\nSome Monday Office Hours will also be cancelled. Make sure to check the office hours schedule.\nMidterm next week\n\nIn-class: Wed, Oct 11th 10:30 - 11:45am\nOral: Wed afternoon - Fri, Oct 13th\n\nNo sections during midterm exam week!"
  },
  {
    "objectID": "stat100_wk09wed.html#announcements",
    "href": "stat100_wk09wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nDon’t forget that the midterm exam rewrites are due on Thursday at 5pm on Gradescope.\n\nMake sure to use the Quarto doc in the Midterm Exam (Rewrites) project on Posit Cloud.\n\n🎉 We are now accepting Course Assistant/Teaching Fellow applications for Stat 100 for next semester. To apply, fill out this application by Nov 15th.\n\nAbout 10-12 hours of work per week.\n\nPrimary responsibilities: Attend weekly team meetings, lead a discussion section, hold office hours, grade assessments.\n\n\nGoals for Today\n\n\n\nConfidence interval interpretations\nSet-up the structure of hypothesis testing\n\n\n\nDetermine if Harvard students have ESP!"
  },
  {
    "objectID": "stat100_wk09wed.html#interpreting-confidence-intervals",
    "href": "stat100_wk09wed.html#interpreting-confidence-intervals",
    "title": "Stat 100",
    "section": "Interpreting Confidence Intervals",
    "text": "Interpreting Confidence Intervals\nExample: Estimating average household income before taxes in the US\n\n\nSE Method Formula:\n\\[\n\\mbox{statistic} \\pm{\\mbox{ME}}\n\\]\n\n\n# A tibble: 1 × 3\n     ME  lower  upper\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 1937. 60543. 64417.\n\n\n\n“The margin of [sampling] error can be described as the ‘penalty’ in precision for not talking to everyone in a given population. It describes the range that an answer likely falls between if the survey had reached everyone in a population, instead of just a sample of that population.” – Courtney Kennedy, Director of Survey Research at Pew Research Center\nCI = interval of plausible values for the parameter\n\n\nSafe interpretation: I am P% confident that {insert what the parameter represents in context} is between {insert lower bound} and {insert upper bound}."
  },
  {
    "objectID": "stat100_wk09wed.html#caution-confidence-intervals-in-the-wild",
    "href": "stat100_wk09wed.html#caution-confidence-intervals-in-the-wild",
    "title": "Stat 100",
    "section": "Caution: Confidence intervals in the wild",
    "text": "Caution: Confidence intervals in the wild\nStatement in an article for The BMJ (British Medical Journal):"
  },
  {
    "objectID": "stat100_wk09wed.html#statistical-inference",
    "href": "stat100_wk09wed.html#statistical-inference",
    "title": "Stat 100",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\n\n\n\n\n\n\n\n\n\n\n\nGoal: Draw conclusions about the population based on a sample.\nMain Flavors:\n\nEstimating numerical quantities.\nTesting conjectures."
  },
  {
    "objectID": "stat100_wk09wed.html#example-does-extrasensory-perception-esp-exist",
    "href": "stat100_wk09wed.html#example-does-extrasensory-perception-esp-exist",
    "title": "Stat 100",
    "section": "Example: Does Extrasensory Perception (ESP) exist?",
    "text": "Example: Does Extrasensory Perception (ESP) exist?\n\n\n\n\n\n\n\nDaryl Bem and Ben Honorton\n\n\n\n\n\nBem and Honorton conducted extrasensory perception studies:\n\n\nA “sender” randomly chooses an object out of 4 possible objects and sends that information to a “receiver”.\nThe “receiver” is then given a set of 4 possible objects and they must decide which one most resembles the object sent to them.\n\n\nOut of 329 trials, the “receivers” correctly identified the object 106 times."
  },
  {
    "objectID": "stat100_wk09wed.html#esp-example",
    "href": "stat100_wk09wed.html#esp-example",
    "title": "Stat 100",
    "section": "ESP Example",
    "text": "ESP Example\nLet’s consider the following questions:\n\n\nIf ESP does not exist and the “receivers” are guessing, how often would we expect them to be correct?\nFor each sample (set of 329 trials), do we expect the proportion of correct guesses to be equal? Why or why not?\nIs it possible to randomly guess correctly 106 out of 329 times (i.e., 32% of the time)?\nHow unusual is it to guess correctly 106 out of 329 times if ESP doesn’t exist?\n\n\n\nTo help us answer d., we need a sampling distribution for the sample proportion where we assume the “receivers” were purely guessing!"
  },
  {
    "objectID": "stat100_wk09wed.html#sampling-distribution-of-a-statistic",
    "href": "stat100_wk09wed.html#sampling-distribution-of-a-statistic",
    "title": "Stat 100",
    "section": "Sampling Distribution of a Statistic",
    "text": "Sampling Distribution of a Statistic\n\n\nSteps for (Approximate) Distribution:\n\n\nDecide on a sample size, \\(n\\).\nRandomly select a sample of size \\(n\\) from the population.\nCompute the sample statistic.\nPut the sample back in.\nRepeat Steps (2) - (4) many (1000+) times."
  },
  {
    "objectID": "stat100_wk09wed.html#sampling-distribution-of-a-statistic-1",
    "href": "stat100_wk09wed.html#sampling-distribution-of-a-statistic-1",
    "title": "Stat 100",
    "section": "Sampling Distribution of a Statistic",
    "text": "Sampling Distribution of a Statistic\n\n\nSteps for (Approximate) Distribution:\n\n\nDecide on a sample size, \\(n\\).\nRandomly select a sample of size \\(n\\) from the population.\nCompute the sample statistic.\nPut the sample back in.\nRepeat Steps (2) - (4) many (1000+) times."
  },
  {
    "objectID": "stat100_wk09wed.html#sampling-distribution-under-no-esp",
    "href": "stat100_wk09wed.html#sampling-distribution-under-no-esp",
    "title": "Stat 100",
    "section": "Sampling Distribution Under No ESP",
    "text": "Sampling Distribution Under No ESP\nSteps for (Approximate) Distribution:\n\n\nDecide on a sample size, \\(n\\).\nRandomly select a sample of size \\(n\\) from the population.\n\n\n\nlibrary(mosaic)\nrflip(n = 329, prob = 0.25)\n\n\nFlipping 329 coins [ Prob(Heads) = 0.25 ] ...\n\nT T T T T H H T T H H T T H T T T H H T H T H H H T T T T T T T H T T H\nT T T T H T T T T T T H T H H H T T T T T H T T T H T H T H H T H T H T\nT T T H H H T T T T H T T T H T T T T H T H T T T T T T T H H T T T H T\nT T T H T T T H T H T T T H T H T T H H T T T T H T T T T T H T T T H T\nT T H T T H T T T T T T T H T T T T H T T H T T T H H H H T H T T T T T\nT T T H T T T H H T T T T T H H T T T T T T H T T T H T T T T T H T T H\nH H T T T T T T H T T T T T T H T T H T T T H T T T T T T T H T T T T T\nH T H H T T T T T T T T T T T T H T T H T T T H T T T H H T H T T T T H\nH H T T T T T T T H T T H H T T H T T T H T T T T H H T T T T T H H T T\nT T T T T\n\nNumber of Heads: 92 [Proportion Heads: 0.279635258358663]"
  },
  {
    "objectID": "stat100_wk09wed.html#sampling-distribution-under-no-esp-1",
    "href": "stat100_wk09wed.html#sampling-distribution-under-no-esp-1",
    "title": "Stat 100",
    "section": "Sampling Distribution Under No ESP",
    "text": "Sampling Distribution Under No ESP\n\n\nCompute the sample statistic.\n\n\n\nrflip(n = 329, prob = 0.25, summarize = TRUE)\n\n    n heads tails prob\n1 329    76   253 0.25\n\n\n\n\n\nPut the sample back in.\nRepeat Steps (2) - (4) many (1000+) times.\n\n\n\nguess_sampling_dist &lt;- do(1000)*rflip(n = 329, prob = 0.25)\nguess_sampling_dist\n\n       n heads tails      prop\n1    329    79   250 0.2401216\n2    329    87   242 0.2644377\n3    329    76   253 0.2310030\n4    329    94   235 0.2857143\n5    329    72   257 0.2188450\n6    329    86   243 0.2613982\n7    329    90   239 0.2735562\n8    329    78   251 0.2370821\n9    329    80   249 0.2431611\n10   329    87   242 0.2644377\n11   329    92   237 0.2796353\n12   329    88   241 0.2674772\n13   329    78   251 0.2370821\n14   329    72   257 0.2188450\n15   329    73   256 0.2218845\n16   329    87   242 0.2644377\n17   329    78   251 0.2370821\n18   329    80   249 0.2431611\n19   329    84   245 0.2553191\n20   329    75   254 0.2279635\n21   329    90   239 0.2735562\n22   329    73   256 0.2218845\n23   329    84   245 0.2553191\n24   329    86   243 0.2613982\n25   329    83   246 0.2522796\n26   329    75   254 0.2279635\n27   329    81   248 0.2462006\n28   329    78   251 0.2370821\n29   329   101   228 0.3069909\n30   329    85   244 0.2583587\n31   329    79   250 0.2401216\n32   329    77   252 0.2340426\n33   329    87   242 0.2644377\n34   329    86   243 0.2613982\n35   329    75   254 0.2279635\n36   329    81   248 0.2462006\n37   329    79   250 0.2401216\n38   329    90   239 0.2735562\n39   329    74   255 0.2249240\n40   329    81   248 0.2462006\n41   329   100   229 0.3039514\n42   329    70   259 0.2127660\n43   329    83   246 0.2522796\n44   329    87   242 0.2644377\n45   329    71   258 0.2158055\n46   329    84   245 0.2553191\n47   329    71   258 0.2158055\n48   329    90   239 0.2735562\n49   329    82   247 0.2492401\n50   329    83   246 0.2522796\n51   329    87   242 0.2644377\n52   329    85   244 0.2583587\n53   329    82   247 0.2492401\n54   329    76   253 0.2310030\n55   329    87   242 0.2644377\n56   329    72   257 0.2188450\n57   329    84   245 0.2553191\n58   329    81   248 0.2462006\n59   329    89   240 0.2705167\n60   329    87   242 0.2644377\n61   329    93   236 0.2826748\n62   329    82   247 0.2492401\n63   329    64   265 0.1945289\n64   329    83   246 0.2522796\n65   329    75   254 0.2279635\n66   329    68   261 0.2066869\n67   329    74   255 0.2249240\n68   329    78   251 0.2370821\n69   329    90   239 0.2735562\n70   329    84   245 0.2553191\n71   329    84   245 0.2553191\n72   329    84   245 0.2553191\n73   329    84   245 0.2553191\n74   329    70   259 0.2127660\n75   329    85   244 0.2583587\n76   329    82   247 0.2492401\n77   329    93   236 0.2826748\n78   329    67   262 0.2036474\n79   329    75   254 0.2279635\n80   329    80   249 0.2431611\n81   329   100   229 0.3039514\n82   329    85   244 0.2583587\n83   329    91   238 0.2765957\n84   329    98   231 0.2978723\n85   329    89   240 0.2705167\n86   329    65   264 0.1975684\n87   329    81   248 0.2462006\n88   329   105   224 0.3191489\n89   329    84   245 0.2553191\n90   329    59   270 0.1793313\n91   329    94   235 0.2857143\n92   329    93   236 0.2826748\n93   329    78   251 0.2370821\n94   329    82   247 0.2492401\n95   329    88   241 0.2674772\n96   329    86   243 0.2613982\n97   329    80   249 0.2431611\n98   329    93   236 0.2826748\n99   329    75   254 0.2279635\n100  329    95   234 0.2887538\n101  329    76   253 0.2310030\n102  329    69   260 0.2097264\n103  329    74   255 0.2249240\n104  329    80   249 0.2431611\n105  329    88   241 0.2674772\n106  329    98   231 0.2978723\n107  329    87   242 0.2644377\n108  329    80   249 0.2431611\n109  329    93   236 0.2826748\n110  329    83   246 0.2522796\n111  329    90   239 0.2735562\n112  329    82   247 0.2492401\n113  329    83   246 0.2522796\n114  329    79   250 0.2401216\n115  329    77   252 0.2340426\n116  329    96   233 0.2917933\n117  329    75   254 0.2279635\n118  329    90   239 0.2735562\n119  329    77   252 0.2340426\n120  329    89   240 0.2705167\n121  329    76   253 0.2310030\n122  329    87   242 0.2644377\n123  329    73   256 0.2218845\n124  329    77   252 0.2340426\n125  329    84   245 0.2553191\n126  329    76   253 0.2310030\n127  329    84   245 0.2553191\n128  329    83   246 0.2522796\n129  329    84   245 0.2553191\n130  329    90   239 0.2735562\n131  329    82   247 0.2492401\n132  329    76   253 0.2310030\n133  329    79   250 0.2401216\n134  329    98   231 0.2978723\n135  329    75   254 0.2279635\n136  329    79   250 0.2401216\n137  329    82   247 0.2492401\n138  329    90   239 0.2735562\n139  329    85   244 0.2583587\n140  329    89   240 0.2705167\n141  329    75   254 0.2279635\n142  329    90   239 0.2735562\n143  329    72   257 0.2188450\n144  329    77   252 0.2340426\n145  329    83   246 0.2522796\n146  329    77   252 0.2340426\n147  329    91   238 0.2765957\n148  329    89   240 0.2705167\n149  329    72   257 0.2188450\n150  329    70   259 0.2127660\n151  329    82   247 0.2492401\n152  329    79   250 0.2401216\n153  329    94   235 0.2857143\n154  329    83   246 0.2522796\n155  329    85   244 0.2583587\n156  329    79   250 0.2401216\n157  329    88   241 0.2674772\n158  329    89   240 0.2705167\n159  329    83   246 0.2522796\n160  329    91   238 0.2765957\n161  329    90   239 0.2735562\n162  329    75   254 0.2279635\n163  329    99   230 0.3009119\n164  329    66   263 0.2006079\n165  329    80   249 0.2431611\n166  329    83   246 0.2522796\n167  329    93   236 0.2826748\n168  329    84   245 0.2553191\n169  329    75   254 0.2279635\n170  329    82   247 0.2492401\n171  329    79   250 0.2401216\n172  329    73   256 0.2218845\n173  329    75   254 0.2279635\n174  329    80   249 0.2431611\n175  329    74   255 0.2249240\n176  329    96   233 0.2917933\n177  329    76   253 0.2310030\n178  329   113   216 0.3434650\n179  329    96   233 0.2917933\n180  329    81   248 0.2462006\n181  329    88   241 0.2674772\n182  329    74   255 0.2249240\n183  329    73   256 0.2218845\n184  329    75   254 0.2279635\n185  329    85   244 0.2583587\n186  329    91   238 0.2765957\n187  329    85   244 0.2583587\n188  329   100   229 0.3039514\n189  329    79   250 0.2401216\n190  329    73   256 0.2218845\n191  329    79   250 0.2401216\n192  329    86   243 0.2613982\n193  329    86   243 0.2613982\n194  329    83   246 0.2522796\n195  329    90   239 0.2735562\n196  329    79   250 0.2401216\n197  329    96   233 0.2917933\n198  329    85   244 0.2583587\n199  329    84   245 0.2553191\n200  329    93   236 0.2826748\n201  329    78   251 0.2370821\n202  329    91   238 0.2765957\n203  329    87   242 0.2644377\n204  329    71   258 0.2158055\n205  329    79   250 0.2401216\n206  329    77   252 0.2340426\n207  329    79   250 0.2401216\n208  329    97   232 0.2948328\n209  329    85   244 0.2583587\n210  329    74   255 0.2249240\n211  329    83   246 0.2522796\n212  329    79   250 0.2401216\n213  329    86   243 0.2613982\n214  329    87   242 0.2644377\n215  329    77   252 0.2340426\n216  329    72   257 0.2188450\n217  329    85   244 0.2583587\n218  329    61   268 0.1854103\n219  329    81   248 0.2462006\n220  329    96   233 0.2917933\n221  329    74   255 0.2249240\n222  329    77   252 0.2340426\n223  329    84   245 0.2553191\n224  329    87   242 0.2644377\n225  329    88   241 0.2674772\n226  329    87   242 0.2644377\n227  329    90   239 0.2735562\n228  329    79   250 0.2401216\n229  329    87   242 0.2644377\n230  329    77   252 0.2340426\n231  329    67   262 0.2036474\n232  329    65   264 0.1975684\n233  329    83   246 0.2522796\n234  329    85   244 0.2583587\n235  329    68   261 0.2066869\n236  329    84   245 0.2553191\n237  329    77   252 0.2340426\n238  329    71   258 0.2158055\n239  329    71   258 0.2158055\n240  329    92   237 0.2796353\n241  329    79   250 0.2401216\n242  329    78   251 0.2370821\n243  329    67   262 0.2036474\n244  329    97   232 0.2948328\n245  329    80   249 0.2431611\n246  329    96   233 0.2917933\n247  329    79   250 0.2401216\n248  329    89   240 0.2705167\n249  329    84   245 0.2553191\n250  329    84   245 0.2553191\n251  329    84   245 0.2553191\n252  329    75   254 0.2279635\n253  329    74   255 0.2249240\n254  329    86   243 0.2613982\n255  329    74   255 0.2249240\n256  329    84   245 0.2553191\n257  329    74   255 0.2249240\n258  329    94   235 0.2857143\n259  329    84   245 0.2553191\n260  329    81   248 0.2462006\n261  329    80   249 0.2431611\n262  329    81   248 0.2462006\n263  329    77   252 0.2340426\n264  329    77   252 0.2340426\n265  329    95   234 0.2887538\n266  329    80   249 0.2431611\n267  329    77   252 0.2340426\n268  329    77   252 0.2340426\n269  329    84   245 0.2553191\n270  329    80   249 0.2431611\n271  329    83   246 0.2522796\n272  329    91   238 0.2765957\n273  329    80   249 0.2431611\n274  329    87   242 0.2644377\n275  329    87   242 0.2644377\n276  329    78   251 0.2370821\n277  329    75   254 0.2279635\n278  329    87   242 0.2644377\n279  329    88   241 0.2674772\n280  329    79   250 0.2401216\n281  329    94   235 0.2857143\n282  329    73   256 0.2218845\n283  329    92   237 0.2796353\n284  329    85   244 0.2583587\n285  329    80   249 0.2431611\n286  329    76   253 0.2310030\n287  329    79   250 0.2401216\n288  329    80   249 0.2431611\n289  329    77   252 0.2340426\n290  329    77   252 0.2340426\n291  329    90   239 0.2735562\n292  329    74   255 0.2249240\n293  329    83   246 0.2522796\n294  329    98   231 0.2978723\n295  329    83   246 0.2522796\n296  329    93   236 0.2826748\n297  329    79   250 0.2401216\n298  329    69   260 0.2097264\n299  329    96   233 0.2917933\n300  329    80   249 0.2431611\n301  329    76   253 0.2310030\n302  329    93   236 0.2826748\n303  329    75   254 0.2279635\n304  329    68   261 0.2066869\n305  329    75   254 0.2279635\n306  329    75   254 0.2279635\n307  329    84   245 0.2553191\n308  329    64   265 0.1945289\n309  329    76   253 0.2310030\n310  329    87   242 0.2644377\n311  329    93   236 0.2826748\n312  329    91   238 0.2765957\n313  329    79   250 0.2401216\n314  329    86   243 0.2613982\n315  329    90   239 0.2735562\n316  329   102   227 0.3100304\n317  329    89   240 0.2705167\n318  329    85   244 0.2583587\n319  329    92   237 0.2796353\n320  329    89   240 0.2705167\n321  329    80   249 0.2431611\n322  329    80   249 0.2431611\n323  329    83   246 0.2522796\n324  329    85   244 0.2583587\n325  329    85   244 0.2583587\n326  329    86   243 0.2613982\n327  329    80   249 0.2431611\n328  329    93   236 0.2826748\n329  329    73   256 0.2218845\n330  329    81   248 0.2462006\n331  329    76   253 0.2310030\n332  329    93   236 0.2826748\n333  329    74   255 0.2249240\n334  329    93   236 0.2826748\n335  329    79   250 0.2401216\n336  329    81   248 0.2462006\n337  329    81   248 0.2462006\n338  329   102   227 0.3100304\n339  329    80   249 0.2431611\n340  329    82   247 0.2492401\n341  329    74   255 0.2249240\n342  329    79   250 0.2401216\n343  329    91   238 0.2765957\n344  329    63   266 0.1914894\n345  329    84   245 0.2553191\n346  329    85   244 0.2583587\n347  329    90   239 0.2735562\n348  329    77   252 0.2340426\n349  329    65   264 0.1975684\n350  329    76   253 0.2310030\n351  329    89   240 0.2705167\n352  329    88   241 0.2674772\n353  329    87   242 0.2644377\n354  329    84   245 0.2553191\n355  329    64   265 0.1945289\n356  329    73   256 0.2218845\n357  329    82   247 0.2492401\n358  329    84   245 0.2553191\n359  329    92   237 0.2796353\n360  329    75   254 0.2279635\n361  329    76   253 0.2310030\n362  329    85   244 0.2583587\n363  329    73   256 0.2218845\n364  329    89   240 0.2705167\n365  329    82   247 0.2492401\n366  329    75   254 0.2279635\n367  329    93   236 0.2826748\n368  329   108   221 0.3282675\n369  329    81   248 0.2462006\n370  329    70   259 0.2127660\n371  329    85   244 0.2583587\n372  329    79   250 0.2401216\n373  329    89   240 0.2705167\n374  329    78   251 0.2370821\n375  329    85   244 0.2583587\n376  329    81   248 0.2462006\n377  329    92   237 0.2796353\n378  329    85   244 0.2583587\n379  329    83   246 0.2522796\n380  329    70   259 0.2127660\n381  329    90   239 0.2735562\n382  329    84   245 0.2553191\n383  329    80   249 0.2431611\n384  329    95   234 0.2887538\n385  329    73   256 0.2218845\n386  329    75   254 0.2279635\n387  329    84   245 0.2553191\n388  329    72   257 0.2188450\n389  329    76   253 0.2310030\n390  329    88   241 0.2674772\n391  329    81   248 0.2462006\n392  329    92   237 0.2796353\n393  329    64   265 0.1945289\n394  329    89   240 0.2705167\n395  329    85   244 0.2583587\n396  329    78   251 0.2370821\n397  329    80   249 0.2431611\n398  329    85   244 0.2583587\n399  329    75   254 0.2279635\n400  329    79   250 0.2401216\n401  329    86   243 0.2613982\n402  329    63   266 0.1914894\n403  329    82   247 0.2492401\n404  329    90   239 0.2735562\n405  329    86   243 0.2613982\n406  329    69   260 0.2097264\n407  329    70   259 0.2127660\n408  329    70   259 0.2127660\n409  329    70   259 0.2127660\n410  329    80   249 0.2431611\n411  329    81   248 0.2462006\n412  329    83   246 0.2522796\n413  329   105   224 0.3191489\n414  329    92   237 0.2796353\n415  329    84   245 0.2553191\n416  329    75   254 0.2279635\n417  329    75   254 0.2279635\n418  329    85   244 0.2583587\n419  329    81   248 0.2462006\n420  329    76   253 0.2310030\n421  329    92   237 0.2796353\n422  329    85   244 0.2583587\n423  329    81   248 0.2462006\n424  329    69   260 0.2097264\n425  329   101   228 0.3069909\n426  329    96   233 0.2917933\n427  329    59   270 0.1793313\n428  329    73   256 0.2218845\n429  329    65   264 0.1975684\n430  329    78   251 0.2370821\n431  329    86   243 0.2613982\n432  329    84   245 0.2553191\n433  329    79   250 0.2401216\n434  329    87   242 0.2644377\n435  329    71   258 0.2158055\n436  329    92   237 0.2796353\n437  329    99   230 0.3009119\n438  329    64   265 0.1945289\n439  329    86   243 0.2613982\n440  329    89   240 0.2705167\n441  329    83   246 0.2522796\n442  329    78   251 0.2370821\n443  329    73   256 0.2218845\n444  329    81   248 0.2462006\n445  329    95   234 0.2887538\n446  329    81   248 0.2462006\n447  329    83   246 0.2522796\n448  329    69   260 0.2097264\n449  329    78   251 0.2370821\n450  329    78   251 0.2370821\n451  329    89   240 0.2705167\n452  329    78   251 0.2370821\n453  329    72   257 0.2188450\n454  329    88   241 0.2674772\n455  329    84   245 0.2553191\n456  329    80   249 0.2431611\n457  329    90   239 0.2735562\n458  329    86   243 0.2613982\n459  329    74   255 0.2249240\n460  329    80   249 0.2431611\n461  329    77   252 0.2340426\n462  329    89   240 0.2705167\n463  329    80   249 0.2431611\n464  329    75   254 0.2279635\n465  329    94   235 0.2857143\n466  329    83   246 0.2522796\n467  329    93   236 0.2826748\n468  329    93   236 0.2826748\n469  329    91   238 0.2765957\n470  329    72   257 0.2188450\n471  329    87   242 0.2644377\n472  329    75   254 0.2279635\n473  329    91   238 0.2765957\n474  329    87   242 0.2644377\n475  329    82   247 0.2492401\n476  329    67   262 0.2036474\n477  329    70   259 0.2127660\n478  329    78   251 0.2370821\n479  329   106   223 0.3221884\n480  329    85   244 0.2583587\n481  329    73   256 0.2218845\n482  329    72   257 0.2188450\n483  329    88   241 0.2674772\n484  329    87   242 0.2644377\n485  329    86   243 0.2613982\n486  329    74   255 0.2249240\n487  329    96   233 0.2917933\n488  329    87   242 0.2644377\n489  329    71   258 0.2158055\n490  329    66   263 0.2006079\n491  329    78   251 0.2370821\n492  329    75   254 0.2279635\n493  329    87   242 0.2644377\n494  329    94   235 0.2857143\n495  329    68   261 0.2066869\n496  329    78   251 0.2370821\n497  329    99   230 0.3009119\n498  329    82   247 0.2492401\n499  329    86   243 0.2613982\n500  329    77   252 0.2340426\n501  329    74   255 0.2249240\n502  329    79   250 0.2401216\n503  329    81   248 0.2462006\n504  329    76   253 0.2310030\n505  329    86   243 0.2613982\n506  329    80   249 0.2431611\n507  329    83   246 0.2522796\n508  329    80   249 0.2431611\n509  329    73   256 0.2218845\n510  329    89   240 0.2705167\n511  329    78   251 0.2370821\n512  329    81   248 0.2462006\n513  329    77   252 0.2340426\n514  329    77   252 0.2340426\n515  329    90   239 0.2735562\n516  329    80   249 0.2431611\n517  329    90   239 0.2735562\n518  329    78   251 0.2370821\n519  329    78   251 0.2370821\n520  329    78   251 0.2370821\n521  329    85   244 0.2583587\n522  329    89   240 0.2705167\n523  329    88   241 0.2674772\n524  329    89   240 0.2705167\n525  329    86   243 0.2613982\n526  329    91   238 0.2765957\n527  329    84   245 0.2553191\n528  329    81   248 0.2462006\n529  329    93   236 0.2826748\n530  329    85   244 0.2583587\n531  329    80   249 0.2431611\n532  329    83   246 0.2522796\n533  329    79   250 0.2401216\n534  329    72   257 0.2188450\n535  329    88   241 0.2674772\n536  329    79   250 0.2401216\n537  329    79   250 0.2401216\n538  329    95   234 0.2887538\n539  329    81   248 0.2462006\n540  329    77   252 0.2340426\n541  329    83   246 0.2522796\n542  329    79   250 0.2401216\n543  329    88   241 0.2674772\n544  329    97   232 0.2948328\n545  329    90   239 0.2735562\n546  329    80   249 0.2431611\n547  329    89   240 0.2705167\n548  329    83   246 0.2522796\n549  329    83   246 0.2522796\n550  329    92   237 0.2796353\n551  329    89   240 0.2705167\n552  329    73   256 0.2218845\n553  329    83   246 0.2522796\n554  329    70   259 0.2127660\n555  329    85   244 0.2583587\n556  329    81   248 0.2462006\n557  329    94   235 0.2857143\n558  329    83   246 0.2522796\n559  329    73   256 0.2218845\n560  329    84   245 0.2553191\n561  329    92   237 0.2796353\n562  329    77   252 0.2340426\n563  329    80   249 0.2431611\n564  329    75   254 0.2279635\n565  329    91   238 0.2765957\n566  329    88   241 0.2674772\n567  329    89   240 0.2705167\n568  329    87   242 0.2644377\n569  329    81   248 0.2462006\n570  329    84   245 0.2553191\n571  329    76   253 0.2310030\n572  329    75   254 0.2279635\n573  329    85   244 0.2583587\n574  329    82   247 0.2492401\n575  329    85   244 0.2583587\n576  329    72   257 0.2188450\n577  329    71   258 0.2158055\n578  329    97   232 0.2948328\n579  329    98   231 0.2978723\n580  329    76   253 0.2310030\n581  329    88   241 0.2674772\n582  329    84   245 0.2553191\n583  329    87   242 0.2644377\n584  329    66   263 0.2006079\n585  329    88   241 0.2674772\n586  329    83   246 0.2522796\n587  329    78   251 0.2370821\n588  329    99   230 0.3009119\n589  329    79   250 0.2401216\n590  329    84   245 0.2553191\n591  329    89   240 0.2705167\n592  329    77   252 0.2340426\n593  329    77   252 0.2340426\n594  329    85   244 0.2583587\n595  329    61   268 0.1854103\n596  329    85   244 0.2583587\n597  329    85   244 0.2583587\n598  329    84   245 0.2553191\n599  329    76   253 0.2310030\n600  329    84   245 0.2553191\n601  329    80   249 0.2431611\n602  329    93   236 0.2826748\n603  329    87   242 0.2644377\n604  329    84   245 0.2553191\n605  329    81   248 0.2462006\n606  329    76   253 0.2310030\n607  329    76   253 0.2310030\n608  329    86   243 0.2613982\n609  329    84   245 0.2553191\n610  329    90   239 0.2735562\n611  329    70   259 0.2127660\n612  329    77   252 0.2340426\n613  329    87   242 0.2644377\n614  329    77   252 0.2340426\n615  329    87   242 0.2644377\n616  329    76   253 0.2310030\n617  329    76   253 0.2310030\n618  329    95   234 0.2887538\n619  329    90   239 0.2735562\n620  329    94   235 0.2857143\n621  329    75   254 0.2279635\n622  329    71   258 0.2158055\n623  329    77   252 0.2340426\n624  329    71   258 0.2158055\n625  329    91   238 0.2765957\n626  329    79   250 0.2401216\n627  329    76   253 0.2310030\n628  329    95   234 0.2887538\n629  329    93   236 0.2826748\n630  329    80   249 0.2431611\n631  329    79   250 0.2401216\n632  329    86   243 0.2613982\n633  329    93   236 0.2826748\n634  329    86   243 0.2613982\n635  329    88   241 0.2674772\n636  329    82   247 0.2492401\n637  329    97   232 0.2948328\n638  329    82   247 0.2492401\n639  329    78   251 0.2370821\n640  329    70   259 0.2127660\n641  329    81   248 0.2462006\n642  329    79   250 0.2401216\n643  329    73   256 0.2218845\n644  329    89   240 0.2705167\n645  329    84   245 0.2553191\n646  329    95   234 0.2887538\n647  329    87   242 0.2644377\n648  329    75   254 0.2279635\n649  329    75   254 0.2279635\n650  329    78   251 0.2370821\n651  329   101   228 0.3069909\n652  329    82   247 0.2492401\n653  329    73   256 0.2218845\n654  329    73   256 0.2218845\n655  329    88   241 0.2674772\n656  329    83   246 0.2522796\n657  329    80   249 0.2431611\n658  329    84   245 0.2553191\n659  329    84   245 0.2553191\n660  329    75   254 0.2279635\n661  329    85   244 0.2583587\n662  329    86   243 0.2613982\n663  329    98   231 0.2978723\n664  329    78   251 0.2370821\n665  329    84   245 0.2553191\n666  329    90   239 0.2735562\n667  329    89   240 0.2705167\n668  329    75   254 0.2279635\n669  329    88   241 0.2674772\n670  329    73   256 0.2218845\n671  329    79   250 0.2401216\n672  329    69   260 0.2097264\n673  329    79   250 0.2401216\n674  329    71   258 0.2158055\n675  329    70   259 0.2127660\n676  329    85   244 0.2583587\n677  329    92   237 0.2796353\n678  329    95   234 0.2887538\n679  329    70   259 0.2127660\n680  329    74   255 0.2249240\n681  329    78   251 0.2370821\n682  329    79   250 0.2401216\n683  329    78   251 0.2370821\n684  329    71   258 0.2158055\n685  329    80   249 0.2431611\n686  329    61   268 0.1854103\n687  329    83   246 0.2522796\n688  329    73   256 0.2218845\n689  329    82   247 0.2492401\n690  329    76   253 0.2310030\n691  329    90   239 0.2735562\n692  329    82   247 0.2492401\n693  329    73   256 0.2218845\n694  329    69   260 0.2097264\n695  329    80   249 0.2431611\n696  329    90   239 0.2735562\n697  329    75   254 0.2279635\n698  329    79   250 0.2401216\n699  329    96   233 0.2917933\n700  329    84   245 0.2553191\n701  329    85   244 0.2583587\n702  329    88   241 0.2674772\n703  329    80   249 0.2431611\n704  329    96   233 0.2917933\n705  329    70   259 0.2127660\n706  329    83   246 0.2522796\n707  329    86   243 0.2613982\n708  329    84   245 0.2553191\n709  329    91   238 0.2765957\n710  329    89   240 0.2705167\n711  329    84   245 0.2553191\n712  329    93   236 0.2826748\n713  329    91   238 0.2765957\n714  329    89   240 0.2705167\n715  329    83   246 0.2522796\n716  329    76   253 0.2310030\n717  329    77   252 0.2340426\n718  329    84   245 0.2553191\n719  329    77   252 0.2340426\n720  329    83   246 0.2522796\n721  329    70   259 0.2127660\n722  329    85   244 0.2583587\n723  329    77   252 0.2340426\n724  329    83   246 0.2522796\n725  329    80   249 0.2431611\n726  329    80   249 0.2431611\n727  329    98   231 0.2978723\n728  329    65   264 0.1975684\n729  329    71   258 0.2158055\n730  329    94   235 0.2857143\n731  329    73   256 0.2218845\n732  329    90   239 0.2735562\n733  329    79   250 0.2401216\n734  329    72   257 0.2188450\n735  329    81   248 0.2462006\n736  329    86   243 0.2613982\n737  329    83   246 0.2522796\n738  329    70   259 0.2127660\n739  329    69   260 0.2097264\n740  329    88   241 0.2674772\n741  329    91   238 0.2765957\n742  329    65   264 0.1975684\n743  329    76   253 0.2310030\n744  329    86   243 0.2613982\n745  329    87   242 0.2644377\n746  329    73   256 0.2218845\n747  329    69   260 0.2097264\n748  329    85   244 0.2583587\n749  329    92   237 0.2796353\n750  329    86   243 0.2613982\n751  329    90   239 0.2735562\n752  329    65   264 0.1975684\n753  329    77   252 0.2340426\n754  329    69   260 0.2097264\n755  329    86   243 0.2613982\n756  329    82   247 0.2492401\n757  329    71   258 0.2158055\n758  329   104   225 0.3161094\n759  329    77   252 0.2340426\n760  329    85   244 0.2583587\n761  329    76   253 0.2310030\n762  329    91   238 0.2765957\n763  329    83   246 0.2522796\n764  329    78   251 0.2370821\n765  329    76   253 0.2310030\n766  329    86   243 0.2613982\n767  329    99   230 0.3009119\n768  329    83   246 0.2522796\n769  329    82   247 0.2492401\n770  329    82   247 0.2492401\n771  329    82   247 0.2492401\n772  329    85   244 0.2583587\n773  329    83   246 0.2522796\n774  329    75   254 0.2279635\n775  329    66   263 0.2006079\n776  329    82   247 0.2492401\n777  329    81   248 0.2462006\n778  329    79   250 0.2401216\n779  329    74   255 0.2249240\n780  329    71   258 0.2158055\n781  329    83   246 0.2522796\n782  329    93   236 0.2826748\n783  329   101   228 0.3069909\n784  329    78   251 0.2370821\n785  329    72   257 0.2188450\n786  329    83   246 0.2522796\n787  329    76   253 0.2310030\n788  329    73   256 0.2218845\n789  329    77   252 0.2340426\n790  329    88   241 0.2674772\n791  329    77   252 0.2340426\n792  329    82   247 0.2492401\n793  329    82   247 0.2492401\n794  329    88   241 0.2674772\n795  329    88   241 0.2674772\n796  329    83   246 0.2522796\n797  329    87   242 0.2644377\n798  329    85   244 0.2583587\n799  329    83   246 0.2522796\n800  329    82   247 0.2492401\n801  329    99   230 0.3009119\n802  329    83   246 0.2522796\n803  329    83   246 0.2522796\n804  329    83   246 0.2522796\n805  329    81   248 0.2462006\n806  329    87   242 0.2644377\n807  329    78   251 0.2370821\n808  329    96   233 0.2917933\n809  329    88   241 0.2674772\n810  329    88   241 0.2674772\n811  329    78   251 0.2370821\n812  329    97   232 0.2948328\n813  329   102   227 0.3100304\n814  329    75   254 0.2279635\n815  329    70   259 0.2127660\n816  329    90   239 0.2735562\n817  329    86   243 0.2613982\n818  329    75   254 0.2279635\n819  329    88   241 0.2674772\n820  329    86   243 0.2613982\n821  329    91   238 0.2765957\n822  329    78   251 0.2370821\n823  329    91   238 0.2765957\n824  329    63   266 0.1914894\n825  329    77   252 0.2340426\n826  329    83   246 0.2522796\n827  329    83   246 0.2522796\n828  329    78   251 0.2370821\n829  329    77   252 0.2340426\n830  329    88   241 0.2674772\n831  329    89   240 0.2705167\n832  329    85   244 0.2583587\n833  329    76   253 0.2310030\n834  329    89   240 0.2705167\n835  329    73   256 0.2218845\n836  329   101   228 0.3069909\n837  329    93   236 0.2826748\n838  329    88   241 0.2674772\n839  329    76   253 0.2310030\n840  329    89   240 0.2705167\n841  329    87   242 0.2644377\n842  329    82   247 0.2492401\n843  329    75   254 0.2279635\n844  329    86   243 0.2613982\n845  329    70   259 0.2127660\n846  329    77   252 0.2340426\n847  329    89   240 0.2705167\n848  329    81   248 0.2462006\n849  329    80   249 0.2431611\n850  329    77   252 0.2340426\n851  329    81   248 0.2462006\n852  329    84   245 0.2553191\n853  329    94   235 0.2857143\n854  329    92   237 0.2796353\n855  329    77   252 0.2340426\n856  329    80   249 0.2431611\n857  329    81   248 0.2462006\n858  329    72   257 0.2188450\n859  329    77   252 0.2340426\n860  329    81   248 0.2462006\n861  329    72   257 0.2188450\n862  329    86   243 0.2613982\n863  329    92   237 0.2796353\n864  329    71   258 0.2158055\n865  329    87   242 0.2644377\n866  329    86   243 0.2613982\n867  329    82   247 0.2492401\n868  329    90   239 0.2735562\n869  329    94   235 0.2857143\n870  329    92   237 0.2796353\n871  329    95   234 0.2887538\n872  329    70   259 0.2127660\n873  329    76   253 0.2310030\n874  329    84   245 0.2553191\n875  329    88   241 0.2674772\n876  329    77   252 0.2340426\n877  329    82   247 0.2492401\n878  329    84   245 0.2553191\n879  329    72   257 0.2188450\n880  329    77   252 0.2340426\n881  329    70   259 0.2127660\n882  329    64   265 0.1945289\n883  329    77   252 0.2340426\n884  329    90   239 0.2735562\n885  329    86   243 0.2613982\n886  329    69   260 0.2097264\n887  329    79   250 0.2401216\n888  329    87   242 0.2644377\n889  329    84   245 0.2553191\n890  329    83   246 0.2522796\n891  329    79   250 0.2401216\n892  329    72   257 0.2188450\n893  329    91   238 0.2765957\n894  329    81   248 0.2462006\n895  329    85   244 0.2583587\n896  329    76   253 0.2310030\n897  329    92   237 0.2796353\n898  329    82   247 0.2492401\n899  329    80   249 0.2431611\n900  329    80   249 0.2431611\n901  329    81   248 0.2462006\n902  329    87   242 0.2644377\n903  329    88   241 0.2674772\n904  329    77   252 0.2340426\n905  329    89   240 0.2705167\n906  329    94   235 0.2857143\n907  329    75   254 0.2279635\n908  329    90   239 0.2735562\n909  329    86   243 0.2613982\n910  329    83   246 0.2522796\n911  329    85   244 0.2583587\n912  329    90   239 0.2735562\n913  329    89   240 0.2705167\n914  329    87   242 0.2644377\n915  329    77   252 0.2340426\n916  329    80   249 0.2431611\n917  329    73   256 0.2218845\n918  329    82   247 0.2492401\n919  329    64   265 0.1945289\n920  329    82   247 0.2492401\n921  329    75   254 0.2279635\n922  329    87   242 0.2644377\n923  329    91   238 0.2765957\n924  329    88   241 0.2674772\n925  329    75   254 0.2279635\n926  329    72   257 0.2188450\n927  329    83   246 0.2522796\n928  329    78   251 0.2370821\n929  329    99   230 0.3009119\n930  329    77   252 0.2340426\n931  329    86   243 0.2613982\n932  329    95   234 0.2887538\n933  329    78   251 0.2370821\n934  329    84   245 0.2553191\n935  329    92   237 0.2796353\n936  329    86   243 0.2613982\n937  329   100   229 0.3039514\n938  329    90   239 0.2735562\n939  329    78   251 0.2370821\n940  329    98   231 0.2978723\n941  329    72   257 0.2188450\n942  329    85   244 0.2583587\n943  329    64   265 0.1945289\n944  329    82   247 0.2492401\n945  329    85   244 0.2583587\n946  329    94   235 0.2857143\n947  329    82   247 0.2492401\n948  329    91   238 0.2765957\n949  329    88   241 0.2674772\n950  329    79   250 0.2401216\n951  329    78   251 0.2370821\n952  329    72   257 0.2188450\n953  329    84   245 0.2553191\n954  329    97   232 0.2948328\n955  329    89   240 0.2705167\n956  329    81   248 0.2462006\n957  329    76   253 0.2310030\n958  329    90   239 0.2735562\n959  329    77   252 0.2340426\n960  329    99   230 0.3009119\n961  329    82   247 0.2492401\n962  329    82   247 0.2492401\n963  329    78   251 0.2370821\n964  329    85   244 0.2583587\n965  329    73   256 0.2218845\n966  329    79   250 0.2401216\n967  329    91   238 0.2765957\n968  329    84   245 0.2553191\n969  329    77   252 0.2340426\n970  329    74   255 0.2249240\n971  329    88   241 0.2674772\n972  329    82   247 0.2492401\n973  329    92   237 0.2796353\n974  329    81   248 0.2462006\n975  329    85   244 0.2583587\n976  329    82   247 0.2492401\n977  329    83   246 0.2522796\n978  329    85   244 0.2583587\n979  329    75   254 0.2279635\n980  329    88   241 0.2674772\n981  329    75   254 0.2279635\n982  329    89   240 0.2705167\n983  329    83   246 0.2522796\n984  329    78   251 0.2370821\n985  329    71   258 0.2158055\n986  329    90   239 0.2735562\n987  329    65   264 0.1975684\n988  329    92   237 0.2796353\n989  329    93   236 0.2826748\n990  329    89   240 0.2705167\n991  329    87   242 0.2644377\n992  329    78   251 0.2370821\n993  329    84   245 0.2553191\n994  329    87   242 0.2644377\n995  329    74   255 0.2249240\n996  329    96   233 0.2917933\n997  329    84   245 0.2553191\n998  329    81   248 0.2462006\n999  329    83   246 0.2522796\n1000 329    81   248 0.2462006"
  },
  {
    "objectID": "stat100_wk09wed.html#sampling-distribution-under-no-esp-2",
    "href": "stat100_wk09wed.html#sampling-distribution-under-no-esp-2",
    "title": "Stat 100",
    "section": "Sampling Distribution Under No ESP",
    "text": "Sampling Distribution Under No ESP\n\n\nggplot(data = guess_sampling_dist,\n       mapping = aes(x = prop)) +\n  geom_histogram(color = \"white\",\n                 bins = 20)\n\n\n\n\n\n\n\n\n\n\nWhat value should our sampling distribution be centered around if the receivers are just guessing?"
  },
  {
    "objectID": "stat100_wk09wed.html#sampling-distribution-under-no-esp-3",
    "href": "stat100_wk09wed.html#sampling-distribution-under-no-esp-3",
    "title": "Stat 100",
    "section": "Sampling Distribution Under No ESP",
    "text": "Sampling Distribution Under No ESP\n\n\nHow do the study results compare to the sampling distribution under no ESP?\n\nHow unusual is it to guess correctly 106 out of 329 times if ESP doesn’t exist?\n\n\n\n\n\np_hat &lt;- 106/329\nggplot(data = guess_sampling_dist,\n       mapping = aes(x = prop)) +\n  geom_histogram(color = \"white\",\n                 bins = 20) +\n  geom_vline(xintercept = p_hat,\n             color = \"orange\",\n             size = 2)\n\n\n\n\n\n\n\n\n\n\n\nDo Bem and Honorton have evidence that ESP exists?"
  },
  {
    "objectID": "stat100_wk09wed.html#do-harvardians-have-esp",
    "href": "stat100_wk09wed.html#do-harvardians-have-esp",
    "title": "Stat 100",
    "section": "Do Harvardians Have ESP?",
    "text": "Do Harvardians Have ESP?\n\n\nIn pairs:\n\n\nDecide who is going to be the sender and who is going to be the receiver.\nSender: Think of one of these images.\nReceiver: Guess which image the sender was thinking of.\nNow switch roles and do it again!\nOnce you have both played each role, each person should add a tally mark on the chalkboard."
  },
  {
    "objectID": "stat100_wk09wed.html#do-harvardians-have-esp-1",
    "href": "stat100_wk09wed.html#do-harvardians-have-esp-1",
    "title": "Stat 100",
    "section": "Do Harvardians Have ESP?",
    "text": "Do Harvardians Have ESP?\nWhat do we need to modify in the code to answer the question?\n\nguess_sampling_dist &lt;- do(1000)*rflip(n = 80, prob = 0.25)\np_hat &lt;- 27/80\nggplot(data = guess_sampling_dist, mapping = aes(x = prop)) +\n  geom_histogram(color = \"white\", bins = 20) +\n  geom_vline(xintercept = p_hat, color = \"orange\", size = 2)"
  },
  {
    "objectID": "stat100_wk09wed.html#reminders",
    "href": "stat100_wk09wed.html#reminders",
    "title": "Stat 100",
    "section": "Reminders:",
    "text": "Reminders:\n\n\nDon’t forget that the midterm exam rewrites are due on Thursday at 5pm on Gradescope.\n\nMake sure to use the Quarto doc in the Midterm Exam (Rewrites) project on Posit Cloud.\n\n🎉 We are now accepting Course Assistant/Teaching Fellow applications for Stat 100 for next semester. To apply, fill out this application by Nov 15th.\n\nAbout 10-12 hours of work per week.\n\nPrimary responsibilities: Attend weekly team meetings, lead a discussion section, hold office hours, grade assessments."
  },
  {
    "objectID": "stat100_wk04wed.html#announcements",
    "href": "stat100_wk04wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nOral practice in section this week.\n\nGoals for Today\n\nFinish up data joins.\nCover data collection/acquisition."
  },
  {
    "objectID": "stat100_wk04wed.html#which-are-you",
    "href": "stat100_wk04wed.html#which-are-you",
    "title": "Stat 100",
    "section": "Which Are YOU?",
    "text": "Which Are YOU?\n\n\nData Visualizer\n\n\n\nvia GIPHY\n\n\nData Wrangler\n\n\n\nvia GIPHY"
  },
  {
    "objectID": "stat100_wk04wed.html#load-necessary-packages",
    "href": "stat100_wk04wed.html#load-necessary-packages",
    "title": "Stat 100",
    "section": "Load Necessary Packages",
    "text": "Load Necessary Packages\n\n\n\n\n\ndplyr is part of this collection of data science packages.\n\n# Load necessary packages\nlibrary(tidyverse)"
  },
  {
    "objectID": "stat100_wk04wed.html#data-setting-bureau-of-labor-statistics-bls-consumer-expenditure-survey",
    "href": "stat100_wk04wed.html#data-setting-bureau-of-labor-statistics-bls-consumer-expenditure-survey",
    "title": "Stat 100",
    "section": "Data Setting: Bureau of Labor Statistics (BLS) Consumer Expenditure Survey",
    "text": "Data Setting: Bureau of Labor Statistics (BLS) Consumer Expenditure Survey\nBLS Mission: “Measures labor market activity, working conditions, price changes, and productivity in the U.S. economy to support public and private decision making.”\nData: Last quarter of the 2016 BLS Consumer Expenditure Survey.\n\nlibrary(tidyverse)\n\nce_raw &lt;- read_csv(\"data/fmli.csv\", \n                 na = c(\"NA\", \".\"))\nglimpse(ce_raw)\n\nRows: 6,301\nColumns: 51\n$ NEWID    &lt;chr&gt; \"03324174\", \"03324204\", \"03324214\", \"03324244\", \"03324274\", \"…\n$ PRINEARN &lt;chr&gt; \"01\", \"01\", \"01\", \"01\", \"02\", \"01\", \"01\", \"01\", \"02\", \"01\", \"…\n$ FINLWT21 &lt;dbl&gt; 25984.767, 6581.018, 20208.499, 18078.372, 20111.619, 19907.3…\n$ FINCBTAX &lt;dbl&gt; 116920, 200, 117000, 0, 2000, 942, 0, 91000, 95000, 40037, 10…\n$ BLS_URBN &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ POPSIZE  &lt;dbl&gt; 2, 3, 4, 2, 2, 2, 1, 2, 5, 2, 3, 2, 2, 3, 4, 3, 3, 1, 4, 1, 1…\n$ EDUC_REF &lt;chr&gt; \"16\", \"15\", \"16\", \"15\", \"14\", \"11\", \"10\", \"13\", \"12\", \"12\", \"…\n$ EDUCA2   &lt;dbl&gt; 15, 15, 13, NA, NA, NA, NA, 15, 15, 14, 12, 12, NA, NA, NA, 1…\n$ AGE_REF  &lt;dbl&gt; 63, 50, 47, 37, 51, 63, 77, 37, 51, 64, 26, 59, 81, 51, 67, 4…\n$ AGE2     &lt;dbl&gt; 50, 47, 46, NA, NA, NA, NA, 36, 53, 67, 44, 62, NA, NA, NA, 4…\n$ SEX_REF  &lt;dbl&gt; 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1…\n$ SEX2     &lt;dbl&gt; 2, 2, 1, NA, NA, NA, NA, 2, 2, 1, 1, 1, NA, NA, NA, 1, NA, 1,…\n$ REF_RACE &lt;dbl&gt; 1, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1…\n$ RACE2    &lt;dbl&gt; 1, 4, 1, NA, NA, NA, NA, 1, 1, 1, 1, 1, NA, NA, NA, 2, NA, 1,…\n$ HISP_REF &lt;dbl&gt; 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1…\n$ HISP2    &lt;dbl&gt; 2, 2, 1, NA, NA, NA, NA, 2, 2, 2, 2, 2, NA, NA, NA, 2, NA, 2,…\n$ FAM_TYPE &lt;dbl&gt; 3, 4, 1, 8, 9, 9, 8, 3, 1, 1, 3, 1, 8, 9, 8, 5, 9, 4, 8, 3, 2…\n$ MARITAL1 &lt;dbl&gt; 1, 1, 1, 5, 3, 3, 2, 1, 1, 1, 1, 1, 2, 3, 5, 1, 3, 1, 3, 1, 1…\n$ REGION   &lt;dbl&gt; 4, 4, 3, 4, 4, 3, 4, 1, 3, 2, 1, 4, 1, 3, 3, 3, 2, 1, 2, 4, 3…\n$ SMSASTAT &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ HIGH_EDU &lt;chr&gt; \"16\", \"15\", \"16\", \"15\", \"14\", \"11\", \"10\", \"15\", \"15\", \"14\", \"…\n$ EHOUSNGC &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ TOTEXPCQ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ FOODCQ   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ TRANSCQ  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ HEALTHCQ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ENTERTCQ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ EDUCACQ  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ TOBACCCQ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ STUDFINX &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ IRAX     &lt;dbl&gt; 1000000, 10000, 0, NA, NA, 0, 0, 15000, NA, 477000, NA, NA, N…\n$ CUTENURE &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 4, 1, 1, 2, 1, 2, 2, 2, 2, 4, 1, 1, 1, 4, 4…\n$ FAM_SIZE &lt;dbl&gt; 4, 6, 2, 1, 2, 2, 1, 5, 2, 2, 4, 2, 1, 2, 1, 4, 2, 4, 1, 3, 3…\n$ VEHQ     &lt;dbl&gt; 3, 5, 0, 4, 2, 0, 0, 2, 4, 2, 3, 2, 1, 3, 1, 2, 4, 4, 0, 2, 3…\n$ ROOMSQ   &lt;dbl&gt; 8, 5, 6, 4, 4, 4, 7, 5, 4, 9, 6, 10, 4, 7, 5, 6, 6, 8, 18, 4,…\n$ INC_HRS1 &lt;dbl&gt; 40, 40, 40, 44, 40, NA, NA, 40, 40, NA, 40, NA, NA, NA, NA, 4…\n$ INC_HRS2 &lt;dbl&gt; 30, 40, 52, NA, NA, NA, NA, 40, 40, NA, 65, NA, NA, NA, NA, 6…\n$ EARNCOMP &lt;dbl&gt; 3, 2, 2, 1, 4, 7, 8, 2, 2, 8, 2, 8, 8, 7, 8, 2, 7, 3, 1, 2, 1…\n$ NO_EARNR &lt;dbl&gt; 4, 2, 2, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 2, 1, 3, 1, 2, 1…\n$ OCCUCOD1 &lt;chr&gt; \"03\", \"03\", \"05\", \"03\", \"04\", \"\", \"\", \"12\", \"04\", \"\", \"01\", \"…\n$ OCCUCOD2 &lt;chr&gt; \"04\", \"02\", \"01\", \"\", \"\", \"\", \"\", \"02\", \"03\", \"\", \"11\", \"\", \"…\n$ STATE    &lt;chr&gt; \"41\", \"15\", \"48\", \"06\", \"06\", \"48\", \"06\", \"42\", \"\", \"27\", \"25…\n$ DIVISION &lt;dbl&gt; 9, 9, 7, 9, 9, 7, 9, 2, NA, 4, 1, 8, 2, 5, 6, 7, 3, 2, 3, 9, …\n$ TOTXEST  &lt;dbl&gt; 15452, 11459, 15738, 25978, 588, 0, 0, 7261, 9406, -1414, 141…\n$ CREDFINX &lt;dbl&gt; 0, NA, 0, NA, 5, NA, NA, NA, NA, 0, NA, 0, NA, NA, NA, 2, 35,…\n$ CREDITB  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREDITX  &lt;dbl&gt; 4000, 5000, 2000, NA, 7000, 1800, NA, 6000, NA, 719, NA, 1200…\n$ BUILDING &lt;chr&gt; \"01\", \"01\", \"01\", \"02\", \"08\", \"01\", \"01\", \"01\", \"01\", \"01\", \"…\n$ ST_HOUS  &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ INT_PHON &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ INT_HOME &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  },
  {
    "objectID": "stat100_wk04wed.html#ce-data",
    "href": "stat100_wk04wed.html#ce-data",
    "title": "Stat 100",
    "section": "CE Data",
    "text": "CE Data\n\n\nHousehold survey but data are also collected on individuals\n\nfmli: household data\nmemi: household member-level data\n\n\n\n\nfmli &lt;- read_csv(\"data/fmli.csv\", \n                 na = c(\"NA\", \".\")) %&gt;%\n  select(NEWID, PRINEARN, FINCBTAX,\n         BLS_URBN, HIGH_EDU)\nmemi &lt;- read_csv(\"data/memi.csv\", \n                 na = c(\"NA\", \".\")) %&gt;%\n  select(NEWID, MEMBNO, AGE, SEX, EARNTYPE)\n\nfmli &lt;- mutate(fmli, PRINEARN = as.integer(PRINEARN))\n\n\nWant to add variables on the principal earner from the member data frame to the household data frame"
  },
  {
    "objectID": "stat100_wk04wed.html#smaller-sets-of-ce-data",
    "href": "stat100_wk04wed.html#smaller-sets-of-ce-data",
    "title": "Stat 100",
    "section": "Smaller Sets of CE Data",
    "text": "Smaller Sets of CE Data\n\n\n\nfmli_small &lt;- filter(fmli, NEWID %in% c(\"03530051\",\n                                        \"03327224\",\n                                        \"03324324\",\n                                        \"03324244\"))\nfmli_small\n\n# A tibble: 4 × 5\n  NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU\n  &lt;chr&gt;       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;   \n1 03324244        1        0        1 15      \n2 03324324        2    95000        2 15      \n3 03327224        1        0        1 14      \n4 03530051        3    70000        1 11      \n\n\n\n\nmemi_small &lt;- filter(memi, NEWID %in% c(\"03530051\",\n                                        \"03327224\",\n                                        \"03324324\",\n                                        \"03324244\"))\nmemi_small\n\n# A tibble: 10 × 5\n   NEWID    MEMBNO   AGE   SEX EARNTYPE\n   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 03324244      1    37     1        1\n 2 03324324      1    51     1        1\n 3 03324324      2    53     2        1\n 4 03327224      1    28     2        3\n 5 03327224      2    32     1        2\n 6 03327224      3     1     2       NA\n 7 03530051      1    43     1       NA\n 8 03530051      2    16     1       NA\n 9 03530051      3    44     1        3\n10 03530051      4     5     2       NA"
  },
  {
    "objectID": "stat100_wk04wed.html#look-at-the-possible-joins",
    "href": "stat100_wk04wed.html#look-at-the-possible-joins",
    "title": "Stat 100",
    "section": "Look at the Possible Joins",
    "text": "Look at the Possible Joins\n\nfull_join(fmli_small, memi_small, join_by(\"NEWID\" == \"NEWID\", \"PRINEARN\" == \"MEMBNO\"))\n\n# A tibble: 10 × 8\n   NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU   AGE   SEX EARNTYPE\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 03324244        1        0        1 15          37     1        1\n 2 03324324        2    95000        2 15          53     2        1\n 3 03327224        1        0        1 14          28     2        3\n 4 03530051        3    70000        1 11          44     1        3\n 5 03324324        1       NA       NA &lt;NA&gt;        51     1        1\n 6 03327224        2       NA       NA &lt;NA&gt;        32     1        2\n 7 03327224        3       NA       NA &lt;NA&gt;         1     2       NA\n 8 03530051        1       NA       NA &lt;NA&gt;        43     1       NA\n 9 03530051        2       NA       NA &lt;NA&gt;        16     1       NA\n10 03530051        4       NA       NA &lt;NA&gt;         5     2       NA"
  },
  {
    "objectID": "stat100_wk04wed.html#joining-tips",
    "href": "stat100_wk04wed.html#joining-tips",
    "title": "Stat 100",
    "section": "Joining Tips",
    "text": "Joining Tips\n\nfmli &lt;- left_join(fmli, memi, join_by(\"NEWID\" == \"NEWID\", \"PRINEARN\" == \"MEMBNO\"))\n\n\nFIRST: conceptualize for yourself what you think you want the final dataset to look like!\nCheck initial dimensions and final dimensions.\nUse variable names when joining even if they are the same."
  },
  {
    "objectID": "stat100_wk04wed.html#naming-wrangled-data",
    "href": "stat100_wk04wed.html#naming-wrangled-data",
    "title": "Stat 100",
    "section": "Naming Wrangled Data",
    "text": "Naming Wrangled Data\nShould I name my new dataframe ce or ce1?\n\nMy answer:\n\nIs your new dataset structurally different? If so, give it a new name.\nAre you removing values you will need for a future analysis within the same document? If so, give it a new name.\nAre you just adding to or cleaning the data? If so, then write over the original."
  },
  {
    "objectID": "stat100_wk04wed.html#now-for-data-collection",
    "href": "stat100_wk04wed.html#now-for-data-collection",
    "title": "Stat 100",
    "section": "Now for Data Collection",
    "text": "Now for Data Collection"
  },
  {
    "objectID": "stat100_wk04wed.html#motivating-our-discussion-of-data-collection",
    "href": "stat100_wk04wed.html#motivating-our-discussion-of-data-collection",
    "title": "Stat 100",
    "section": "Motivating Our Discussion of Data Collection",
    "text": "Motivating Our Discussion of Data Collection"
  },
  {
    "objectID": "stat100_wk04wed.html#who-are-the-data-supposed-to-represent",
    "href": "stat100_wk04wed.html#who-are-the-data-supposed-to-represent",
    "title": "Stat 100",
    "section": "Who are the data supposed to represent?",
    "text": "Who are the data supposed to represent?\n\n\n\n\n\nKey questions:\n\nWhat evidence is there that the data are representative?\nWho is present? Who is absent?\nWho is overrepresented? Who is underrepresented?"
  },
  {
    "objectID": "stat100_wk04wed.html#who-are-the-data-supposed-to-represent-1",
    "href": "stat100_wk04wed.html#who-are-the-data-supposed-to-represent-1",
    "title": "Stat 100",
    "section": "Who are the data supposed to represent?",
    "text": "Who are the data supposed to represent?\n\n\n\n\n\nCensus: We have data on the whole population!"
  },
  {
    "objectID": "stat100_wk04wed.html#who-are-the-data-supposed-to-represent-2",
    "href": "stat100_wk04wed.html#who-are-the-data-supposed-to-represent-2",
    "title": "Stat 100",
    "section": "Who are the data supposed to represent?",
    "text": "Who are the data supposed to represent?"
  },
  {
    "objectID": "stat100_wk04wed.html#who-are-the-data-supposed-to-represent-3",
    "href": "stat100_wk04wed.html#who-are-the-data-supposed-to-represent-3",
    "title": "Stat 100",
    "section": "Who are the data supposed to represent?",
    "text": "Who are the data supposed to represent?\n\n\n\n\n\nKey questions:\n\nWhat evidence is there that the sample is representative of the population?\nWho is present? Who is absent?\nWho is overrepresented? Who is underrepresented?"
  },
  {
    "objectID": "stat100_wk04wed.html#sampling-bias",
    "href": "stat100_wk04wed.html#sampling-bias",
    "title": "Stat 100",
    "section": "Sampling Bias",
    "text": "Sampling Bias\n\n\n\n\n\nSampling bias: When the sampled units are systematically different from the non-sampled units on the variables of interest."
  },
  {
    "objectID": "stat100_wk04wed.html#random-sampling",
    "href": "stat100_wk04wed.html#random-sampling",
    "title": "Stat 100",
    "section": "Random Sampling",
    "text": "Random Sampling\nUse random sampling (a random mechanism for selecting cases from the population) to remove sampling bias.\nTypes of random sampling\n\nSimple random sampling\nCluster sampling\nStratified random sampling\nSystematic sampling\n\n\nWhy aren’t all samples generated using simple random sampling?"
  },
  {
    "objectID": "stat100_wk04wed.html#responsibilities-to-research-subjects",
    "href": "stat100_wk04wed.html#responsibilities-to-research-subjects",
    "title": "Stat 100",
    "section": "Responsibilities to Research Subjects",
    "text": "Responsibilities to Research Subjects\n\n“The ethical statistician protects and respects the rights and interests of human and animal subjects at all stages of their involvement in a project. This includes respondents to the census or to surveys, those whose data are contained in administrative records, and subjects of physically or psychologically invasive research.”"
  },
  {
    "objectID": "stat100_wk04wed.html#detour-from-our-detour",
    "href": "stat100_wk04wed.html#detour-from-our-detour",
    "title": "Stat 100",
    "section": "Detour from Our Detour",
    "text": "Detour from Our Detour\n\n\nlibrary(tidyverse)\nlibrary(NHANES)\n\nggplot(data = NHANES, \n       mapping = aes(x = Age,\n                     y = Height)) +\n  geom_point(alpha = 0.1) +\n  geom_smooth(color = \"skyblue\")"
  },
  {
    "objectID": "stat100_wk04wed.html#detour-from-our-detour-1",
    "href": "stat100_wk04wed.html#detour-from-our-detour-1",
    "title": "Stat 100",
    "section": "Detour from Our Detour",
    "text": "Detour from Our Detour\n\n\nlibrary(tidyverse)\nlibrary(NHANES)\nlibrary(emojifont)\n\nNHANES &lt;- mutate(NHANES, \n          heart = fontawesome(\"fa-heart\"))\n\nggplot(data = NHANES, \n       mapping = aes(x = Age,\n                     y = Height,\n                     label = heart)) +\n  geom_text(alpha = 0.1, color = \"red\",\n            family='fontawesome-webfont',\n            size = 16) +\n  stat_smooth(color = \"deeppink\")"
  },
  {
    "objectID": "stat100_wk02mon.html#announcements",
    "href": "stat100_wk02mon.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nClass in full swing:\n\nSections: Can find your assigned section in my.harvard but need to go to the linked spreadsheet to find the room!\nOffice hours\nWrap-ups on Th 3-4pm and Fri 10:30 - 11:30am in SC 309\nLecture quiz will be released in Gradescope after class on Wednesday."
  },
  {
    "objectID": "stat100_wk02mon.html#day-2-goals",
    "href": "stat100_wk02mon.html#day-2-goals",
    "title": "Stat 100",
    "section": "Day 2 Goals",
    "text": "Day 2 Goals\n\nDiscuss course structure & goals (lecture, section, wrap-ups, office hours, assessments…)\nPresent important course policies (engagement, code of conduct, chatGPT, …)\nGet started in RStudio and with Quarto documents"
  },
  {
    "objectID": "stat100_wk02mon.html#data-analysis-workflow",
    "href": "stat100_wk02mon.html#data-analysis-workflow",
    "title": "Stat 100",
    "section": "Data Analysis Workflow",
    "text": "Data Analysis Workflow"
  },
  {
    "objectID": "stat100_wk02mon.html#stat-100-weekly-flow",
    "href": "stat100_wk02mon.html#stat-100-weekly-flow",
    "title": "Stat 100",
    "section": "Stat 100 Weekly Flow",
    "text": "Stat 100 Weekly Flow"
  },
  {
    "objectID": "stat100_wk02mon.html#forms-of-assessment",
    "href": "stat100_wk02mon.html#forms-of-assessment",
    "title": "Stat 100",
    "section": "Forms of Assessment",
    "text": "Forms of Assessment\n\n\n\nWeekly lecture quizzes:\n\nAddress important concepts covered.\nFind out what is still confusing.\nCan drop one quiz grade.\n\n\n\n\nWeekly problem sets:\n\nPractice concepts.\nTime during section will be devoted to starting the next p-set.\nCan drop one p-set grade and get 4 extension days.\n\n\n\n\n\n\n\nExams:\n\nFormat: In-class Exam & Oral Exam.\nWill have both a Mid-term and Final.\n\n\n\n\nParticipation/Engagement:\n\nIn lecture and section.\nBy Oct 9th, must:\n\nAttend at least one office hour.\nPost at least two messages on Slack."
  },
  {
    "objectID": "stat100_wk02mon.html#this-weeks-assessments",
    "href": "stat100_wk02mon.html#this-weeks-assessments",
    "title": "Stat 100",
    "section": "This Week’s Assessments",
    "text": "This Week’s Assessments\n\nLecture quiz releases on Wed at 11:45am.\nP-Set 1 will be posted to Posit Cloud on Wednesday.\n\nDue the following Tuesday, September 19th at 5pm on Gradescope.\nIn section this week, you will get started on P-Set 1 and will learn how to submit to Gradescope."
  },
  {
    "objectID": "stat100_wk02mon.html#professor-mcconville-in-spring-2023",
    "href": "stat100_wk02mon.html#professor-mcconville-in-spring-2023",
    "title": "Stat 100",
    "section": "Professor McConville in Spring 2023",
    "text": "Professor McConville in Spring 2023\n\n\n\nBBC Science Focus"
  },
  {
    "objectID": "stat100_wk02mon.html#professor-mcconville-in-summer-2023",
    "href": "stat100_wk02mon.html#professor-mcconville-in-summer-2023",
    "title": "Stat 100",
    "section": "Professor McConville in Summer 2023",
    "text": "Professor McConville in Summer 2023\n\n\n\n\n\nRicardo IV Tamayo\n\n\n\nGenerative AI Engagements\n\nParticipated in Stats Dept reading group on generative AI\nWent to conference talks on generative AI\nTalked to ChatGPT"
  },
  {
    "objectID": "stat100_wk02mon.html#chatgpt",
    "href": "stat100_wk02mon.html#chatgpt",
    "title": "Stat 100",
    "section": "",
    "text": "ChatGPT Strengths\n\nVery dangerous automated data analysis.\n\nHard to determine if its conclusions are based on the data at hand or the data the large language model was built on.\n\n\n\nStat 100 Goals\n\nLearn that data analysis is a humanistic endeavor where context drives the data analysis process.\n\nStill need to be careful about biases and data quality.\n\n\n\n\n\n\n\nA personalized tutor (especially for coding) that tells you the answers.\n\n\n\nFor you to learn to code and to think statistically.\n\nThe Stat 100 Teaching Team will help support that learning.\n\n\n\n\n\n\n\nInstantly generating written blurbs.\n\n\n\nFor you to learn how to communicate about your data work and data ethics."
  },
  {
    "objectID": "stat100_wk02mon.html#my-view-on-the-current-role-of-chatgpt-in-data-work",
    "href": "stat100_wk02mon.html#my-view-on-the-current-role-of-chatgpt-in-data-work",
    "title": "Stat 100",
    "section": "My View on the (Current) Role of ChatGPT in Data Work",
    "text": "My View on the (Current) Role of ChatGPT in Data Work\n\nTo generate code to realize fully conceived ideas that aren’t novel or advanced.\nSeasoned data scientist can/should:\n\nVerify the correctness of the code.\nIdentify any assumptions or defaults ChatGPT is employing.\nRun the code in R and draw conclusions based on the data to reduce risk of perpetuating biases that exist in ChatGPT’s training data.\n\nSo, ChatGPT might be useful to you after Stat 100 but will be detrimental to your learning during Stat 100."
  },
  {
    "objectID": "stat100_wk02mon.html#ai-policy-for-stat-100",
    "href": "stat100_wk02mon.html#ai-policy-for-stat-100",
    "title": "Stat 100",
    "section": "AI Policy for Stat 100",
    "text": "AI Policy for Stat 100\n\nWhile A.I. tools, such as ChatGPT, are being used to generate code and analyze data, goals of this course are to develop your own ability to write code and to thoughtfully extract knowledge from data. Therefore, we expect that all work students submit for this course will be their own. This includes code, written work, and oral assessments. We specifically forbid the use of ChatGPT or any other generative artificial intelligence (AI) tools at all stages of the work process, including preliminary ones, unless the assignment specifically states that it is allowed. Violations of this policy will be considered academic misconduct. We draw your attention to the fact that different classes at Harvard could implement different AI policies, and it is the student’s responsibility to conform to expectations for each course.\n\n\nThe goal of this policy is not to lessen your access to support but to ensure we are achieving the learning objectives of the course. Please see the Avenues for Help section of the syllabus for ways to get support in Stat 100."
  },
  {
    "objectID": "stat100_wk02mon.html#engagement",
    "href": "stat100_wk02mon.html#engagement",
    "title": "Stat 100",
    "section": "Engagement",
    "text": "Engagement\n\n\n \n\n\n\n\n\n\nBeing actively present is key.\n\n\n\nDuring lecture and section, remove distractions.\n\nWhen we are on our computers, close email, social media, news, etc.\nIf you will be using a computer/tablet for taking notes, please sit outside the technology-free zone (first 6 rows of the middle section) starting next lecture so as not to distract classmates.\nHide your phone.\n\nI have high expectations but know that all of you (regardless of your stats or computing background) have the ability to meet them."
  },
  {
    "objectID": "stat100_wk02mon.html#identity-and-the-classroom",
    "href": "stat100_wk02mon.html#identity-and-the-classroom",
    "title": "Stat 100",
    "section": "Identity and the Classroom",
    "text": "Identity and the Classroom\n\nAcknowledge that my perspectives and experiences have shaped how I teach this course and how I approach my data work\nSome of my identities place me in dominant groups while others in marginalized groups\nStrive to bring examples and scholarly contributions that value knowledge from folks with a wide variety of identities\nStrive to be a open listener and recognize your thoughts as a generous offer and a vote of confidence in my ability to hear and be transformed by you\nAsk that you reflect on your own identities, privileges, and power and how they impact your engagement with Stat 100"
  },
  {
    "objectID": "stat100_wk02mon.html#code-of-conduct",
    "href": "stat100_wk02mon.html#code-of-conduct",
    "title": "Stat 100",
    "section": "Code of Conduct",
    "text": "Code of Conduct\n\nWe expect all members of STAT 100 to make participation a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n\nWe expect everyone to act and interact in ways that contribute to an open, welcoming diverse, inclusive, and healthy community of learners. You can contribute to a positive learning environment by demonstrating empathy and kindness, being respectful of differing viewpoints and experiences, and giving and gracefully accepting constructive feedback.\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0."
  },
  {
    "objectID": "stat100_wk02mon.html#ways-to-get-support",
    "href": "stat100_wk02mon.html#ways-to-get-support",
    "title": "Stat 100",
    "section": "Ways to Get Support",
    "text": "Ways to Get Support\n\nAttend, attend, attend when you don’t feel ill\nParticipate in the Stat 100 Slack Workspace\nCome to Office Hours and Wrap-up Sessions\nCreate study groups with your classmates\n\nDon’t know anyone in the course?\n\nUse Slack or Section to each to know other students in the course!\nFill out this Stat 100 study group matching form"
  },
  {
    "objectID": "stat100_wk02mon.html#language-r-this-r-that-q-what",
    "href": "stat100_wk02mon.html#language-r-this-r-that-q-what",
    "title": "Stat 100",
    "section": "Language: R-This, R-That, Q-What?",
    "text": "Language: R-This, R-That, Q-What?\n\n\n\n \n\n\nR is the name of the programming language.\n\n\n\nRStudio is the pretty interface and is hosted on a Posit Cloud Server.\n\n\n\n\nQuarto is the type of file where we will record all of our work (code, output, narrative)."
  },
  {
    "objectID": "stat100_wk02mon.html#main-components-of-rstudio-lay-out",
    "href": "stat100_wk02mon.html#main-components-of-rstudio-lay-out",
    "title": "Stat 100",
    "section": "Main Components of RStudio Lay-Out",
    "text": "Main Components of RStudio Lay-Out"
  },
  {
    "objectID": "stat100_wk02mon.html#reminders",
    "href": "stat100_wk02mon.html#reminders",
    "title": "Stat 100",
    "section": "Reminders",
    "text": "Reminders\n\nClass in full swing:\n\nSections: Can find your assigned section in my.harvard but need to go to the linked spreadsheet to find the room!\nOffice hours\nWrap-ups on Th 3-4pm and Fri 10:30 - 11:30am in SC 309\nLecture quiz will be released in Gradescope after class on Wednesday."
  },
  {
    "objectID": "stat100_wk04mon.html#announcements",
    "href": "stat100_wk04mon.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nStarting 1-on-1, virtual Office Hours\n\n15 minute appointments, max 30 minutes per week\nFor conceptual, not p-set, questions\n\n\nGoals for Today\n\n\n\nMore data wrangling\n\n\n\nData joins"
  },
  {
    "objectID": "stat100_wk04mon.html#load-necessary-packages",
    "href": "stat100_wk04mon.html#load-necessary-packages",
    "title": "Stat 100",
    "section": "Load Necessary Packages",
    "text": "Load Necessary Packages\n\n\n\n\n\ndplyr is part of this collection of data science packages.\n\n# Load necessary packages\nlibrary(tidyverse)"
  },
  {
    "objectID": "stat100_wk04mon.html#data-setting-bureau-of-labor-statistics-bls-consumer-expenditure-survey",
    "href": "stat100_wk04mon.html#data-setting-bureau-of-labor-statistics-bls-consumer-expenditure-survey",
    "title": "Stat 100",
    "section": "Data Setting: Bureau of Labor Statistics (BLS) Consumer Expenditure Survey",
    "text": "Data Setting: Bureau of Labor Statistics (BLS) Consumer Expenditure Survey\nBLS Mission: “Measures labor market activity, working conditions, price changes, and productivity in the U.S. economy to support public and private decision making.”\nData: Last quarter of the 2016 BLS Consumer Expenditure Survey.\n\nlibrary(tidyverse)\n\nce_raw &lt;- read_csv(\"data/fmli.csv\", \n                 na = c(\"NA\", \".\"))\nglimpse(ce_raw)\n\nRows: 6,301\nColumns: 51\n$ NEWID    &lt;chr&gt; \"03324174\", \"03324204\", \"03324214\", \"03324244\", \"03324274\", \"…\n$ PRINEARN &lt;chr&gt; \"01\", \"01\", \"01\", \"01\", \"02\", \"01\", \"01\", \"01\", \"02\", \"01\", \"…\n$ FINLWT21 &lt;dbl&gt; 25984.767, 6581.018, 20208.499, 18078.372, 20111.619, 19907.3…\n$ FINCBTAX &lt;dbl&gt; 116920, 200, 117000, 0, 2000, 942, 0, 91000, 95000, 40037, 10…\n$ BLS_URBN &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ POPSIZE  &lt;dbl&gt; 2, 3, 4, 2, 2, 2, 1, 2, 5, 2, 3, 2, 2, 3, 4, 3, 3, 1, 4, 1, 1…\n$ EDUC_REF &lt;chr&gt; \"16\", \"15\", \"16\", \"15\", \"14\", \"11\", \"10\", \"13\", \"12\", \"12\", \"…\n$ EDUCA2   &lt;dbl&gt; 15, 15, 13, NA, NA, NA, NA, 15, 15, 14, 12, 12, NA, NA, NA, 1…\n$ AGE_REF  &lt;dbl&gt; 63, 50, 47, 37, 51, 63, 77, 37, 51, 64, 26, 59, 81, 51, 67, 4…\n$ AGE2     &lt;dbl&gt; 50, 47, 46, NA, NA, NA, NA, 36, 53, 67, 44, 62, NA, NA, NA, 4…\n$ SEX_REF  &lt;dbl&gt; 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1…\n$ SEX2     &lt;dbl&gt; 2, 2, 1, NA, NA, NA, NA, 2, 2, 1, 1, 1, NA, NA, NA, 1, NA, 1,…\n$ REF_RACE &lt;dbl&gt; 1, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1…\n$ RACE2    &lt;dbl&gt; 1, 4, 1, NA, NA, NA, NA, 1, 1, 1, 1, 1, NA, NA, NA, 2, NA, 1,…\n$ HISP_REF &lt;dbl&gt; 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1…\n$ HISP2    &lt;dbl&gt; 2, 2, 1, NA, NA, NA, NA, 2, 2, 2, 2, 2, NA, NA, NA, 2, NA, 2,…\n$ FAM_TYPE &lt;dbl&gt; 3, 4, 1, 8, 9, 9, 8, 3, 1, 1, 3, 1, 8, 9, 8, 5, 9, 4, 8, 3, 2…\n$ MARITAL1 &lt;dbl&gt; 1, 1, 1, 5, 3, 3, 2, 1, 1, 1, 1, 1, 2, 3, 5, 1, 3, 1, 3, 1, 1…\n$ REGION   &lt;dbl&gt; 4, 4, 3, 4, 4, 3, 4, 1, 3, 2, 1, 4, 1, 3, 3, 3, 2, 1, 2, 4, 3…\n$ SMSASTAT &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ HIGH_EDU &lt;chr&gt; \"16\", \"15\", \"16\", \"15\", \"14\", \"11\", \"10\", \"15\", \"15\", \"14\", \"…\n$ EHOUSNGC &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ TOTEXPCQ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ FOODCQ   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ TRANSCQ  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ HEALTHCQ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ENTERTCQ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ EDUCACQ  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ TOBACCCQ &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ STUDFINX &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ IRAX     &lt;dbl&gt; 1000000, 10000, 0, NA, NA, 0, 0, 15000, NA, 477000, NA, NA, N…\n$ CUTENURE &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 4, 1, 1, 2, 1, 2, 2, 2, 2, 4, 1, 1, 1, 4, 4…\n$ FAM_SIZE &lt;dbl&gt; 4, 6, 2, 1, 2, 2, 1, 5, 2, 2, 4, 2, 1, 2, 1, 4, 2, 4, 1, 3, 3…\n$ VEHQ     &lt;dbl&gt; 3, 5, 0, 4, 2, 0, 0, 2, 4, 2, 3, 2, 1, 3, 1, 2, 4, 4, 0, 2, 3…\n$ ROOMSQ   &lt;dbl&gt; 8, 5, 6, 4, 4, 4, 7, 5, 4, 9, 6, 10, 4, 7, 5, 6, 6, 8, 18, 4,…\n$ INC_HRS1 &lt;dbl&gt; 40, 40, 40, 44, 40, NA, NA, 40, 40, NA, 40, NA, NA, NA, NA, 4…\n$ INC_HRS2 &lt;dbl&gt; 30, 40, 52, NA, NA, NA, NA, 40, 40, NA, 65, NA, NA, NA, NA, 6…\n$ EARNCOMP &lt;dbl&gt; 3, 2, 2, 1, 4, 7, 8, 2, 2, 8, 2, 8, 8, 7, 8, 2, 7, 3, 1, 2, 1…\n$ NO_EARNR &lt;dbl&gt; 4, 2, 2, 1, 2, 1, 0, 2, 2, 0, 2, 0, 0, 1, 0, 2, 1, 3, 1, 2, 1…\n$ OCCUCOD1 &lt;chr&gt; \"03\", \"03\", \"05\", \"03\", \"04\", \"\", \"\", \"12\", \"04\", \"\", \"01\", \"…\n$ OCCUCOD2 &lt;chr&gt; \"04\", \"02\", \"01\", \"\", \"\", \"\", \"\", \"02\", \"03\", \"\", \"11\", \"\", \"…\n$ STATE    &lt;chr&gt; \"41\", \"15\", \"48\", \"06\", \"06\", \"48\", \"06\", \"42\", \"\", \"27\", \"25…\n$ DIVISION &lt;dbl&gt; 9, 9, 7, 9, 9, 7, 9, 2, NA, 4, 1, 8, 2, 5, 6, 7, 3, 2, 3, 9, …\n$ TOTXEST  &lt;dbl&gt; 15452, 11459, 15738, 25978, 588, 0, 0, 7261, 9406, -1414, 141…\n$ CREDFINX &lt;dbl&gt; 0, NA, 0, NA, 5, NA, NA, NA, NA, 0, NA, 0, NA, NA, NA, 2, 35,…\n$ CREDITB  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREDITX  &lt;dbl&gt; 4000, 5000, 2000, NA, 7000, 1800, NA, 6000, NA, 719, NA, 1200…\n$ BUILDING &lt;chr&gt; \"01\", \"01\", \"01\", \"02\", \"08\", \"01\", \"01\", \"01\", \"01\", \"01\", \"…\n$ ST_HOUS  &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ INT_PHON &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ INT_HOME &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  },
  {
    "objectID": "stat100_wk04mon.html#wrangling-ce-data",
    "href": "stat100_wk04mon.html#wrangling-ce-data",
    "title": "Stat 100",
    "section": "Wrangling CE Data",
    "text": "Wrangling CE Data\n\n\nWant to better understand a family’s income and expenditures\n\nce &lt;- ce_raw %&gt;%\n  select(NEWID, PRINEARN, FINCBTAX,\n         BLS_URBN, HIGH_EDU, TOTEXPCQ, IRAX)\ndim(ce)\n\n[1] 6301    7\n\n\nVariables:\n\n\nNEWID: ID for the household\nPRINEARN: ID for which member of the household is the principal earner\nFINCBTAX: Final income before taxes for the year\n\n\n\n\n\nBLS_URBN: 1 = urban, 2 = rural\nHIGH_EDU: Highest education in the household. 00 = Never attended, 10 = Grades 1-8, 11 = Grades 9-12, no degree, 12 = High school graduate, 13 = Some college, no degree, 14 = Associates degree, 15 = Bachelor’s degree, 16 = Masters, Professional/doctorate degree\nTOTEXPCQ = Total household expenditures for the current quarter\nIRAX = Total in retirement funds"
  },
  {
    "objectID": "stat100_wk04mon.html#wrangling-ce-data-1",
    "href": "stat100_wk04mon.html#wrangling-ce-data-1",
    "title": "Stat 100",
    "section": "Wrangling CE Data",
    "text": "Wrangling CE Data\n\nce &lt;- ce %&gt;%\n  mutate(YEARLY_EXP = TOTEXPCQ*4)\nce\n\n# A tibble: 6,301 × 8\n   NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU TOTEXPCQ    IRAX YEARLY_EXP\n   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n 1 03324174 01         116920        1 16              0 1000000          0\n 2 03324204 01            200        1 15              0   10000          0\n 3 03324214 01         117000        1 16              0       0          0\n 4 03324244 01              0        1 15              0      NA          0\n 5 03324274 02           2000        1 14              0      NA          0\n 6 03324284 01            942        1 11              0       0          0\n 7 03324294 01              0        1 10              0       0          0\n 8 03324304 01          91000        1 15              0   15000          0\n 9 03324324 02          95000        2 15              0      NA          0\n10 03324334 01          40037        1 14              0  477000          0\n# ℹ 6,291 more rows"
  },
  {
    "objectID": "stat100_wk04mon.html#logical-operators",
    "href": "stat100_wk04mon.html#logical-operators",
    "title": "Stat 100",
    "section": "Logical Operators",
    "text": "Logical Operators\n\nce_sub &lt;- ce %&gt;%\n  filter(YEARLY_EXP &gt; 0, BLS_URBN == 1, HIGH_EDU != \"00\")\nce_sub\n\n# A tibble: 3,950 × 8\n   NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU TOTEXPCQ   IRAX YEARLY_EXP\n   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n 1 03335204 01          37000        1 14          2492.      0      9968.\n 2 03335214 01         103000        1 16          6128.     NA     24513.\n 3 03335224 01          14686        1 13          1072.     NA      4287.\n 4 03335244 02          33396        1 12          1630       0      6520 \n 5 03335264 01              0        1 13          3213.     NA     12853.\n 6 03335274 01              0        1 15          4674.      0     18694.\n 7 03335294 01         745136        1 16          8693. 280000     34773.\n 8 03335304 01          36000        1 16          3733.     NA     14933.\n 9 03335314 02          45000        1 15          3627.   3000     14509 \n10 03335334 01          20862        1 13           802.      0      3209.\n# ℹ 3,940 more rows"
  },
  {
    "objectID": "stat100_wk04mon.html#logical-operators-1",
    "href": "stat100_wk04mon.html#logical-operators-1",
    "title": "Stat 100",
    "section": "Logical Operators",
    "text": "Logical Operators\n\nce_sub &lt;- ce %&gt;%\n  filter(YEARLY_EXP &gt; 0, (BLS_URBN == 1 | HIGH_EDU != \"00\"))\nce_sub\n\n# A tibble: 4,178 × 8\n   NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU TOTEXPCQ   IRAX YEARLY_EXP\n   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n 1 03335204 01          37000        1 14          2492.      0      9968.\n 2 03335214 01         103000        1 16          6128.     NA     24513.\n 3 03335224 01          14686        1 13          1072.     NA      4287.\n 4 03335244 02          33396        1 12          1630       0      6520 \n 5 03335264 01              0        1 13          3213.     NA     12853.\n 6 03335274 01              0        1 15          4674.      0     18694.\n 7 03335294 01         745136        1 16          8693. 280000     34773.\n 8 03335304 01          36000        1 16          3733.     NA     14933.\n 9 03335314 02          45000        1 15          3627.   3000     14509 \n10 03335334 01          20862        1 13           802.      0      3209.\n# ℹ 4,168 more rows"
  },
  {
    "objectID": "stat100_wk04mon.html#case_when-recoding-variables",
    "href": "stat100_wk04mon.html#case_when-recoding-variables",
    "title": "Stat 100",
    "section": "case_when: Recoding Variables",
    "text": "case_when: Recoding Variables\n\n\n\ncount(ce, BLS_URBN)\n\n# A tibble: 2 × 2\n  BLS_URBN     n\n     &lt;dbl&gt; &lt;int&gt;\n1        1  5952\n2        2   349\n\n\n\n\nce &lt;- ce %&gt;%\n  mutate(BLS_URBN = case_when(\n    BLS_URBN == 1 ~ \"Urban\",\n    BLS_URBN == 2 ~ \"Rural\"\n  ))\ncount(ce, BLS_URBN)\n\n# A tibble: 2 × 2\n  BLS_URBN     n\n  &lt;chr&gt;    &lt;int&gt;\n1 Rural      349\n2 Urban     5952"
  },
  {
    "objectID": "stat100_wk04mon.html#case_when-creating-variables",
    "href": "stat100_wk04mon.html#case_when-creating-variables",
    "title": "Stat 100",
    "section": "case_when: Creating Variables",
    "text": "case_when: Creating Variables\n\n\n\ncount(ce, HIGH_EDU)\n\n# A tibble: 8 × 2\n  HIGH_EDU     n\n  &lt;chr&gt;    &lt;int&gt;\n1 00           8\n2 10         110\n3 11         302\n4 12        1272\n5 13        1297\n6 14         714\n7 15        1528\n8 16        1070\n\nce &lt;- ce %&gt;%\n  mutate(HIGH_EDU = as.numeric(HIGH_EDU))\ncount(ce, HIGH_EDU)\n\n# A tibble: 8 × 2\n  HIGH_EDU     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0     8\n2       10   110\n3       11   302\n4       12  1272\n5       13  1297\n6       14   714\n7       15  1528\n8       16  1070\n\n\n\n\nce &lt;- ce %&gt;%\n  mutate(HIGH_EDU2 = case_when(\n    is.na(HIGH_EDU) ~ NA,\n    HIGH_EDU &lt;= 11 ~ \"Less than high school degree\",\n    between(HIGH_EDU, 12, 13) ~ \"High school degree\",\n    HIGH_EDU &gt;= 14 ~ \"College degree\"\n  ))\ncount(ce, HIGH_EDU2)\n\n# A tibble: 3 × 2\n  HIGH_EDU2                        n\n  &lt;chr&gt;                        &lt;int&gt;\n1 College degree                3312\n2 High school degree            2569\n3 Less than high school degree   420"
  },
  {
    "objectID": "stat100_wk04mon.html#variable-names",
    "href": "stat100_wk04mon.html#variable-names",
    "title": "Stat 100",
    "section": "Variable Names",
    "text": "Variable Names\nSometimes datasets come with terrible variable names.\n\nce &lt;- ce %&gt;%\n  rename(INCOME = FINCBTAX)\nce\n\n# A tibble: 6,301 × 9\n   NEWID PRINEARN INCOME BLS_URBN HIGH_EDU TOTEXPCQ    IRAX YEARLY_EXP HIGH_EDU2\n   &lt;chr&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    \n 1 0332… 01       116920 Urban          16        0 1000000          0 College …\n 2 0332… 01          200 Urban          15        0   10000          0 College …\n 3 0332… 01       117000 Urban          16        0       0          0 College …\n 4 0332… 01            0 Urban          15        0      NA          0 College …\n 5 0332… 02         2000 Urban          14        0      NA          0 College …\n 6 0332… 01          942 Urban          11        0       0          0 Less tha…\n 7 0332… 01            0 Urban          10        0       0          0 Less tha…\n 8 0332… 01        91000 Urban          15        0   15000          0 College …\n 9 0332… 02        95000 Rural          15        0      NA          0 College …\n10 0332… 01        40037 Urban          14        0  477000          0 College …\n# ℹ 6,291 more rows"
  },
  {
    "objectID": "stat100_wk04mon.html#handling-missing-data",
    "href": "stat100_wk04mon.html#handling-missing-data",
    "title": "Stat 100",
    "section": "Handling Missing Data",
    "text": "Handling Missing Data\nWant to compute mean income and mean retirement funds by location.\n\n\n\nce %&gt;%\n  group_by(BLS_URBN) %&gt;%\n  summarize(mean_INCOME = mean(INCOME),\n            mean_IRAX = mean(IRAX),\n            households = n())\n\n# A tibble: 2 × 4\n  BLS_URBN mean_INCOME mean_IRAX households\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;      &lt;int&gt;\n1 Rural         40440.        NA        349\n2 Urban         63772.        NA       5952\n\n\n\n\nce_aggressive &lt;- ce_raw %&gt;%\n  na.omit()\nce_aggressive\n\n# A tibble: 0 × 51\n# ℹ 51 variables: NEWID &lt;chr&gt;, PRINEARN &lt;chr&gt;, FINLWT21 &lt;dbl&gt;, FINCBTAX &lt;dbl&gt;,\n#   BLS_URBN &lt;dbl&gt;, POPSIZE &lt;dbl&gt;, EDUC_REF &lt;chr&gt;, EDUCA2 &lt;dbl&gt;, AGE_REF &lt;dbl&gt;,\n#   AGE2 &lt;dbl&gt;, SEX_REF &lt;dbl&gt;, SEX2 &lt;dbl&gt;, REF_RACE &lt;dbl&gt;, RACE2 &lt;dbl&gt;,\n#   HISP_REF &lt;dbl&gt;, HISP2 &lt;dbl&gt;, FAM_TYPE &lt;dbl&gt;, MARITAL1 &lt;dbl&gt;, REGION &lt;dbl&gt;,\n#   SMSASTAT &lt;dbl&gt;, HIGH_EDU &lt;chr&gt;, EHOUSNGC &lt;dbl&gt;, TOTEXPCQ &lt;dbl&gt;,\n#   FOODCQ &lt;dbl&gt;, TRANSCQ &lt;dbl&gt;, HEALTHCQ &lt;dbl&gt;, ENTERTCQ &lt;dbl&gt;, EDUCACQ &lt;dbl&gt;,\n#   TOBACCCQ &lt;dbl&gt;, STUDFINX &lt;dbl&gt;, IRAX &lt;dbl&gt;, CUTENURE &lt;dbl&gt;, …"
  },
  {
    "objectID": "stat100_wk04mon.html#handling-missing-data-1",
    "href": "stat100_wk04mon.html#handling-missing-data-1",
    "title": "Stat 100",
    "section": "Handling Missing Data",
    "text": "Handling Missing Data\n\n\n\nce_moderate &lt;- ce %&gt;%\n  drop_na(IRAX, INCOME, BLS_URBN) %&gt;%\n  group_by(BLS_URBN) %&gt;%  \n  summarize(mean_INCOME = mean(INCOME),\n            mean_IRAX = mean(IRAX),\n            households = n())\n\nce_moderate\n\n# A tibble: 2 × 4\n  BLS_URBN mean_INCOME mean_IRAX households\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;      &lt;int&gt;\n1 Rural         38651.    37008.         63\n2 Urban         58987.    94512.        991\n\n\n\n\nce_light &lt;- ce %&gt;%\n  group_by(BLS_URBN) %&gt;%\n  summarize(mean_INCOME = mean(INCOME, na.rm = TRUE),\n            mean_IRAX = mean(IRAX, na.rm = TRUE), \n            households = n())\n\nce_light\n\n# A tibble: 2 × 4\n  BLS_URBN mean_INCOME mean_IRAX households\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;      &lt;int&gt;\n1 Rural         40440.    37008.        349\n2 Urban         63772.    94512.       5952"
  },
  {
    "objectID": "stat100_wk04mon.html#multiple-groupings",
    "href": "stat100_wk04mon.html#multiple-groupings",
    "title": "Stat 100",
    "section": "Multiple Groupings",
    "text": "Multiple Groupings\n\nce %&gt;%\n  group_by(BLS_URBN, HIGH_EDU2) %&gt;%\n  summarize(mean_INCOME = mean(INCOME, na.rm = TRUE),\n            mean_IRAX = mean(IRAX, na.rm = TRUE), \n            households = n()) %&gt;%\n  arrange(mean_IRAX)\n\n# A tibble: 6 × 5\n# Groups:   BLS_URBN [2]\n  BLS_URBN HIGH_EDU2                    mean_INCOME mean_IRAX households\n  &lt;chr&gt;    &lt;chr&gt;                              &lt;dbl&gt;     &lt;dbl&gt;      &lt;int&gt;\n1 Rural    Less than high school degree      14715.        0          39\n2 Urban    Less than high school degree      23046.     8270.        381\n3 Rural    High school degree                31087.    15543.        192\n4 Urban    High school degree                39147.    30533.       2377\n5 Rural    College degree                    64161.   105148.        118\n6 Urban    College degree                    86957.   168767.       3194"
  },
  {
    "objectID": "stat100_wk04mon.html#piping-into-ggplot2",
    "href": "stat100_wk04mon.html#piping-into-ggplot2",
    "title": "Stat 100",
    "section": "Piping into ggplot2",
    "text": "Piping into ggplot2\n\n\nce %&gt;%\n  group_by(BLS_URBN, HIGH_EDU2) %&gt;%\n  summarize(mean_INCOME = mean(INCOME, na.rm = TRUE),\n            mean_IRAX = mean(IRAX, na.rm = TRUE), \n            households = n()) %&gt;%\n  ggplot(mapping = aes(x = mean_INCOME,\n                       y = mean_IRAX, \n                       shape = BLS_URBN,\n                       color = HIGH_EDU2)) +\n  geom_point(size = 5)"
  },
  {
    "objectID": "stat100_wk04mon.html#data-joins",
    "href": "stat100_wk04mon.html#data-joins",
    "title": "Stat 100",
    "section": "Data Joins",
    "text": "Data Joins\n\nOften in the data analysis workflow, we have more than one data source, which means more than one dataframe, and we want to combine these dataframes.\nNeed principled way to combine.\n\nNeed a key that links two dataframes together.\n\nThese multiple dataframes are called relational data."
  },
  {
    "objectID": "stat100_wk04mon.html#ce-data",
    "href": "stat100_wk04mon.html#ce-data",
    "title": "Stat 100",
    "section": "CE Data",
    "text": "CE Data\n\n\nHousehold survey but data are also collected on individuals\n\nfmli: household data\nmemi: household member-level data\n\n\n\n\nfmli &lt;- read_csv(\"data/fmli.csv\", \n                 na = c(\"NA\", \".\")) %&gt;%\n  select(NEWID, PRINEARN, FINCBTAX,\n         BLS_URBN, HIGH_EDU)\nmemi &lt;- read_csv(\"data/memi.csv\", \n                 na = c(\"NA\", \".\")) %&gt;%\n  select(NEWID, MEMBNO, AGE, SEX, EARNTYPE)\n\n\nWant to add variables on the principal earner from the member data frame to the household data frame"
  },
  {
    "objectID": "stat100_wk04mon.html#ce-data-1",
    "href": "stat100_wk04mon.html#ce-data-1",
    "title": "Stat 100",
    "section": "CE Data",
    "text": "CE Data\nKey variable(s)?\n\n\n\nfmli\n\n# A tibble: 6,301 × 5\n   NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU\n   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;   \n 1 03324174 01         116920        1 16      \n 2 03324204 01            200        1 15      \n 3 03324214 01         117000        1 16      \n 4 03324244 01              0        1 15      \n 5 03324274 02           2000        1 14      \n 6 03324284 01            942        1 11      \n 7 03324294 01              0        1 10      \n 8 03324304 01          91000        1 15      \n 9 03324324 02          95000        2 15      \n10 03324334 01          40037        1 14      \n# ℹ 6,291 more rows\n\n\n\n\nmemi\n\n# A tibble: 15,412 × 5\n   NEWID    MEMBNO   AGE   SEX EARNTYPE\n   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 03552611      1    58     2        2\n 2 03552641      1    54     1        1\n 3 03552641      2    49     2       NA\n 4 03552651      1    39     2       NA\n 5 03552651      2    10     2       NA\n 6 03552651      3    32     1       NA\n 7 03552651      4     7     1       NA\n 8 03552651      5     9     1       NA\n 9 03552681      1    38     1        3\n10 03552681      2    34     2       NA\n# ℹ 15,402 more rows"
  },
  {
    "objectID": "stat100_wk04mon.html#ce-data-2",
    "href": "stat100_wk04mon.html#ce-data-2",
    "title": "Stat 100",
    "section": "CE Data",
    "text": "CE Data\n\nKey variables?\n\nProblem with class?\n\n\n\nclass(fmli$NEWID)\n\n[1] \"character\"\n\nclass(memi$NEWID)\n\n[1] \"character\"\n\nclass(fmli$PRINEARN)\n\n[1] \"character\"\n\nclass(memi$MEMBNO)\n\n[1] \"numeric\""
  },
  {
    "objectID": "stat100_wk04mon.html#ce-data-3",
    "href": "stat100_wk04mon.html#ce-data-3",
    "title": "Stat 100",
    "section": "CE Data",
    "text": "CE Data\n\nKey variables?\n\nProblem with class?\n\n\n\nfmli &lt;- mutate(fmli, PRINEARN = as.integer(PRINEARN))\nclass(fmli$PRINEARN)\n\n[1] \"integer\"\n\nclass(memi$MEMBNO)\n\n[1] \"numeric\""
  },
  {
    "objectID": "stat100_wk04mon.html#ce-data-4",
    "href": "stat100_wk04mon.html#ce-data-4",
    "title": "Stat 100",
    "section": "CE Data",
    "text": "CE Data\n\nWant to add columns of memi to fmli that correspond to the principal earner’s memi data\n\nWhat type of join is that?"
  },
  {
    "objectID": "stat100_wk04mon.html#the-world-of-joins",
    "href": "stat100_wk04mon.html#the-world-of-joins",
    "title": "Stat 100",
    "section": "The World of Joins",
    "text": "The World of Joins\n\nMutating joins: Add new variables to one dataset from matching observations in another.\n\nleft_join() (and right_join())\ninner_join()\nfull_join()\n\nThere are also filtering joins but we won’t cover those today."
  },
  {
    "objectID": "stat100_wk04mon.html#example-dataframes",
    "href": "stat100_wk04mon.html#example-dataframes",
    "title": "Stat 100",
    "section": "Example Dataframes",
    "text": "Example Dataframes\nHere I created the data frames by hand.\n\nstaff &lt;- data.frame(member = c(\"Prof McConville\", \"Lety\", \"Kate\",\n                               \"Thor\", \"Mally\", \"Dylan\", \"Nick\"),\n                 Year = c(2006, 2024, 2023, 2025, 2025, 2025, 2025),\n                 Food = c(\"tikka masala\", \"chicken wings\", \"sushi\",\n                          \"Sun HUDS Brunch\", \"quesadillas\",\n                          \"shepards pie\", \"burgers\"),\n                 Neighborhood = c(\"Somerville\", \"River Central\", \"Quad\", \n                                  \"River East\", \"River Central\",\n                                  \"Quad\", \"River Central\"))\nhousing &lt;- data.frame(Neighborhoods = c(\"Yard\", \"River East\",\n                                        \"River Central\", \"River West\",\n                                        \"Quad\"),\n                      Steps = c(75, 600, 450, 1100, 1200))"
  },
  {
    "objectID": "stat100_wk04mon.html#example-dataframes-1",
    "href": "stat100_wk04mon.html#example-dataframes-1",
    "title": "Stat 100",
    "section": "Example Dataframes",
    "text": "Example Dataframes\n\nstaff\n\n           member Year            Food  Neighborhood\n1 Prof McConville 2006    tikka masala    Somerville\n2            Lety 2024   chicken wings River Central\n3            Kate 2023           sushi          Quad\n4            Thor 2025 Sun HUDS Brunch    River East\n5           Mally 2025     quesadillas River Central\n6           Dylan 2025    shepards pie          Quad\n7            Nick 2025         burgers River Central\n\nhousing\n\n  Neighborhoods Steps\n1          Yard    75\n2    River East   600\n3 River Central   450\n4    River West  1100\n5          Quad  1200"
  },
  {
    "objectID": "stat100_wk04mon.html#left_join",
    "href": "stat100_wk04mon.html#left_join",
    "title": "Stat 100",
    "section": "left_join()",
    "text": "left_join()\n\nstaff_new &lt;- left_join(staff, housing)\n\nError in `left_join()`:\n! `by` must be supplied when `x` and `y` have no common variables.\nℹ Use `cross_join()` to perform a cross-join.\n\nstaff_new\n\nError in eval(expr, envir, enclos): object 'staff_new' not found"
  },
  {
    "objectID": "stat100_wk04mon.html#left_join-1",
    "href": "stat100_wk04mon.html#left_join-1",
    "title": "Stat 100",
    "section": "left_join()",
    "text": "left_join()\n\nstaff_new &lt;- left_join(staff, housing, join_by(\"Neighborhood\" == \"Neighborhoods\"))\nstaff_new\n\n           member Year            Food  Neighborhood Steps\n1 Prof McConville 2006    tikka masala    Somerville    NA\n2            Lety 2024   chicken wings River Central   450\n3            Kate 2023           sushi          Quad  1200\n4            Thor 2025 Sun HUDS Brunch    River East   600\n5           Mally 2025     quesadillas River Central   450\n6           Dylan 2025    shepards pie          Quad  1200\n7            Nick 2025         burgers River Central   450"
  },
  {
    "objectID": "stat100_wk04mon.html#inner_join",
    "href": "stat100_wk04mon.html#inner_join",
    "title": "Stat 100",
    "section": "inner_join()",
    "text": "inner_join()\n\nstaff_housing &lt;- inner_join(staff, housing, join_by(\"Neighborhood\" == \"Neighborhoods\"))\nstaff_housing\n\n  member Year            Food  Neighborhood Steps\n1   Lety 2024   chicken wings River Central   450\n2   Kate 2023           sushi          Quad  1200\n3   Thor 2025 Sun HUDS Brunch    River East   600\n4  Mally 2025     quesadillas River Central   450\n5  Dylan 2025    shepards pie          Quad  1200\n6   Nick 2025         burgers River Central   450"
  },
  {
    "objectID": "stat100_wk04mon.html#full_join",
    "href": "stat100_wk04mon.html#full_join",
    "title": "Stat 100",
    "section": "full_join()",
    "text": "full_join()\n\nstaff_housing &lt;- full_join(staff, housing, join_by(\"Neighborhood\" == \"Neighborhoods\"))\nstaff_housing\n\n           member Year            Food  Neighborhood Steps\n1 Prof McConville 2006    tikka masala    Somerville    NA\n2            Lety 2024   chicken wings River Central   450\n3            Kate 2023           sushi          Quad  1200\n4            Thor 2025 Sun HUDS Brunch    River East   600\n5           Mally 2025     quesadillas River Central   450\n6           Dylan 2025    shepards pie          Quad  1200\n7            Nick 2025         burgers River Central   450\n8            &lt;NA&gt;   NA            &lt;NA&gt;          Yard    75\n9            &lt;NA&gt;   NA            &lt;NA&gt;    River West  1100"
  },
  {
    "objectID": "stat100_wk04mon.html#back-to-our-example",
    "href": "stat100_wk04mon.html#back-to-our-example",
    "title": "Stat 100",
    "section": "Back to our Example",
    "text": "Back to our Example\n\nWhat kind of join do we want for the Consumer Expenditure data?\n\nWant to add columns of memi to fmli that correspond to the principal earner’s memi data\n\nAlso going to create smaller data frames for us to play with:\n\n\n\n\nfmli_small &lt;- filter(fmli, NEWID %in% c(\"03530051\",\n                                        \"03327224\",\n                                        \"03324324\",\n                                        \"03324244\"))\nfmli_small\n\n# A tibble: 4 × 5\n  NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU\n  &lt;chr&gt;       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;   \n1 03324244        1        0        1 15      \n2 03324324        2    95000        2 15      \n3 03327224        1        0        1 14      \n4 03530051        3    70000        1 11      \n\n\n\n\nmemi_small &lt;- filter(memi, NEWID %in% c(\"03530051\",\n                                        \"03327224\",\n                                        \"03324324\",\n                                        \"03324244\"))\nmemi_small\n\n# A tibble: 10 × 5\n   NEWID    MEMBNO   AGE   SEX EARNTYPE\n   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 03324244      1    37     1        1\n 2 03324324      1    51     1        1\n 3 03324324      2    53     2        1\n 4 03327224      1    28     2        3\n 5 03327224      2    32     1        2\n 6 03327224      3     1     2       NA\n 7 03530051      1    43     1       NA\n 8 03530051      2    16     1       NA\n 9 03530051      3    44     1        3\n10 03530051      4     5     2       NA"
  },
  {
    "objectID": "stat100_wk04mon.html#look-at-the-possible-joins",
    "href": "stat100_wk04mon.html#look-at-the-possible-joins",
    "title": "Stat 100",
    "section": "Look at the Possible Joins",
    "text": "Look at the Possible Joins\n\nleft_join(fmli_small, memi_small) \n\nJoining with `by = join_by(NEWID)`\n\n\n# A tibble: 10 × 9\n   NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU MEMBNO   AGE   SEX EARNTYPE\n   &lt;chr&gt;       &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 03324244        1        0        1 15            1    37     1        1\n 2 03324324        2    95000        2 15            1    51     1        1\n 3 03324324        2    95000        2 15            2    53     2        1\n 4 03327224        1        0        1 14            1    28     2        3\n 5 03327224        1        0        1 14            2    32     1        2\n 6 03327224        1        0        1 14            3     1     2       NA\n 7 03530051        3    70000        1 11            1    43     1       NA\n 8 03530051        3    70000        1 11            2    16     1       NA\n 9 03530051        3    70000        1 11            3    44     1        3\n10 03530051        3    70000        1 11            4     5     2       NA"
  },
  {
    "objectID": "stat100_wk04mon.html#look-at-the-possible-joins-1",
    "href": "stat100_wk04mon.html#look-at-the-possible-joins-1",
    "title": "Stat 100",
    "section": "Look at the Possible Joins",
    "text": "Look at the Possible Joins\n\nBe careful. This erroneous example made my R crash when I tried it on the full data frames.\n\n\n\n\nleft_join(fmli_small, memi_small, join_by(\"PRINEARN\" == \"MEMBNO\"))\n\n# A tibble: 13 × 9\n   NEWID.x  PRINEARN FINCBTAX BLS_URBN HIGH_EDU NEWID.y    AGE   SEX EARNTYPE\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 03324244        1        0        1 15       03324244    37     1        1\n 2 03324244        1        0        1 15       03324324    51     1        1\n 3 03324244        1        0        1 15       03327224    28     2        3\n 4 03324244        1        0        1 15       03530051    43     1       NA\n 5 03324324        2    95000        2 15       03324324    53     2        1\n 6 03324324        2    95000        2 15       03327224    32     1        2\n 7 03324324        2    95000        2 15       03530051    16     1       NA\n 8 03327224        1        0        1 14       03324244    37     1        1\n 9 03327224        1        0        1 14       03324324    51     1        1\n10 03327224        1        0        1 14       03327224    28     2        3\n11 03327224        1        0        1 14       03530051    43     1       NA\n12 03530051        3    70000        1 11       03327224     1     2       NA\n13 03530051        3    70000        1 11       03530051    44     1        3\n\n\n\n\ncount(fmli_small, PRINEARN)\n\n# A tibble: 3 × 2\n  PRINEARN     n\n     &lt;int&gt; &lt;int&gt;\n1        1     2\n2        2     1\n3        3     1\n\ncount(memi_small, MEMBNO)\n\n# A tibble: 4 × 2\n  MEMBNO     n\n   &lt;dbl&gt; &lt;int&gt;\n1      1     4\n2      2     3\n3      3     2\n4      4     1"
  },
  {
    "objectID": "stat100_wk04mon.html#look-at-the-possible-joins-2",
    "href": "stat100_wk04mon.html#look-at-the-possible-joins-2",
    "title": "Stat 100",
    "section": "Look at the Possible Joins",
    "text": "Look at the Possible Joins\n\nleft_join(fmli_small, memi_small, join_by(\"NEWID\" == \"NEWID\", \"PRINEARN\" == \"MEMBNO\"))\n\n# A tibble: 4 × 8\n  NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU   AGE   SEX EARNTYPE\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 03324244        1        0        1 15          37     1        1\n2 03324324        2    95000        2 15          53     2        1\n3 03327224        1        0        1 14          28     2        3\n4 03530051        3    70000        1 11          44     1        3"
  },
  {
    "objectID": "stat100_wk04mon.html#look-at-the-possible-joins-3",
    "href": "stat100_wk04mon.html#look-at-the-possible-joins-3",
    "title": "Stat 100",
    "section": "Look at the Possible Joins",
    "text": "Look at the Possible Joins\n\ninner_join(fmli_small, memi_small, join_by(\"NEWID\" == \"NEWID\", \"PRINEARN\" == \"MEMBNO\"))\n\n# A tibble: 4 × 8\n  NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU   AGE   SEX EARNTYPE\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 03324244        1        0        1 15          37     1        1\n2 03324324        2    95000        2 15          53     2        1\n3 03327224        1        0        1 14          28     2        3\n4 03530051        3    70000        1 11          44     1        3\n\n\n\nWhy does this give us the same answer as left_join for this situation?"
  },
  {
    "objectID": "stat100_wk04mon.html#look-at-the-possible-joins-4",
    "href": "stat100_wk04mon.html#look-at-the-possible-joins-4",
    "title": "Stat 100",
    "section": "Look at the Possible Joins",
    "text": "Look at the Possible Joins\n\nfull_join(fmli_small, memi_small, join_by(\"NEWID\" == \"NEWID\", \"PRINEARN\" == \"MEMBNO\"))\n\n# A tibble: 10 × 8\n   NEWID    PRINEARN FINCBTAX BLS_URBN HIGH_EDU   AGE   SEX EARNTYPE\n   &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 03324244        1        0        1 15          37     1        1\n 2 03324324        2    95000        2 15          53     2        1\n 3 03327224        1        0        1 14          28     2        3\n 4 03530051        3    70000        1 11          44     1        3\n 5 03324324        1       NA       NA &lt;NA&gt;        51     1        1\n 6 03327224        2       NA       NA &lt;NA&gt;        32     1        2\n 7 03327224        3       NA       NA &lt;NA&gt;         1     2       NA\n 8 03530051        1       NA       NA &lt;NA&gt;        43     1       NA\n 9 03530051        2       NA       NA &lt;NA&gt;        16     1       NA\n10 03530051        4       NA       NA &lt;NA&gt;         5     2       NA"
  },
  {
    "objectID": "stat100_wk04mon.html#joining-tips",
    "href": "stat100_wk04mon.html#joining-tips",
    "title": "Stat 100",
    "section": "Joining Tips",
    "text": "Joining Tips\n\nfmli &lt;- left_join(fmli, memi, join_by(\"NEWID\" == \"NEWID\", \"PRINEARN\" == \"MEMBNO\"))\n\n\nFIRST: conceptualize for yourself what you think you want the final dataset to look like!\nCheck initial dimensions and final dimensions.\nUse variable names when joining even if they are the same."
  },
  {
    "objectID": "stat100_wk04mon.html#naming-wrangled-data",
    "href": "stat100_wk04mon.html#naming-wrangled-data",
    "title": "Stat 100",
    "section": "Naming Wrangled Data",
    "text": "Naming Wrangled Data\nShould I name my new dataframe ce or ce1?\n\nMy answer:\n\nIs your new dataset structurally different? If so, give it a new name.\nAre you removing values you will need for a future analysis within the same document? If so, give it a new name.\nAre you just adding to or cleaning the data? If so, then write over the original."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stat 100: Introduction to Statistics and Data Science",
    "section": "",
    "text": "The lecture slides (both in HTML and PDF) will be posted here.\n\n\n\n\nClass Period\nHTML Slides\nPDF Slides\n\n\n\n\nWeek 1, Wed\n\n\n\n\nWeek 2, Mon\n\n\n\n\nWeek 2, Wed\n\n\n\n\nWeek 3, Mon\n\n\n\n\nWeek 3, Wed\n\n\n\n\nWeek 4, Mon\n\n\n\n\nWeek 4, Wed\n\n\n\n\nWeek 5, Mon\n\n\n\n\nWeek 5, Wed\n\n\n\n\nWeek 7, Mon\n\n\n\n\nWeek 7, Wed\n\n\n\n\nWeek 8, Mon\n\n\n\n\nWeek 8, Wed\n\n\n\n\nWeek 9, Mon\n\n\n\n\nWeek 9, Wed\n\n\n\n\nWeek 10, Mon\n\n\n\n\nWeek 10, Wed\n\n\n\n\nWeek 11, Mon\n\n\n\n\nWeek 11, Wed"
  },
  {
    "objectID": "stat100_wk07mon.html#announcements",
    "href": "stat100_wk07mon.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nThis Wednesday we will be in Sanders Hall instead of Hall C.\nBack to a normal schedule.\n\nHave section & wrap-ups this week!\n\nNotes on the midterm.\n\nGoals for Today\n\n\n\nRecap: Simple linear regression model\nBroadening our idea of linear regression\n\n\n\nRegression with a single, categorical explanatory variable\nRegression with multiple explanatory variables"
  },
  {
    "objectID": "stat100_wk07mon.html#example",
    "href": "stat100_wk07mon.html#example",
    "title": "Stat 100",
    "section": "Example",
    "text": "Example\nMeadowfoam is a plant that grows in the Pacific Northwest and is harvested for its seed oil. In a randomized experiment, researchers at Oregon State University looked at how two light-related factors influenced the number of flowers per meadowfoam plant, the primary measure of productivity for this plant. The two light measures were light intensity (in mmol/ \\(m^2\\) /sec) and the timing of onset of the light (early or late in terms of photo periodic floral induction).\n\nResponse variable:\n\nExplanatory variables:\n\nModel Form:"
  },
  {
    "objectID": "stat100_wk11wed.html#announcements",
    "href": "stat100_wk11wed.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nOnly Thursday wrap-ups this week!\nNo sections or wrap-ups during Thanksgiving Week.\nOH schedule for Thanksgiving Week:\n\nSun, Nov 19th - Tues, Nov 21st: Happening with some modifications\nNo OHs Wed, Nov 22nd - Sun, Nov 26th!\n\n\nGoals for Today\n\n\n\nLearn about conditional probabilities\nCover continuous random variables\n\n\n\nLearn important named random variables\nDiscuss the Central Limit Theorem"
  },
  {
    "objectID": "stat100_wk11wed.html#example",
    "href": "stat100_wk11wed.html#example",
    "title": "Stat 100",
    "section": "Example",
    "text": "Example\nTesting for COVID-19 was an important part of the Keep Harvard Healthy Program. There are a variety of COVID-19 tests out there but for this problem let’s assume the following:\n\n\nThe test gives a false negative result 13% of the time where a false negative case is a person with COVID-19 but the test says they don’t have it.\nThe test gives a false positive result 5% of the time where a false positive case is a person who doesn’t have COVID-19 but the test says they do.\n\n\nLet’s assume the true prevalence is 1%. During the 2021-2022 school year, each week they tested about 30,000 Harvard affiliates. Use the assumed percentages to fill in the following table of potential outcomes:\n\n\n\n\n\n\n\n\n\n\nPositive Test Result\nNegative Test Result\nTotal\n\n\n\n\nActually have COVID-19\n\n\n\n\n\nActually don’t have COVID-19\n\n\n\n\n\nTotal\n\n\n30,000\n\n\n\n\n\nP(test - | have COVID) =\nP(have COVID | test -) =\n\nP(test + | don’t have COVID) =\nP(don’t have COVID | test +) ="
  },
  {
    "objectID": "stat100_wk11wed.html#example-1",
    "href": "stat100_wk11wed.html#example-1",
    "title": "Stat 100",
    "section": "Example",
    "text": "Example\nThe false negative rate of COVID-19 tests have varied wildly. One paper estimated it could be as high as 54%.\nRecreate the table with this new false negative rate.\n\n\n\n\n\n\n\n\n\n\nPositive Test Result\nNegative Test Result\nTotal\n\n\n\n\nActually have COVID-19\n\n\n\n\n\nActually don’t have COVID-19\n\n\n\n\n\nTotal\n\n\n30,000\n\n\n\n\n\nP(test - | have COVID) =\nP(have COVID | test -) =\n\nP(test + | don’t have COVID) =\nP(don’t have COVID | test +) ="
  },
  {
    "objectID": "stat100_wk11wed.html#reminders",
    "href": "stat100_wk11wed.html#reminders",
    "title": "Stat 100",
    "section": "Reminders:",
    "text": "Reminders:\n\n\nNo sections or wrap-ups during Thanksgiving Week.\nOH schedule for Thanksgiving Week:\n\nSun, Nov 19th - Tues, Nov 21st: Happening with some modifications\nNo OHs Wed, Nov 22nd - Sun, Nov 26th!"
  },
  {
    "objectID": "stat100_wk09mon.html#announcements",
    "href": "stat100_wk09mon.html#announcements",
    "title": "Stat 100",
    "section": "Announcements",
    "text": "Announcements\n\nOct 30th Today: Hex or Treat Day in Stat 100\n\nIf you are wearing a Halloween costume, come to the front before or after class for your hex sticker or treat!\n\n\nGoals for Today\n\n\n\nEstimation\nBootstrap distributions\n\n\n\nBootstrapped confidence intervals"
  },
  {
    "objectID": "stat100_wk09mon.html#estimation",
    "href": "stat100_wk09mon.html#estimation",
    "title": "Stat 100",
    "section": "Estimation",
    "text": "Estimation\nGoal: Estimate the value of a population parameter using data from the sample.\nSub-Goal: Quantify our uncertainty in using the sample to say something about the population.\n\nConfidence Interval (CI): Interval of plausible values for a parameter\nForm of a 95% Confidence Interval:\n\\[\\begin{align*}\n\\mbox{statistic} &\\pm \\mbox{Margin of Error}\\\\\n\\mbox{statistic} &\\pm 2\\mbox{SE}\n\\end{align*}\\]\n\n\nProblem: To compute the SE, we need many samples from the population. We have 1 sample.\nSolution: Approximate the sampling distribution using ONLY OUR ONE SAMPLE!"
  },
  {
    "objectID": "stat100_wk09mon.html#load-packages-and-data",
    "href": "stat100_wk09mon.html#load-packages-and-data",
    "title": "Stat 100",
    "section": "Load Packages and Data",
    "text": "Load Packages and Data\n\nlibrary(tidyverse)\nlibrary(infer)\n\nLet’s return to the movies dataset and estimate numerical quantities about Hollywood movies.\n\n# Read in data\nmovies &lt;- read_csv(\"https://www.lock5stat.com/datasets2e/HollywoodMovies.csv\")"
  },
  {
    "objectID": "stat100_wk09mon.html#estimation-for-a-single-mean",
    "href": "stat100_wk09mon.html#estimation-for-a-single-mean",
    "title": "Stat 100",
    "section": "Estimation for a Single Mean",
    "text": "Estimation for a Single Mean\nWhat is the average amount of money \\((\\mu)\\) made in the opening weekend?\n\n# Compute the summary statistic\nx_bar &lt;- movies %&gt;%\n  drop_na(OpeningWeekend) %&gt;%\n  specify(response = OpeningWeekend) %&gt;%\n  calculate(stat = \"mean\")\nx_bar\n\nResponse: OpeningWeekend (numeric)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1  20.6\n\n\n\nWhy is our numerical quantity a mean and not a proportion or correlation here?"
  },
  {
    "objectID": "stat100_wk09mon.html#estimation-for-a-single-mean-1",
    "href": "stat100_wk09mon.html#estimation-for-a-single-mean-1",
    "title": "Stat 100",
    "section": "Estimation for a Single Mean",
    "text": "Estimation for a Single Mean\n\n\nset.seed(999)\n\n\n# Construct bootstrap distribution\nbootstrap_dist &lt;- movies %&gt;%\n  drop_na(OpeningWeekend) %&gt;%\n  specify(response = OpeningWeekend) %&gt;%\n  generate(reps =  1000, type = \"bootstrap\") %&gt;%\n  calculate(stat = \"mean\")\n\n# Look at bootstrap distribution\nggplot(data = bootstrap_dist, \n       mapping = aes(x = stat)) +\n  geom_histogram(color = \"white\")"
  },
  {
    "objectID": "stat100_wk09mon.html#estimation-for-a-single-mean-se-method",
    "href": "stat100_wk09mon.html#estimation-for-a-single-mean-se-method",
    "title": "Stat 100",
    "section": "Estimation for a Single Mean – SE Method",
    "text": "Estimation for a Single Mean – SE Method\n\n\n# Get confidence interval\nci &lt;- bootstrap_dist %&gt;% \n  get_confidence_interval(type = \"se\", level = 0.95,\n                          point_estimate = x_bar)\nci\n\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1     19.0     22.2\n\n\n\nInterpretation: The point estimate is $ 20.6M. I am 95% confidence that the average amount of money made by all Hollywood movies is between $ 19M and $ 22.2M.\nInline R code: The point estimate is $ 20.6M. I am 95% confidence that the average amount of money made by all Hollywood movies is between $ 19.0243721 M and $ 22.2 M."
  },
  {
    "objectID": "stat100_wk09mon.html#estimation-for-a-single-mean-2",
    "href": "stat100_wk09mon.html#estimation-for-a-single-mean-2",
    "title": "Stat 100",
    "section": "Estimation for a Single Mean",
    "text": "Estimation for a Single Mean\n\n\n# Visualize confidence interval\nbootstrap_dist %&gt;%\n  visualize() +\n  shade_confidence_interval(endpoints = ci)"
  },
  {
    "objectID": "stat100_wk09mon.html#estimation-for-a-single-mean-percentile-method",
    "href": "stat100_wk09mon.html#estimation-for-a-single-mean-percentile-method",
    "title": "Stat 100",
    "section": "Estimation for a Single Mean – Percentile Method",
    "text": "Estimation for a Single Mean – Percentile Method\n\n\n# Get confidence interval \nci_95 &lt;- bootstrap_dist %&gt;% \n  get_confidence_interval(type = \"percentile\",\n                          level = 0.95) \nci_95\n\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1     19.0     22.3"
  },
  {
    "objectID": "stat100_wk09mon.html#estimation-for-difference-in-means",
    "href": "stat100_wk09mon.html#estimation-for-difference-in-means",
    "title": "Stat 100",
    "section": "Estimation for Difference in Means",
    "text": "Estimation for Difference in Means\nWhat is the difference in average amount of money made in the opening weekend between action movies and dramas \\((\\mu_1 - \\mu_2)\\)?\n\n\n# Compute the summary statistic\ndiff_x_bar &lt;- movies %&gt;%\n  drop_na(OpeningWeekend) %&gt;%\n  filter(Genre %in% c(\"Drama\", \"Action\")) %&gt;%\n  specify(OpeningWeekend ~ Genre) %&gt;%\n  calculate(stat = \"diff in means\")\ndiff_x_bar\n\n\nResponse: OpeningWeekend (numeric)\nExplanatory: Genre (factor)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1  21.7\n\n\n\n\nWhy a difference in means?"
  },
  {
    "objectID": "stat100_wk09mon.html#estimation-for-difference-in-means-1",
    "href": "stat100_wk09mon.html#estimation-for-difference-in-means-1",
    "title": "Stat 100",
    "section": "Estimation for Difference in Means",
    "text": "Estimation for Difference in Means\n\n\n# Construct bootstrap distribution\nbootstrap_dist &lt;- movies %&gt;%\n  drop_na(OpeningWeekend) %&gt;%\n  filter(Genre %in% c(\"Drama\", \"Action\")) %&gt;%\n  specify(OpeningWeekend ~ Genre) %&gt;%\n  generate(reps =  1000, type = \"bootstrap\") %&gt;%\n  calculate(stat = \"diff in means\",\n            order = c(\"Action\", \"Drama\"))\n\n# Look at bootstrap distribution\nggplot(data = bootstrap_dist,\n       mapping = aes(x = stat)) +\n  geom_histogram(color = \"white\")"
  },
  {
    "objectID": "stat100_wk09mon.html#estimation-for-difference-in-means-se-method",
    "href": "stat100_wk09mon.html#estimation-for-difference-in-means-se-method",
    "title": "Stat 100",
    "section": "Estimation for Difference in Means – SE Method",
    "text": "Estimation for Difference in Means – SE Method\n\n\n# Get confidence interval \nci_95 &lt;- bootstrap_dist %&gt;% \n  get_confidence_interval(type = \"se\", level = 0.95,\n                          point_estimate = diff_x_bar) \nci_95\n\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1     15.9     27.5\n\n\n\nInterpretation: The point estimate is $ 21.7M. I am 95% confidence that action movies make, on average, between $ 15.9M and $ 27.5M more than dramas."
  },
  {
    "objectID": "stat100_wk09mon.html#comparing-cis",
    "href": "stat100_wk09mon.html#comparing-cis",
    "title": "Stat 100",
    "section": "Comparing CIs",
    "text": "Comparing CIs\n\n\nci_99 &lt;- bootstrap_dist %&gt;% \n  get_confidence_interval(type = \"se\", level = 0.99,\n                          point_estimate = diff_x_bar)\n\nbootstrap_dist %&gt;%\n  visualize() +\n  shade_confidence_interval(endpoints = ci_99,\n                            fill = \"gold1\",\n                            color = \"gold3\") +\n  shade_confidence_interval(endpoints = ci_95) \n\n\n\n\n\n\n\n\n\n\n\nWhy construct a 95% CI versus a 99% CI?\n\nNeed to dig into what we mean by confidence!"
  },
  {
    "objectID": "stat100_wk09mon.html#interpreting-confidence-intervals",
    "href": "stat100_wk09mon.html#interpreting-confidence-intervals",
    "title": "Stat 100",
    "section": "Interpreting Confidence Intervals",
    "text": "Interpreting Confidence Intervals\nExample: Estimating average household income before taxes in the US\n\n\nSE Method Formula:\n\\[\n\\mbox{statistic} \\pm{\\mbox{ME}}\n\\]\n\n\n# A tibble: 1 × 3\n     ME  lower  upper\n  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 1963. 60517. 64443.\n\n\n\n“The margin of [sampling] error can be described as the ‘penalty’ in precision for not talking to everyone in a given population. It describes the range that an answer likely falls between if the survey had reached everyone in a population, instead of just a sample of that population.” – Courtney Kennedy, Director of Survey Research at Pew Research Center\nCI = interval of plausible values for the parameter\n\n\nSafe interpretation: I am P% confident that {insert what the parameter represents in context} is between {insert lower bound} and {insert upper bound}."
  },
  {
    "objectID": "stat100_wk09mon.html#caution-confidence-intervals-in-the-wild",
    "href": "stat100_wk09mon.html#caution-confidence-intervals-in-the-wild",
    "title": "Stat 100",
    "section": "Caution: Confidence intervals in the wild",
    "text": "Caution: Confidence intervals in the wild\nStatement in an article for The BMJ (British Medical Journal):"
  },
  {
    "objectID": "stat100_wk09mon.html#reminders",
    "href": "stat100_wk09mon.html#reminders",
    "title": "Stat 100",
    "section": "Reminders:",
    "text": "Reminders:\n\nOct 30th Today: Hex or Treat Day in Stat 100\n\nIf you are wearing a Halloween costume, come to the front before or after class for your hex sticker or treat!"
  }
]